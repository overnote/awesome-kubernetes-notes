

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>一 Kubernetes概述 &mdash; KaliArch&#39;s awesome-kubernetes-notes 1.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to kaliarch kubernetes-note’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> KaliArch's awesome-kubernetes-notes
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">一 Kubernetes概述</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">1.1 容器编排工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">1.2 kubernetes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">1.3 环境架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">1.4 架构和组件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id5">二 核心组件/附件</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#controller">2.1 Controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="#service">2.2 Service</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id6">2.3 网络模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kube-proxy">2.4 kube-proxy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#etcd">2.5 etcd</a></li>
<li class="toctree-l2"><a class="reference internal" href="#flanel">2.6 flanel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">知识小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id8">三 集群部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id9">3.1 部署前准备</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#firewalld-selinux">3.1.1 关闭 firewalld 和 selinux</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ipvs">3.1.2 加载 ipvs 内核模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="#docker-k8s">3.1.3 下载 Docker 和 K8S</a></li>
<li class="toctree-l3"><a class="reference internal" href="#k8s">3.1.4 设置内核及 K8S 参数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#master">3.2 部署 Master</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id10">3.2.1 提前拉取镜像</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">3.2.2 初始化Master</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#node">3.3 部署 Node</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id12">3.3.1 加入集群</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id13">3.3.2 查看进度</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">3.3.3 镜像下载太慢</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id15">四 入门命令</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#kubectl">4.1 kubectl</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run">4.2 run</a></li>
<li class="toctree-l2"><a class="reference internal" href="#expose">4.3 expose</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cp">4.4 cp</a></li>
<li class="toctree-l2"><a class="reference internal" href="#port-forward">4.5 port-forward</a></li>
<li class="toctree-l2"><a class="reference internal" href="#coredns">4.6 coredns</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pod">4.7 模拟 POD 被删除</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id16">4.8 模拟 service 被删除</a></li>
<li class="toctree-l2"><a class="reference internal" href="#labels">4.9 labels</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id17">4.10 动态扩容</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id18">4.11 滚动升级</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id19">4.12 集群外访问</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id20">4.13 排查日志</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id21">4.14 连入 POD 容器</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id22">五 配置清单使用</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id23">5.1 可配置的对象</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id24">5.2 配置清单组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id25">5.3 获取清单帮助</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id26">5.4 清单基本格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id27">5.5 快捷获取清单</a></li>
<li class="toctree-l2"><a class="reference internal" href="#create">5.6 create 创建</a></li>
<li class="toctree-l2"><a class="reference internal" href="#delete">5.7 delete 删除</a></li>
<li class="toctree-l2"><a class="reference internal" href="#apply">5.8 apply 创建或更新</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id28">六 POD 配置清单</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pods-metadata-pod">6.1 pods.metadata POD元数据</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id29">6.1.1 labels 标签</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pods-spec">6.2 pods.spec 规范</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#nodename">6.2.1 nodeName 运行节点</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nodeselector">6.2.2 nodeSelector 节点选择</a></li>
<li class="toctree-l3"><a class="reference internal" href="#restartpolicy-pod">6.2.3 restartPolicy POD重启策略</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hostnetwork">6.2.4 hostNetwork 主机网络空间</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hostpid-pid">6.2.5 hostPID 主机PID空间</a></li>
<li class="toctree-l3"><a class="reference internal" href="#containers">6.2.6 containers 配置</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#imagepullpolicy">6.2.6.1 imagePullPolicy下载策略</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ports">6.2.6.2 ports 端口信息</a></li>
<li class="toctree-l4"><a class="reference internal" href="#env">6.2.6.3 env 传递环境变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="#command-entrypoint">6.2.6.4 command ENTRYPOINT</a></li>
<li class="toctree-l4"><a class="reference internal" href="#args-cmd">6.2.6.5 args CMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="#annotations">6.2.6.6 annotations 注解信息</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id30">6.2.6.7 POD 生命周期</a></li>
<li class="toctree-l4"><a class="reference internal" href="#livenessprobe">6.2.6.8 livenessProbe 存活性探测</a></li>
<li class="toctree-l4"><a class="reference internal" href="#readinessprobe">6.2.6.9 readinessProbe 就绪性检测</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lifecycle">6.2.6.10 lifecycle 生命周期钩子</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id31">七 控制器配置清单</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#replicaset">7.1 ReplicaSet 控制器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#replicaset-spec">7.1.1 replicaset.spec 规范</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id32">7.1.2 清单示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deployment">7.2 Deployment控制器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id33">7.2.1 replicaset.spec 对象规范</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id34">7.2.2 清单示例</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id36">7.2.3 关于更新</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id37">7.2.4 模拟金丝雀发布</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id38">7.2.5 更新策略</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id39">7.2.6 关于回滚</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#daemonset">7.3 DaemonSet控制器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#daemonset-spec">7.3.1 DaemonSet.spec规范</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id40">7.3.2 清单示例</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id42">7.3.3 关于更新</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id44">八 Service 配置清单</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id45">8.1 Service 工作模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id46">8.2 Service 类型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id47">8.3 资源记录</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id48">8.4 Service 清单</a></li>
<li class="toctree-l2"><a class="reference internal" href="#service-spec">8.5 service.spec 规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clusterip-service">8.6 ClusterIP 类型的 service</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nodeport-service">8.7 NodePort 类型的 service</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loadbalancerip">8.8 loadBalancerIP 类型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id49">8.9 无集群地址的 Service</a></li>
<li class="toctree-l2"><a class="reference internal" href="#externalname">8.10 externalName 类型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#ingress">九 ingress 控制器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ingress-spec">9.1 ingress.spec 规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ingress-nginx">9.2 ingress-nginx 代理</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ingress-tomcat">9.3 ingress-tomcat 代理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id50">十 POD 存储卷</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id51">10.1 卷的类型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id52">10.2 容器挂载选项</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id53">10.3 节点存储</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hostpath">10.3.1 hostpath存储卷</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gitrepo">10.3.2 gitRepo卷</a></li>
<li class="toctree-l3"><a class="reference internal" href="#emptydir">10.3.3 emptyDir缓存卷</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id54">10.4 网络存储</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#nfs">10.4.1 nfs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id55">10.5 分布式存储</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#persistentvolume">10.5.1 PersistentVolume</a></li>
<li class="toctree-l3"><a class="reference internal" href="#persistentvolumeclaim">10.5.2. PersistentVolumeClaim</a></li>
<li class="toctree-l3"><a class="reference internal" href="#storageclass">10.5.3 StorageClass</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#storageclass-ceph-rbd">10.6 StorageClass Ceph RBD</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ceph">10.6.1 配置 Ceph 储存池</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rbd-provisioner">10.6.2 安装 rbd-provisioner</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id56">10.6.3 使用 StorageClass</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id57">十一 配置信息容器化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id58">11.1 POD 获取环境变量</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configmap">11.2 configMap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pod-env">11.2.1 注入 POD ENV</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id59">11.2.2 挂载为 POD 卷</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#secret">11.3 secret</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id60">11.3.1 私有仓库认证1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id61">11.3.2 私有仓库认证2</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tls">11.3.3 创建 TLS 证书</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#statefulset">十二 StatefulSet 控制器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id62">12.1 清单格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nfs-pv">12.2 创建 NFS PV</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id63">12.3 创建 statefulSet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id64">12.4 扩容和升级</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id65">十三 用户认证系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id66">13.1 用户的类型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id67">13.2 POD如何连接集群</a></li>
<li class="toctree-l2"><a class="reference internal" href="#serviceaccount">13.3 serviceaccount 对象</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pod-serviceaccount">13.3.1 在 POD 中使用 serviceaccount</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id68">13.4 kubectl 配置文件</a></li>
<li class="toctree-l2"><a class="reference internal" href="#config">13.5 添加证书用户到 config</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ssl">13.5.1 创建SSL证书用户</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sslconfig">13.5.2 添加SSL证书用户到config</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id69">13.5.3 创建切换上下文</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id70">13.6 创建新 config 文件</a></li>
<li class="toctree-l2"><a class="reference internal" href="#token">13.7 基于 token 认证</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id71">13.7.1 创建 serviceaccount</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id72">13.7.2 绑定集群管理员角色</a></li>
<li class="toctree-l3"><a class="reference internal" href="#serviceaccount-token">13.7.3 通过 serviceaccount 得到 Token</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id73">十四 用户权限系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id74">14.1 权限列表</a></li>
<li class="toctree-l2"><a class="reference internal" href="#role">14.2 创建 Role</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rolebinding">14.3 创建 rolebinding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clusterrole">14.4 创建 clusterrole</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clusterrolebinding">14.5 创建 clusterrolebinding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rolebinding-clusterrole">14.6 rolebinding 与 clusterrole</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rbac">14.7 RBAC授权</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#dashboard">十五 dashboard</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id75">15.1 部署流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id76">15.2 使用令牌登录</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id77">15.3 分级管理</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id78">15.4 配置文件认证</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id79">十六 网络通信</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id80">16.1 通信模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id81">16.2 通信模型底层</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id82">16.3 K8S 名称空间</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id83">16.4 K8S网络拓扑</a></li>
<li class="toctree-l2"><a class="reference internal" href="#flannel">16.5 flannel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id84">16.5.1 flannel 工作模式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#vxlan">16.5.2 VXLAN 通信过程</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id85">16.5.3 flannel 部署方式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id86">16.5.4flannel 配置文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id87">16.5.5 修改工作模式</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#calico">16.6 Calico</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#canal">16.6.1 安装 canal</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id88">16.6.2 清单定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="#policytypes">16.6.3 policyTypes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id89">十七 调度策略</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id90">17.1 POD创建流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id91">17.2 Service创建过程</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id92">17.3 资源限制维度</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scheduler">17.4 Scheduler 调度过程</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id93">17.4 预选因素</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id94">17.5 优选函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id95">17.6 选择函数</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id96">十八 高级调度设置</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id97">18.1 节点选择器</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id98">18.2 对节点的亲和性</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id99">18.3 对 POD 的亲和性</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id100">18.4 对 POD 的反亲和性</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id101">18.5 node 污点</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id102">18.6 POD 污点容忍</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id103">十九 容器资源限制</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id104">19.1 资源限制</a></li>
<li class="toctree-l2"><a class="reference internal" href="#qos">19.2 qos 质量管理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#heapster">二十 HeapSter监控（废弃中）</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#influx-db">20.1 安装 influx DB</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id105">20.2 安装 HeapSter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#grafana">20.3 安装 Grafana</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id106">二十一 新一代监控架构</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id107">21.1 核心指标流水线</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id108">21.2监控流水线</a></li>
<li class="toctree-l2"><a class="reference internal" href="#metrics-server">21.3 安装 metrics-server</a></li>
<li class="toctree-l2"><a class="reference internal" href="#prometheus">21.4 安装 prometheus</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hpa">21.5 HPA命令行方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id109">21.6 HPA清单</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id110">二十二 K8S包管理器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id111">22.1 基础概念</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helm">22.2 Helm 工作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id112">22.3 部署 Helm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chart">22.4 Chart文件组织</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helm-ceph-efk">22.5 使用 Helm + Ceph 部署 EFK</a></li>
<li class="toctree-l2"><a class="reference internal" href="#storage-class">22.6 Storage Class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helm-elasticsearch">22.7 Helm Elasticsearch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helm-fluentd-elasticsearch">22.8 Helm fluentd-elasticsearch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helm-kibana">22.9 Helm kibana</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#id113">二十三 ETCD详解</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id114">23.1 ETCD概述</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id115">23.1.1 ETCD简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id116">23.1.2 发展历史</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id117">23.1.3 ETCD特点</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id118">23.1.4 概念术语</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id119">23.1.5 相关原理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id120">23.1.5.1 数据读写顺序</a></li>
<li class="toctree-l4"><a class="reference internal" href="#leader">23.1.5.2 leader选举</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id121">23.1.5.3 判断数据是否写入</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id122">23.2 ETCD架构及解析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id123">23.2.1 架构图</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id124">23.2.2 架构解析</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id125">23.3 应用场景</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id126">23.3.1 服务注册发现</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id127">23.3.2 消息发布与订阅</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id128">23.3.3 负载均衡</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id129">23.3.4 分布式通知与协调</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id130">23.3.5 分布式锁</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id131">23.3.6 分布式队列</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id132">23.3.7 集群及爱你与Leader选举</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id133">23.4 安装部署</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id134">23.4.1 单机安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id135">23.4.2 集群部署</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id136">23.4.2.1 主机信息</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hosts">23.4.2.2 HOSTS配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id137">23.4.2.3 ETCD安装</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id138">23.4.2.4 ETCD配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id139">23.4.2.5 查看集群状态</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id140">23.5 简单使用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id141">23.5.1 增加</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id142">23.5.2 删除</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id143">23.5.3 更新</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id144">23.5.4 查询</a></li>
<li class="toctree-l3"><a class="reference internal" href="#watch">23.5.5 watch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id145">23.5.6 备份</a></li>
<li class="toctree-l3"><a class="reference internal" href="#member">23.5.7 member</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id146">23.6 示例</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#kubesphere">二十四 国产容器管理平台KubeSphere实战排错</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id147">24.1 清理退出状态的容器</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id148">24.2 清理异常或被驱逐的 pod</a></li>
<li class="toctree-l2"><a class="reference internal" href="#docker">24.3 Docker 数据迁移</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id149">24.4 kubesphere 网络排错</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id150">24.5 kubesphere 应用路由异常</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jenkins-agent">24.6 Jenkins 的 Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#devops-mail">24.7 Devops 中 Mail的发送</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id151">24.8 kubesphere应用上传问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id152">24.8.1 文件上传413</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id153">24.8.2 大文件上传后端504</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id154">24.9 跨域问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id155">24.10 添加节点</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id156">24.10.1 ceph集群添加节点</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id157">24.10.2 node节点添加</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id158">24.11 K8s集群资源不均</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kubesphere-devops">24.12 kubesphere devops工程</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id159">24.13 kubesphere 应用安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id160">参考链接</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id161">视频</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id162">请我喝咖啡☕️</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">KaliArch's awesome-kubernetes-notes</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>一 Kubernetes概述</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/awesome-kubernetes-notes.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#kubernetes" id="id167">一 Kubernetes概述</a></p>
<ul>
<li><p><a class="reference internal" href="#id1" id="id168">1.1 容器编排工具</a></p></li>
<li><p><a class="reference internal" href="#id2" id="id169">1.2 kubernetes</a></p></li>
<li><p><a class="reference internal" href="#id3" id="id170">1.3 环境架构</a></p></li>
<li><p><a class="reference internal" href="#id4" id="id171">1.4 架构和组件</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id5" id="id172">二 核心组件/附件</a></p>
<ul>
<li><p><a class="reference internal" href="#controller" id="id173">2.1 Controller</a></p></li>
<li><p><a class="reference internal" href="#service" id="id174">2.2 Service</a></p></li>
<li><p><a class="reference internal" href="#id6" id="id175">2.3 网络模型</a></p></li>
<li><p><a class="reference internal" href="#kube-proxy" id="id176">2.4 kube-proxy</a></p></li>
<li><p><a class="reference internal" href="#etcd" id="id177">2.5 etcd</a></p></li>
<li><p><a class="reference internal" href="#flanel" id="id178">2.6 flanel</a></p></li>
<li><p><a class="reference internal" href="#id7" id="id179">知识小结</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id8" id="id180">三 集群部署</a></p>
<ul>
<li><p><a class="reference internal" href="#id9" id="id181">3.1 部署前准备</a></p>
<ul>
<li><p><a class="reference internal" href="#firewalld-selinux" id="id182">3.1.1 关闭 firewalld 和 selinux</a></p></li>
<li><p><a class="reference internal" href="#ipvs" id="id183">3.1.2 加载 ipvs 内核模块</a></p></li>
<li><p><a class="reference internal" href="#docker-k8s" id="id184">3.1.3 下载 Docker 和 K8S</a></p></li>
<li><p><a class="reference internal" href="#k8s" id="id185">3.1.4 设置内核及 K8S 参数</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#master" id="id186">3.2 部署 Master</a></p>
<ul>
<li><p><a class="reference internal" href="#id10" id="id187">3.2.1 提前拉取镜像</a></p></li>
<li><p><a class="reference internal" href="#id11" id="id188">3.2.2 初始化Master</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#node" id="id189">3.3 部署 Node</a></p>
<ul>
<li><p><a class="reference internal" href="#id12" id="id190">3.3.1 加入集群</a></p></li>
<li><p><a class="reference internal" href="#id13" id="id191">3.3.2 查看进度</a></p></li>
<li><p><a class="reference internal" href="#id14" id="id192">3.3.3 镜像下载太慢</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#id15" id="id193">四 入门命令</a></p>
<ul>
<li><p><a class="reference internal" href="#kubectl" id="id194">4.1 kubectl</a></p></li>
<li><p><a class="reference internal" href="#run" id="id195">4.2 run</a></p></li>
<li><p><a class="reference internal" href="#expose" id="id196">4.3 expose</a></p></li>
<li><p><a class="reference internal" href="#cp" id="id197">4.4 cp</a></p></li>
<li><p><a class="reference internal" href="#port-forward" id="id198">4.5 port-forward</a></p></li>
<li><p><a class="reference internal" href="#coredns" id="id199">4.6 coredns</a></p></li>
<li><p><a class="reference internal" href="#pod" id="id200">4.7 模拟 POD 被删除</a></p></li>
<li><p><a class="reference internal" href="#id16" id="id201">4.8 模拟 service 被删除</a></p></li>
<li><p><a class="reference internal" href="#labels" id="id202">4.9 labels</a></p></li>
<li><p><a class="reference internal" href="#id17" id="id203">4.10 动态扩容</a></p></li>
<li><p><a class="reference internal" href="#id18" id="id204">4.11 滚动升级</a></p></li>
<li><p><a class="reference internal" href="#id19" id="id205">4.12 集群外访问</a></p></li>
<li><p><a class="reference internal" href="#id20" id="id206">4.13 排查日志</a></p></li>
<li><p><a class="reference internal" href="#id21" id="id207">4.14 连入 POD 容器</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id22" id="id208">五 配置清单使用</a></p>
<ul>
<li><p><a class="reference internal" href="#id23" id="id209">5.1 可配置的对象</a></p></li>
<li><p><a class="reference internal" href="#id24" id="id210">5.2 配置清单组成</a></p></li>
<li><p><a class="reference internal" href="#id25" id="id211">5.3 获取清单帮助</a></p></li>
<li><p><a class="reference internal" href="#id26" id="id212">5.4 清单基本格式</a></p></li>
<li><p><a class="reference internal" href="#id27" id="id213">5.5 快捷获取清单</a></p></li>
<li><p><a class="reference internal" href="#create" id="id214">5.6 create 创建</a></p></li>
<li><p><a class="reference internal" href="#delete" id="id215">5.7 delete 删除</a></p></li>
<li><p><a class="reference internal" href="#apply" id="id216">5.8 apply 创建或更新</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id28" id="id217">六 POD 配置清单</a></p>
<ul>
<li><p><a class="reference internal" href="#pods-metadata-pod" id="id218">6.1 pods.metadata POD元数据</a></p>
<ul>
<li><p><a class="reference internal" href="#id29" id="id219">6.1.1 labels 标签</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#pods-spec" id="id220">6.2 pods.spec 规范</a></p>
<ul>
<li><p><a class="reference internal" href="#nodename" id="id221">6.2.1 nodeName 运行节点</a></p></li>
<li><p><a class="reference internal" href="#nodeselector" id="id222">6.2.2 nodeSelector 节点选择</a></p></li>
<li><p><a class="reference internal" href="#restartpolicy-pod" id="id223">6.2.3 restartPolicy POD重启策略</a></p></li>
<li><p><a class="reference internal" href="#hostnetwork" id="id224">6.2.4 hostNetwork 主机网络空间</a></p></li>
<li><p><a class="reference internal" href="#hostpid-pid" id="id225">6.2.5 hostPID 主机PID空间</a></p></li>
<li><p><a class="reference internal" href="#containers" id="id226">6.2.6 containers 配置</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#id31" id="id227">七 控制器配置清单</a></p>
<ul>
<li><p><a class="reference internal" href="#replicaset" id="id228">7.1 ReplicaSet 控制器</a></p>
<ul>
<li><p><a class="reference internal" href="#replicaset-spec" id="id229">7.1.1 replicaset.spec 规范</a></p></li>
<li><p><a class="reference internal" href="#id32" id="id230">7.1.2 清单示例</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#deployment" id="id231">7.2 Deployment控制器</a></p>
<ul>
<li><p><a class="reference internal" href="#id33" id="id232">7.2.1 replicaset.spec 对象规范</a></p></li>
<li><p><a class="reference internal" href="#id34" id="id233">7.2.2 清单示例</a></p></li>
<li><p><a class="reference internal" href="#id36" id="id234">7.2.3 关于更新</a></p></li>
<li><p><a class="reference internal" href="#id37" id="id235">7.2.4 模拟金丝雀发布</a></p></li>
<li><p><a class="reference internal" href="#id38" id="id236">7.2.5 更新策略</a></p></li>
<li><p><a class="reference internal" href="#id39" id="id237">7.2.6 关于回滚</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#daemonset" id="id238">7.3 DaemonSet控制器</a></p>
<ul>
<li><p><a class="reference internal" href="#daemonset-spec" id="id239">7.3.1 DaemonSet.spec规范</a></p></li>
<li><p><a class="reference internal" href="#id40" id="id240">7.3.2 清单示例</a></p></li>
<li><p><a class="reference internal" href="#id42" id="id241">7.3.3 关于更新</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#id44" id="id242">八 Service 配置清单</a></p>
<ul>
<li><p><a class="reference internal" href="#id45" id="id243">8.1 Service 工作模式</a></p></li>
<li><p><a class="reference internal" href="#id46" id="id244">8.2 Service 类型</a></p></li>
<li><p><a class="reference internal" href="#id47" id="id245">8.3 资源记录</a></p></li>
<li><p><a class="reference internal" href="#id48" id="id246">8.4 Service 清单</a></p></li>
<li><p><a class="reference internal" href="#service-spec" id="id247">8.5 service.spec 规范</a></p></li>
<li><p><a class="reference internal" href="#clusterip-service" id="id248">8.6 ClusterIP 类型的 service</a></p></li>
<li><p><a class="reference internal" href="#nodeport-service" id="id249">8.7 NodePort 类型的 service</a></p></li>
<li><p><a class="reference internal" href="#loadbalancerip" id="id250">8.8 loadBalancerIP 类型</a></p></li>
<li><p><a class="reference internal" href="#id49" id="id251">8.9 无集群地址的 Service</a></p></li>
<li><p><a class="reference internal" href="#externalname" id="id252">8.10 externalName 类型</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#ingress" id="id253">九 ingress 控制器</a></p>
<ul>
<li><p><a class="reference internal" href="#ingress-spec" id="id254">9.1 ingress.spec 规范</a></p></li>
<li><p><a class="reference internal" href="#ingress-nginx" id="id255">9.2 ingress-nginx 代理</a></p></li>
<li><p><a class="reference internal" href="#ingress-tomcat" id="id256">9.3 ingress-tomcat 代理</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id50" id="id257">十 POD 存储卷</a></p>
<ul>
<li><p><a class="reference internal" href="#id51" id="id258">10.1 卷的类型</a></p></li>
<li><p><a class="reference internal" href="#id52" id="id259">10.2 容器挂载选项</a></p></li>
<li><p><a class="reference internal" href="#id53" id="id260">10.3 节点存储</a></p>
<ul>
<li><p><a class="reference internal" href="#hostpath" id="id261">10.3.1 hostpath存储卷</a></p></li>
<li><p><a class="reference internal" href="#gitrepo" id="id262">10.3.2 gitRepo卷</a></p></li>
<li><p><a class="reference internal" href="#emptydir" id="id263">10.3.3 emptyDir缓存卷</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id54" id="id264">10.4 网络存储</a></p>
<ul>
<li><p><a class="reference internal" href="#nfs" id="id265">10.4.1 nfs</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id55" id="id266">10.5 分布式存储</a></p>
<ul>
<li><p><a class="reference internal" href="#persistentvolume" id="id267">10.5.1 PersistentVolume</a></p></li>
<li><p><a class="reference internal" href="#persistentvolumeclaim" id="id268">10.5.2. PersistentVolumeClaim</a></p></li>
<li><p><a class="reference internal" href="#storageclass" id="id269">10.5.3 StorageClass</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#storageclass-ceph-rbd" id="id270">10.6 StorageClass Ceph RBD</a></p>
<ul>
<li><p><a class="reference internal" href="#ceph" id="id271">10.6.1 配置 Ceph 储存池</a></p></li>
<li><p><a class="reference internal" href="#rbd-provisioner" id="id272">10.6.2 安装 rbd-provisioner</a></p></li>
<li><p><a class="reference internal" href="#id56" id="id273">10.6.3 使用 StorageClass</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#id57" id="id274">十一 配置信息容器化</a></p>
<ul>
<li><p><a class="reference internal" href="#id58" id="id275">11.1 POD 获取环境变量</a></p></li>
<li><p><a class="reference internal" href="#configmap" id="id276">11.2 configMap</a></p>
<ul>
<li><p><a class="reference internal" href="#pod-env" id="id277">11.2.1 注入 POD ENV</a></p></li>
<li><p><a class="reference internal" href="#id59" id="id278">11.2.2 挂载为 POD 卷</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#secret" id="id279">11.3 secret</a></p>
<ul>
<li><p><a class="reference internal" href="#id60" id="id280">11.3.1 私有仓库认证1</a></p></li>
<li><p><a class="reference internal" href="#id61" id="id281">11.3.2 私有仓库认证2</a></p></li>
<li><p><a class="reference internal" href="#tls" id="id282">11.3.3 创建 TLS 证书</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#statefulset" id="id283">十二 StatefulSet 控制器</a></p>
<ul>
<li><p><a class="reference internal" href="#id62" id="id284">12.1 清单格式</a></p></li>
<li><p><a class="reference internal" href="#nfs-pv" id="id285">12.2 创建 NFS PV</a></p></li>
<li><p><a class="reference internal" href="#id63" id="id286">12.3 创建 statefulSet</a></p></li>
<li><p><a class="reference internal" href="#id64" id="id287">12.4 扩容和升级</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id65" id="id288">十三 用户认证系统</a></p>
<ul>
<li><p><a class="reference internal" href="#id66" id="id289">13.1 用户的类型</a></p></li>
<li><p><a class="reference internal" href="#id67" id="id290">13.2 POD如何连接集群</a></p></li>
<li><p><a class="reference internal" href="#serviceaccount" id="id291">13.3 serviceaccount 对象</a></p>
<ul>
<li><p><a class="reference internal" href="#pod-serviceaccount" id="id292">13.3.1 在 POD 中使用 serviceaccount</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id68" id="id293">13.4 kubectl 配置文件</a></p></li>
<li><p><a class="reference internal" href="#config" id="id294">13.5 添加证书用户到 config</a></p>
<ul>
<li><p><a class="reference internal" href="#ssl" id="id295">13.5.1 创建SSL证书用户</a></p></li>
<li><p><a class="reference internal" href="#sslconfig" id="id296">13.5.2 添加SSL证书用户到config</a></p></li>
<li><p><a class="reference internal" href="#id69" id="id297">13.5.3 创建切换上下文</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id70" id="id298">13.6 创建新 config 文件</a></p></li>
<li><p><a class="reference internal" href="#token" id="id299">13.7 基于 token 认证</a></p>
<ul>
<li><p><a class="reference internal" href="#id71" id="id300">13.7.1 创建 serviceaccount</a></p></li>
<li><p><a class="reference internal" href="#id72" id="id301">13.7.2 绑定集群管理员角色</a></p></li>
<li><p><a class="reference internal" href="#serviceaccount-token" id="id302">13.7.3 通过 serviceaccount 得到 Token</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#id73" id="id303">十四 用户权限系统</a></p>
<ul>
<li><p><a class="reference internal" href="#id74" id="id304">14.1 权限列表</a></p></li>
<li><p><a class="reference internal" href="#role" id="id305">14.2 创建 Role</a></p></li>
<li><p><a class="reference internal" href="#rolebinding" id="id306">14.3 创建 rolebinding</a></p></li>
<li><p><a class="reference internal" href="#clusterrole" id="id307">14.4 创建 clusterrole</a></p></li>
<li><p><a class="reference internal" href="#clusterrolebinding" id="id308">14.5 创建 clusterrolebinding</a></p></li>
<li><p><a class="reference internal" href="#rolebinding-clusterrole" id="id309">14.6 rolebinding 与 clusterrole</a></p></li>
<li><p><a class="reference internal" href="#rbac" id="id310">14.7 RBAC授权</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#dashboard" id="id311">十五 dashboard</a></p>
<ul>
<li><p><a class="reference internal" href="#id75" id="id312">15.1 部署流程</a></p></li>
<li><p><a class="reference internal" href="#id76" id="id313">15.2 使用令牌登录</a></p></li>
<li><p><a class="reference internal" href="#id77" id="id314">15.3 分级管理</a></p></li>
<li><p><a class="reference internal" href="#id78" id="id315">15.4 配置文件认证</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id79" id="id316">十六 网络通信</a></p>
<ul>
<li><p><a class="reference internal" href="#id80" id="id317">16.1 通信模型</a></p></li>
<li><p><a class="reference internal" href="#id81" id="id318">16.2 通信模型底层</a></p></li>
<li><p><a class="reference internal" href="#id82" id="id319">16.3 K8S 名称空间</a></p></li>
<li><p><a class="reference internal" href="#id83" id="id320">16.4 K8S网络拓扑</a></p></li>
<li><p><a class="reference internal" href="#flannel" id="id321">16.5 flannel</a></p>
<ul>
<li><p><a class="reference internal" href="#id84" id="id322">16.5.1 flannel 工作模式</a></p></li>
<li><p><a class="reference internal" href="#vxlan" id="id323">16.5.2 VXLAN 通信过程</a></p></li>
<li><p><a class="reference internal" href="#id85" id="id324">16.5.3 flannel 部署方式</a></p></li>
<li><p><a class="reference internal" href="#id86" id="id325">16.5.4flannel 配置文件</a></p></li>
<li><p><a class="reference internal" href="#id87" id="id326">16.5.5 修改工作模式</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#calico" id="id327">16.6 Calico</a></p>
<ul>
<li><p><a class="reference internal" href="#canal" id="id328">16.6.1 安装 canal</a></p></li>
<li><p><a class="reference internal" href="#id88" id="id329">16.6.2 清单定义</a></p></li>
<li><p><a class="reference internal" href="#policytypes" id="id330">16.6.3 policyTypes</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#id89" id="id331">十七 调度策略</a></p>
<ul>
<li><p><a class="reference internal" href="#id90" id="id332">17.1 POD创建流程</a></p></li>
<li><p><a class="reference internal" href="#id91" id="id333">17.2 Service创建过程</a></p></li>
<li><p><a class="reference internal" href="#id92" id="id334">17.3 资源限制维度</a></p></li>
<li><p><a class="reference internal" href="#scheduler" id="id335">17.4 Scheduler 调度过程</a></p></li>
<li><p><a class="reference internal" href="#id93" id="id336">17.4 预选因素</a></p></li>
<li><p><a class="reference internal" href="#id94" id="id337">17.5 优选函数</a></p></li>
<li><p><a class="reference internal" href="#id95" id="id338">17.6 选择函数</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id96" id="id339">十八 高级调度设置</a></p>
<ul>
<li><p><a class="reference internal" href="#id97" id="id340">18.1 节点选择器</a></p></li>
<li><p><a class="reference internal" href="#id98" id="id341">18.2 对节点的亲和性</a></p></li>
<li><p><a class="reference internal" href="#id99" id="id342">18.3 对 POD 的亲和性</a></p></li>
<li><p><a class="reference internal" href="#id100" id="id343">18.4 对 POD 的反亲和性</a></p></li>
<li><p><a class="reference internal" href="#id101" id="id344">18.5 node 污点</a></p></li>
<li><p><a class="reference internal" href="#id102" id="id345">18.6 POD 污点容忍</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id103" id="id346">十九 容器资源限制</a></p>
<ul>
<li><p><a class="reference internal" href="#id104" id="id347">19.1 资源限制</a></p></li>
<li><p><a class="reference internal" href="#qos" id="id348">19.2 qos 质量管理</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#heapster" id="id349">二十 HeapSter监控（废弃中）</a></p>
<ul>
<li><p><a class="reference internal" href="#influx-db" id="id350">20.1 安装 influx DB</a></p></li>
<li><p><a class="reference internal" href="#id105" id="id351">20.2 安装 HeapSter</a></p></li>
<li><p><a class="reference internal" href="#grafana" id="id352">20.3 安装 Grafana</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id106" id="id353">二十一 新一代监控架构</a></p>
<ul>
<li><p><a class="reference internal" href="#id107" id="id354">21.1 核心指标流水线</a></p></li>
<li><p><a class="reference internal" href="#id108" id="id355">21.2监控流水线</a></p></li>
<li><p><a class="reference internal" href="#metrics-server" id="id356">21.3 安装 metrics-server</a></p></li>
<li><p><a class="reference internal" href="#prometheus" id="id357">21.4 安装 prometheus</a></p></li>
<li><p><a class="reference internal" href="#hpa" id="id358">21.5 HPA命令行方式</a></p></li>
<li><p><a class="reference internal" href="#id109" id="id359">21.6 HPA清单</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id110" id="id360">二十二 K8S包管理器</a></p>
<ul>
<li><p><a class="reference internal" href="#id111" id="id361">22.1 基础概念</a></p></li>
<li><p><a class="reference internal" href="#helm" id="id362">22.2 Helm 工作原理</a></p></li>
<li><p><a class="reference internal" href="#id112" id="id363">22.3 部署 Helm</a></p></li>
<li><p><a class="reference internal" href="#chart" id="id364">22.4 Chart文件组织</a></p></li>
<li><p><a class="reference internal" href="#helm-ceph-efk" id="id365">22.5 使用 Helm + Ceph 部署 EFK</a></p></li>
<li><p><a class="reference internal" href="#storage-class" id="id366">22.6 Storage Class</a></p></li>
<li><p><a class="reference internal" href="#helm-elasticsearch" id="id367">22.7 Helm Elasticsearch</a></p></li>
<li><p><a class="reference internal" href="#helm-fluentd-elasticsearch" id="id368">22.8 Helm fluentd-elasticsearch</a></p></li>
<li><p><a class="reference internal" href="#helm-kibana" id="id369">22.9 Helm kibana</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id113" id="id370">二十三 ETCD详解</a></p>
<ul>
<li><p><a class="reference internal" href="#id114" id="id371">23.1 ETCD概述</a></p>
<ul>
<li><p><a class="reference internal" href="#id115" id="id372">23.1.1 ETCD简介</a></p></li>
<li><p><a class="reference internal" href="#id116" id="id373">23.1.2 发展历史</a></p></li>
<li><p><a class="reference internal" href="#id117" id="id374">23.1.3 ETCD特点</a></p></li>
<li><p><a class="reference internal" href="#id118" id="id375">23.1.4 概念术语</a></p></li>
<li><p><a class="reference internal" href="#id119" id="id376">23.1.5 相关原理</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id122" id="id377">23.2 ETCD架构及解析</a></p>
<ul>
<li><p><a class="reference internal" href="#id123" id="id378">23.2.1 架构图</a></p></li>
<li><p><a class="reference internal" href="#id124" id="id379">23.2.2 架构解析</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id125" id="id380">23.3 应用场景</a></p>
<ul>
<li><p><a class="reference internal" href="#id126" id="id381">23.3.1 服务注册发现</a></p></li>
<li><p><a class="reference internal" href="#id127" id="id382">23.3.2 消息发布与订阅</a></p></li>
<li><p><a class="reference internal" href="#id128" id="id383">23.3.3 负载均衡</a></p></li>
<li><p><a class="reference internal" href="#id129" id="id384">23.3.4 分布式通知与协调</a></p></li>
<li><p><a class="reference internal" href="#id130" id="id385">23.3.5 分布式锁</a></p></li>
<li><p><a class="reference internal" href="#id131" id="id386">23.3.6 分布式队列</a></p></li>
<li><p><a class="reference internal" href="#id132" id="id387">23.3.7 集群及爱你与Leader选举</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id133" id="id388">23.4 安装部署</a></p>
<ul>
<li><p><a class="reference internal" href="#id134" id="id389">23.4.1 单机安装</a></p></li>
<li><p><a class="reference internal" href="#id135" id="id390">23.4.2 集群部署</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id140" id="id391">23.5 简单使用</a></p>
<ul>
<li><p><a class="reference internal" href="#id141" id="id392">23.5.1 增加</a></p></li>
<li><p><a class="reference internal" href="#id142" id="id393">23.5.2 删除</a></p></li>
<li><p><a class="reference internal" href="#id143" id="id394">23.5.3 更新</a></p></li>
<li><p><a class="reference internal" href="#id144" id="id395">23.5.4 查询</a></p></li>
<li><p><a class="reference internal" href="#watch" id="id396">23.5.5 watch</a></p></li>
<li><p><a class="reference internal" href="#id145" id="id397">23.5.6 备份</a></p></li>
<li><p><a class="reference internal" href="#member" id="id398">23.5.7 member</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id146" id="id399">23.6 示例</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#kubesphere" id="id400">二十四 国产容器管理平台KubeSphere实战排错</a></p>
<ul>
<li><p><a class="reference internal" href="#id147" id="id401">24.1 清理退出状态的容器</a></p></li>
<li><p><a class="reference internal" href="#id148" id="id402">24.2 清理异常或被驱逐的 pod</a></p></li>
<li><p><a class="reference internal" href="#docker" id="id403">24.3 Docker 数据迁移</a></p></li>
<li><p><a class="reference internal" href="#id149" id="id404">24.4 kubesphere 网络排错</a></p></li>
<li><p><a class="reference internal" href="#id150" id="id405">24.5 kubesphere 应用路由异常</a></p></li>
<li><p><a class="reference internal" href="#jenkins-agent" id="id406">24.6 Jenkins 的 Agent</a></p></li>
<li><p><a class="reference internal" href="#devops-mail" id="id407">24.7 Devops 中 Mail的发送</a></p></li>
<li><p><a class="reference internal" href="#id151" id="id408">24.8 kubesphere应用上传问题</a></p>
<ul>
<li><p><a class="reference internal" href="#id152" id="id409">24.8.1 文件上传413</a></p></li>
<li><p><a class="reference internal" href="#id153" id="id410">24.8.2 大文件上传后端504</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id154" id="id411">24.9 跨域问题</a></p></li>
<li><p><a class="reference internal" href="#id155" id="id412">24.10 添加节点</a></p>
<ul>
<li><p><a class="reference internal" href="#id156" id="id413">24.10.1 ceph集群添加节点</a></p></li>
<li><p><a class="reference internal" href="#id157" id="id414">24.10.2 node节点添加</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id158" id="id415">24.11 K8s集群资源不均</a></p></li>
<li><p><a class="reference internal" href="#kubesphere-devops" id="id416">24.12 kubesphere devops工程</a></p></li>
<li><p><a class="reference internal" href="#id159" id="id417">24.13 kubesphere 应用安装</a></p></li>
<li><p><a class="reference internal" href="#id160" id="id418">参考链接</a></p>
<ul>
<li><p><a class="reference internal" href="#id161" id="id419">视频</a></p></li>
<li><p><a class="reference internal" href="#id162" id="id420">请我喝咖啡☕️</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<p>[TOC]</p>
<div class="section" id="kubernetes">
<h1><a class="toc-backref" href="#id167">一 Kubernetes概述</a><a class="headerlink" href="#kubernetes" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2><a class="toc-backref" href="#id168">1.1 容器编排工具</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>docker 官方编排工具</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">compose</span>    <span class="c1"># 单机编排工具</span>
<span class="n">docker</span> <span class="n">swarm</span>      <span class="c1"># 将多台 docker 提供的计算资源整合的接口，随后 docker compose 编排的时候只需要面向这个整合的接口进行编排就行，无论接口下有多少个主机。</span>
<span class="n">docker</span> <span class="n">mechine</span>    <span class="c1"># 将一个主机初始化为一个能够加入 docker swarm 集群中的预置程序</span>
</pre></div>
</div>
<ul class="simple">
<li><p>mesos IDC 操作系统</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>IDC 操作系统，能将一个 IDC 提供的硬件资源，统一调度和分配，它只是一个资源分配工具，非能够直接托管容器的，所以它提供了以个能够直接编排框架，marathon。
</pre></div>
</div>
<ul class="simple">
<li><p>kubernetes</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>目前最流行的容器编排工具,市场占有率最高
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2><a class="toc-backref" href="#id169">1.2 kubernetes</a><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>kubernetes 是希腊语，翻译过来是：舵手的意思，它的原型是谷歌内部使用 Borg
集群管理系统，可以说是集结了 Borg 设计思想的精华，并且吸收了 Borg
系统中的经验和教训。</p>
<p>它的目标不仅仅是一个编排系统，而是提供一个规范，可以让你来描述集群的架构，定义服务的最终状态，Kubernetes可以帮你将系统自动地达到和维持在这个状态。Kubernetes作为云原生应用的基石，相当于一个云操作系统，其重要性不言而喻。</p>
<p>kubernetes 在 2014 年发布了第一个版本，目前开源并托管在 Github 上。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>https://github.com/Kubernetes
</pre></div>
</div>
<p>目前，AWS、阿里云、微软云，目前已经原生支持 K8S
，目前已经可以让用户直接部署云原生的服务。</p>
<ul class="simple">
<li><p>有什么优势</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 基于 Borg 系统，设计成熟，开源、且轻量级，简单易学、容易理解；
- 模块化，可插拔，支持钩子，可任意组合，例如：网络组件 flannel，存储插件；
- 故障发现（存活性探针）和自我修复能力（副本数量）、服务滚动升级（就绪探针）和在线扩容（副本数量）密钥和配置管理；
- 可扩展的资源自动调度机制（多维度的水平自动扩容）、多粒度的资源配额管理能力（资源限制）。
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h2><a class="toc-backref" href="#id170">1.3 环境架构</a><a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>Kubernetes
是一个集群，整合多台计算机的计算能力，它是一种有中心节点模式的集群，在
K8S 集群中主机分为两种角色：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Master：集群的管理节点，有一个或者一组节点，一般 3 个足够了。
nodes：提供计算资源的节点，就是运行容器的节点，可以扩展。
</pre></div>
</div>
<p>客户端创建启动容器的请求交给 Master ，Master
上有一个<strong>调度器</strong>它能分析各 nodes
节点上的资源状态，找一个最适合运行用户容器的节点，并在这个节点上使用
Docker 启动这个容器，node 节点的 Docker
在启动容器时候会首先检查本地有没有镜像，如果没有就从仓库中 pull
然后运行。</p>
<p>那么仓库可以运行为容器，所以也可以托管在 Kubernetes 之上，其实
Kubernetes 可以托管自身，即自托管。</p>
<ul class="simple">
<li><p>ApiServer</p></li>
</ul>
<p>kubernetes 接收用户创建容器等请求的是 Kubernetes
Cluster，那么它对外提供服务的接口就是一个 API 接口
，这个接口需要编程来访问，或者通过编写好的客户端程序来访问，Kubernetes
Master 上有一个组件就是
ApiServer，来接收客端请求，解析客户端请求，其主要功能包括认证授权、数据校验以及集群状态变更，以及负责其他模块直接的相互通讯和数据交互，只有api
server才能操作etcd，其他模块想要获取数据需要通过api
server提供的接口进行相关数据操作</p>
<ul class="simple">
<li><p>Scheduler</p></li>
</ul>
<p>scheduler watch
apiserver，接受系统或用户请求是运行，如何要运行一个pod，那么 Master
会使用调度器（scheduler）根据请求来分配一个能够运行容器的 nodes
节点，例如：根据用户对资源要求，CPU、内存、来评估哪个 nodes 最合适运行。</p>
<p>大概的过程就是：首先是预选，从 nodes
中挑选出符合用户容器运行要求的，然后在这些预选结果中进行优选，选出最佳的适配
node。</p>
<ul class="simple">
<li><p>Controller（控制器）</p></li>
</ul>
<p>如果运行容器的节点宕机或者容器本身运行出现问题，kubernetes
能够在其他节点再启动一个一模一样的容器，这就是 Kubernetes
提供的自愈能力。</p>
<p>控制器就实现了监控它所负责的每一个容器的健康状态，一旦发现不健康了，那么控制器会向
Master 发送请求，Master 会再次由调度器挑选出合适的节点再次运行这个容器。</p>
<p>它能持续性探测所管理的容器，一旦不健康，或不符合用户定义的健康状态，就会由它发起来请求，来保证容器向用户希望的健康状态迁徙。</p>
<p>而 Kubernets 支持众多的控制器，支持容器健康的控制器只是其中一种。</p>
<ul class="simple">
<li><p>ControllerManager（制器管理器）</p></li>
</ul>
<p>在 Master
内置组件中有一个控制器管理器，它负责监视着每一个控制器，如果控制器不健康无法工作，那么由控制器管理器来确保控制器的健康，由于
Master 有多个，所以具有冗余性。</p>
<ul class="simple">
<li><p>Pod（原子调度单元，是容器的封装）</p></li>
</ul>
<p>在 Kubernetes 上调度的原子单元，Kubernetes 不直接调度容器，而是
Pod，Pod可以理解为容器的二次封装，可以由一个或者多个容器组成，多个容器共享同一个网络名称空间：NET、UTS、IPC。</p>
<p>同一个 POD 里的容器，还能共享同一个存储卷，存储卷可以属于 POD。</p>
<p>一般一个 POD
只运行一个容器，如果需要在POD放多个容器，那么一般有一个主容器，其他容器是为主容器提供服务的。</p>
<ul class="simple">
<li><p>Node（工作节点）</p></li>
</ul>
<p>提供计算资源的节点，就是运行 Pod 的主机，Kubenetes Cluster
统一管理所有的 node
节点的计算资源，当用户请求创建资源的时候，可以检查目前集群还有没有资源可以运行用户的容器，这实现了统一调度统一管理的一个平台。</p>
<ul class="simple">
<li><p>Label（标签）</p></li>
</ul>
<p>一个由 <code class="docutils literal notranslate"><span class="pre">key</span> <span class="pre">=</span> <span class="pre">value</span></code> 组成的标签，可以为 POD 打上一个标签。</p>
<ul class="simple">
<li><p>Selecter（标签选择器）</p></li>
</ul>
<p>集群中运行的众多 POD ，前面提到一个控制器可以管理若干个 POD
，那么控制器如何从集群中运行的所有 POD 中挑选出来自己需要管理的 POD 呢?</p>
<p>在创建一个 POD 的时候为 POD
打上一个标签，让程序可以通过这个标签来识别出来这个POD，还可以用来区分一组相同功能的POD，例如：创建四个nginx
pod，可以给每个pod加一个 K/V类型的标签如：app=nginx，将来找出这四个
nginx pod，那么条件就是根据 拥有 key 为 app 的pod 并且 value 为 nginx
来挑出这组 POD。</p>
<p>标签不是 POD 唯一具有的机制，其他的组件同样可以有标签。</p>
</div>
<div class="section" id="id4">
<h2><a class="toc-backref" href="#id171">1.4 架构和组件</a><a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Etcd</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>用于 Kubernetes 的后端数据存储,所有集群数据都存储在此处
</pre></div>
</div>
<ul class="simple">
<li><p>Master 节点负责维护集群的目标状态，上面运行的主控组件有</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kube-apiserver                 <span class="c1"># 对外暴露了 Kubernetes API，它是的 Kubernetes 前端控制层，只有 API Server 会与 etcd 通信，其它模块都必须通过 API Server 访问集群状态</span>
kube-controller-manager        <span class="c1"># 处理集群中常规任务，它是单独的进程，内部包含多个控制器，例如维护 POD 数量</span>
kube-scheduler                 <span class="c1"># 监视新创建的 Pod 为新创建的 POD 分配合适的 node 节点</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Node 节点实际负责实施，也就是运行 POD 的节点，上面运行的组件有</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubelet                        <span class="c1"># 节点自注册和节点状态更新，它监测已经分配给自己的 Pod，为 POD 准备卷，下载 POD 所需的 Secret，下载镜像并运行，进行生命周期探测，上报 POD 和节点状态</span>
kube-proxy                     <span class="c1"># 通过维护主机上的网络规则并执行连接转发，将 Kubernetes 提供的网络服务代理到每个节点上，实现了Kubernetes服务抽象</span>
docker                         <span class="c1"># 用于运行容器</span>
</pre></div>
</div>
<ul class="simple">
<li><p>插件</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>插件是增强集群功能的 Pod 和 Service,插件对象本身是受命名空间限制的,被创建于 kube-system 命名空间.
</pre></div>
</div>
<ul class="simple">
<li><p>DNS</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>虽然其他插件并不是必需的,但所有 Kubernetes 集群都应该具有Cluster DNS,许多应用依赖于它,为 Kubernetes 服务提供DNS记录,容器启动该后会自动将 DNS 服务器包含在 resolv.conf 中.
</pre></div>
</div>
</div>
</div>
<div class="section" id="id5">
<h1><a class="toc-backref" href="#id172">二 核心组件/附件</a><a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h1>
<div class="section" id="controller">
<h2><a class="toc-backref" href="#id173">2.1 Controller</a><a class="headerlink" href="#controller" title="Permalink to this headline">¶</a></h2>
<p>这些控制器分别用于确保不同类型的 POD 资源运行于符合用户所期望的状态。</p>
<ul class="simple">
<li><p>RelicationController</p></li>
</ul>
<p>控制同一类 POD 对象的副本数量，实现程序的滚动更新，或者回滚的操作。</p>
<p>在滚动更新时候，允许临时超出规定的副本数量，</p>
<ul class="simple">
<li><p>RelicaSet</p></li>
</ul>
<p>副本集控制器，它不直接使用，它有一个声明式中心控制器 Deployment</p>
<ul class="simple">
<li><p>Deployment</p></li>
</ul>
<p>它只能管理无状态的应用，这个控制器，支持二级控制器，例如：HPA（Horizontal
Pod Autoscaler，水平 POD
自动伸缩控制器），当负载高的时候，自动启动更多的 POD。</p>
<ul class="simple">
<li><p>StatefulSet</p></li>
</ul>
<p>管理有状态的应用</p>
<ul class="simple">
<li><p>DaemonSet</p></li>
</ul>
<p>如果需要在每一个 node 上运行一个副本，而不是随意运行</p>
<ul class="simple">
<li><p>Job</p></li>
</ul>
<p>运行一次性作业，时间不固定的操作，例如：备份、清理，临时启动一个 POD
来进行备份的任务，运行完成就结束了。</p>
<p>如果运行时候 JOB
挂了，那么需要重新启动起来，如果运行完成了则不需要再启动了。</p>
<ul class="simple">
<li><p>Cronjob</p></li>
</ul>
<p>运行周期性作业</p>
</div>
<div class="section" id="service">
<h2><a class="toc-backref" href="#id174">2.2 Service</a><a class="headerlink" href="#service" title="Permalink to this headline">¶</a></h2>
<p>为客户端提供一个稳定的访问入口，Service 靠标签选择器来关联 POD 的，只要
POD 上有相关的标签，那么就会被 Service 选中，作为 Service
的后端，Service 关联 POD 后会动态探测这个 POD 的 IP
地址和端口，并作为自己调度的后端。</p>
<p>总的来说客户端请求 Service 由 Service 代理至后端的
POD，所以客户端看到的始终是 Service 的地址。</p>
<p>K8S 上的 Service 不是一个应用程序，也不是一个组件，它是一个 iptables
dnat 规则，或者 ipvs 规则，Service 只是规则，所以是 ping
不通的，由于是dnat规则或是ipvs规则，可以使用利用端口进行测试</p>
<p>Service 作为 k8s 的对象来说，是有名称的，可以通过 Service 的名称解析为
Service 的 IP 地址</p>
<p>一般格式: <code class="docutils literal notranslate"><span class="pre">svcname.namespace.svc.cluster.local</span></code>, 如果在同一个
namespace 中可以直接使用 svcname , 如果不在同一个 namespace 中,
需要写完整的FQDN域名。</p>
<ul class="simple">
<li><p>AddOns</p></li>
</ul>
<p>解析域名是由 DNS 来解析的，为 k8s
中提供域名解析这种基础服务，称之为基础架构 POD 也称为 k8s
附件，所以域名解析的 POD 就是 k8s 中的一种 AddOns。</p>
<p>而 k8s 中的 dns 附件，是动态的，例如：service 名称发生更改，就会自动触发
dns 中的解析记录的改变，如果手动修改 service 的地址，也会自动触发 DNS
解析记录的改变，所以客户端访问服务时，可以直接访问服务的名称。</p>
</div>
<div class="section" id="id6">
<h2><a class="toc-backref" href="#id175">2.3 网络模型</a><a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>k8s 有三种网络：POD网络、集群网络、节点网络</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>POD网络：所有 POD 处于同一个网络中，叠加网络
集群网络：Service 是一个另外一个网络
节点网络：node 节点也是另外一个网络，宿主机的内网网络
</pre></div>
</div>
<p>所以，接入外部访问时候，请求首先到达 node 网络，然后 node 网络代理至
service 网络，service 根据 iptables/ipvs 规则来转发到 pod 网络中的 pod
上。 ~~~ NODE 网络 -&gt; SVC 网络 -&gt; POD 网络 ~~~</p>
<p>k8s 有三种通信：</p>
<ul class="simple">
<li><p>同一个 POD 内的多个容器间的通信，可以通过 lo 通信直接通讯。</p></li>
<li><p>POD 与 POD 通信，如果使用 flannel 所有 POD 都处于一个网络，可以跨
node 与另外的 POD 直接通信，因为使用了叠加网络。</p></li>
<li><p>POD 与 Service 通信。</p></li>
</ul>
</div>
<div class="section" id="kube-proxy">
<h2><a class="toc-backref" href="#id176">2.4 kube-proxy</a><a class="headerlink" href="#kube-proxy" title="Permalink to this headline">¶</a></h2>
<p>在 node 节点上运行的一个守护进程，它负责随时与 apiserver
进行通信，因为每个 pod 发生变化后需要保存在 apiserver 中，而 apiserver
发生改变后会生成一个通知事件，这个事件可以被任何关联的组件接收到，例如被
kube-proxy 一旦发现某个 service 后端的 pod 地址发生改变，那么就由
kube-proxy 负责在本地将地址写入 iptables 或者 ipvs 规则中。</p>
<p>所以 service 的管理是靠 kube-proxy 来实现的，当你创建一个 service
，那么就靠 kube-proxy 在每个节点上创建为 iptables 或者 ipvs 规则，每个
service 的变动也需要 kube-proxy 反应到规则上。</p>
<p>apiserver 需要保存各个 node 信息，它需要保存在 etcd 中。</p>
</div>
<div class="section" id="etcd">
<h2><a class="toc-backref" href="#id177">2.5 etcd</a><a class="headerlink" href="#etcd" title="Permalink to this headline">¶</a></h2>
<p>是一个键值存储的系统，与 redis 很像，但是 etcd 还有一些协调功能是 redis
所不具备的，它还有节点选举等功能，从这个角度来讲 etcd 更像 zookeeper。</p>
<p>由于整个集群的所有信息都保存在 etcd，所以 etcd
如果宕机，那么整个集群就挂了，因而 etcd 需要做高可用。</p>
</div>
<div class="section" id="flanel">
<h2><a class="toc-backref" href="#id178">2.6 flanel</a><a class="headerlink" href="#flanel" title="Permalink to this headline">¶</a></h2>
<p>托管为 k8s 的附件运行, 在 k8s 中有很多其他的开源网络插件，例如高性能的
calico 三层网络插件,性能很好，支持访问控制</p>
<p>node 网络：物理各节点之间进行通信</p>
<p>POD 网络：所有 node上的 POD 彼此之间通过叠加，或者直接路由方式通信</p>
<p>service 网络：由 kube-proxy 负责管控和生成</p>
</div>
<div class="section" id="id7">
<h2><a class="toc-backref" href="#id179">知识小结</a><a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Master</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kube</span><span class="o">-</span><span class="n">scheduler</span>             <span class="c1"># 调度 pod</span>
<span class="n">kuber</span><span class="o">-</span><span class="n">controller</span><span class="o">-</span><span class="n">manager</span>   <span class="c1"># 管理 pod</span>
<span class="n">kube</span><span class="o">-</span><span class="n">apiserver</span>             <span class="c1"># 接收请求</span>
<span class="n">etcd</span>                       <span class="c1"># 集群状态存储，集群所有的组件的状态都保存在这里</span>
</pre></div>
</div>
<ul class="simple">
<li><p>node</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kubelet</span>                    <span class="c1"># 节点/pod管理</span>
<span class="n">kube</span><span class="o">-</span><span class="n">proxy</span>                 <span class="c1"># watch apiserver管理service</span>
<span class="n">docker</span>                     <span class="c1"># 容器运行时</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id8">
<h1><a class="toc-backref" href="#id180">三 集群部署</a><a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h1>
<p>为简单上手体验功能，可以先利用kubeadm安装测试，生产环境建议二进制或者一些成熟的集群高可用安装方式，Kubeadm
是 K8S 官方提供的快速部署工具，它提供了 kubeadm init 以及 kubeadm join
这两个命令作为快速创建 kubernetes 集群的最佳实践，本章节说明了使用
kubeadm 来部署 K8S 集群的过程。</p>
<ul class="simple">
<li><p>集群组织结构</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 16%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>项目</p></th>
<th class="head"><p>说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>集群规模</p></td>
<td><p>Master、node1、node2</p></td>
</tr>
<tr class="row-odd"><td><p>系统</p></td>
<td><p>CentOS 7.3</p></td>
</tr>
<tr class="row-even"><td><p>网络规划</p></td>
<td><p>POD：10.244.0.0/16、Service：10.96.0.0/12</p></td>
</tr>
</tbody>
</table>
<div class="section" id="id9">
<h2><a class="toc-backref" href="#id181">3.1 部署前准备</a><a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>本小节的所有的操作，在所有的节点上进行</p>
</div></blockquote>
<div class="section" id="firewalld-selinux">
<h3><a class="toc-backref" href="#id182">3.1.1 关闭 firewalld 和 selinux</a><a class="headerlink" href="#firewalld-selinux" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>setenforce <span class="m">0</span>
sed -i <span class="s1">&#39;/^SELINUX=/cSELINUX=disabled&#39;</span> /etc/selinux/config

systemctl stop firewalld
systemctl disable firewalld
</pre></div>
</div>
</div>
<div class="section" id="ipvs">
<h3><a class="toc-backref" href="#id183">3.1.2 加载 ipvs 内核模块</a><a class="headerlink" href="#ipvs" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>安装 IPVS 模块</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>yum -y install ipvsadm ipset sysstat conntrack libseccomp
</pre></div>
</div>
<ul class="simple">
<li><p>设置开机加载配置文件</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat &gt;&gt;/etc/modules-load.d/ipvs.conf<span class="s">&lt;&lt;EOF</span>
<span class="s">ip_vs_dh</span>
<span class="s">ip_vs_ftp</span>
<span class="s">ip_vs</span>
<span class="s">ip_vs_lblc</span>
<span class="s">ip_vs_lblcr</span>
<span class="s">ip_vs_lc</span>
<span class="s">ip_vs_nq</span>
<span class="s">ip_vs_pe_sip</span>
<span class="s">ip_vs_rr</span>
<span class="s">ip_vs_sed</span>
<span class="s">ip_vs_sh</span>
<span class="s">ip_vs_wlc</span>
<span class="s">ip_vs_wrr</span>
<span class="s">nf_conntrack_ipv4</span>
<span class="s">EOF</span>
</pre></div>
</div>
<ul class="simple">
<li><p>设置开机加载 IPVS 模块</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>systemctl <span class="nb">enable</span> systemd-modules-load.service   <span class="c1"># 设置开机加载内核模块</span>
lsmod <span class="p">|</span> grep -e ip_vs -e nf_conntrack_ipv4      <span class="c1"># 重启后检查 ipvs 模块是否加载</span>
</pre></div>
</div>
<ul class="simple">
<li><p>如果集群已经部署在了 iptables 模式下，可以通过下面命令修改，修改 mode
为 ipvs 重启集群即可。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl edit -n kube-system configmap kube-proxy
</pre></div>
</div>
</div>
<div class="section" id="docker-k8s">
<h3><a class="toc-backref" href="#id184">3.1.3 下载 Docker 和 K8S</a><a class="headerlink" href="#docker-k8s" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>设置 docker 源</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl -o /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</pre></div>
</div>
<ul class="simple">
<li><p>设置 k8s 源</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat &gt;&gt;/etc/yum.repos.d/kuberetes.repo<span class="s">&lt;&lt;EOF</span>
<span class="s">[kuberneres]</span>
<span class="s">name=Kubernetes</span>
<span class="s">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span>
<span class="s">gpgcheck=0</span>
<span class="s">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</span>
<span class="s">enabled=1</span>
<span class="s">EOF</span>
</pre></div>
</div>
<ul class="simple">
<li><p>安装 docker-ce 和 kubernetes</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>yum install docker-ce kubelet kubectl kubeadm -y
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>systemctl start docker
systemctl <span class="nb">enable</span> docker
systemctl <span class="nb">enable</span> kubelet
</pre></div>
</div>
</div>
<div class="section" id="k8s">
<h3><a class="toc-backref" href="#id185">3.1.4 设置内核及 K8S 参数</a><a class="headerlink" href="#k8s" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>设置内核参数</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat &gt;&gt;/etc/sysctl.conf<span class="s">&lt;&lt;EOF</span>
<span class="s">net.bridge.bridge-nf-call-ip6tables = 1</span>
<span class="s">net.bridge.bridge-nf-call-iptables = 1</span>
<span class="s">net.ipv4.ip_forward = 1</span>
<span class="s">EOF</span>
</pre></div>
</div>
<ul class="simple">
<li><p>设置 kubelet 忽略 swap，使用 ipvs</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat &gt;/etc/sysconfig/kubelet<span class="s">&lt;&lt;EOF</span>
<span class="s">KUBELET_EXTRA_ARGS=&quot;--fail-swap-on=false&quot;</span>
<span class="s">KUBE_PROXY_MODE=ipvs</span>
<span class="s">EOF</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="master">
<h2><a class="toc-backref" href="#id186">3.2 部署 Master</a><a class="headerlink" href="#master" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>本小节的所有的操作，只在 Master 节点上进行</p>
</div></blockquote>
<div class="section" id="id10">
<h3><a class="toc-backref" href="#id187">3.2.1 提前拉取镜像</a><a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>宿主机最好能访问国外资源，在kubeadm init 在初始化的时候会到谷歌的 docker
hub 拉取镜像，如果宿主机测试无法访问 k8s.gcr.io
可以在服务器所以我们要提前部署好代理软件，本例中监听个本机 9666
进行部署。</p>
<p>如果条件不允许可以参考:
<a class="reference external" href="https://blog.csdn.net/jinguangliu/article/details/82792617">https://blog.csdn.net/jinguangliu/article/details/82792617</a>
来解决镜像问题。</p>
<ul class="simple">
<li><p>配置 Docker 拉取镜像时候的代理地址，vim
/usr/lib/systemd/system/docker.service。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Service<span class="o">]</span>
<span class="nv">Environment</span><span class="o">=</span><span class="s2">&quot;HTTPS_PROXY=127.0.0.1:9666&quot;</span>
<span class="nv">Environment</span><span class="o">=</span><span class="s2">&quot;NO_PROXY=127.0.0.0/8,172.16.0.0/16&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>提前拉取初始化需要的镜像</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubeadm config images pull
</pre></div>
</div>
<ul class="simple">
<li><p>使用其他源镜像</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker pull mirrorgooglecontainers/kube-apiserver:v1.14.2
docker pull mirrorgooglecontainers/kube-controller-manager:v1.14.2
docker pull mirrorgooglecontainers/kube-scheduler:v1.14.2
docker pull mirrorgooglecontainers/kube-proxy:v1.14.2
docker pull mirrorgooglecontainers/pause:3.1
docker pull mirrorgooglecontainers/etcd:3.3.10
docker pull coredns/coredns:1.3.1


利用<span class="sb">`</span>kubeadm config images list<span class="sb">`</span> 查看需要的docker image name

k8s.gcr.io/kube-apiserver:v1.14.2
k8s.gcr.io/kube-controller-manager:v1.14.2
k8s.gcr.io/kube-scheduler:v1.14.2
k8s.gcr.io/kube-proxy:v1.14.2
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.3.10
k8s.gcr.io/coredns:1.3.1

<span class="c1"># 修改tag</span>

docker tag docker.io/mirrorgooglecontainers/kube-apiserver:v1.14.2 k8s.gcr.io/kube-apiserver:v1.14.2
docker tag docker.io/mirrorgooglecontainers/kube-scheduler:v1.14.2 k8s.gcr.io/kube-scheduler:v1.14.2
docker tag docker.io/mirrorgooglecontainers/kube-proxy:v1.14.2 k8s.gcr.io/kube-proxy:v1.14.2
docker tag docker.io/mirrorgooglecontainers/kube-controller-manager:v1.14.2 k8s.gcr.io/kube-controller-manager:v1.14.2
docker tag docker.io/mirrorgooglecontainers/etcd:3.3.10  k8s.gcr.io/etcd:3.3.10
docker tag docker.io/mirrorgooglecontainers/pause:3.1  k8s.gcr.io/pause:3.1
docker tag docker.io/coredns/coredns:1.3.1  k8s.gcr.io/coredns:1.3.1

docker rmi <span class="sb">`</span>docker images <span class="p">|</span>grep docker.io/ <span class="p">|</span>awk <span class="s1">&#39;{print $1&quot;:&quot;$2}&#39;</span><span class="sb">`</span>
</pre></div>
</div>
</div>
<div class="section" id="id11">
<h3><a class="toc-backref" href="#id188">3.2.2 初始化Master</a><a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>使用 kubeadm 初始化 k8s 集群</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubeadm init --kubernetes-version<span class="o">=</span>v1.14.0 --pod-network-cidr<span class="o">=</span><span class="m">10</span>.244.0.0/16 --service-cidr<span class="o">=</span><span class="m">10</span>.96.0.0/12 --ignore-preflight-errors<span class="o">=</span>Swap
</pre></div>
</div>
<ul class="simple">
<li><p>如果有报错使用下面命令查看</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>journalctl -xeu kubelet
</pre></div>
</div>
<ul class="simple">
<li><p>如果初始化过程被中断可以使用下面命令来恢复</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubeadm reset
</pre></div>
</div>
<ul class="simple">
<li><p>下面是最后执行成功显示的结果，需要保存这个执行结果，以让 node
节点加入集群</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span class="nv">$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
  sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config

You should now deploy a pod network to the cluster.
Run <span class="s2">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join <span class="m">172</span>.16.100.9:6443 --token 2dyd69.hrfsjkkxs4stim7n <span class="se">\</span>
    --discovery-token-ca-cert-hash sha256:4e30c1f41aefb177b708a404ccb7e818e31647c7dbdd2d42f6c5c9894b6f41e7
</pre></div>
</div>
<ul class="simple">
<li><p>最好以普通用户的身份运行下面的命令</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 在当前用户家目录下创建.kube目录并配置访问集群的config 文件</span>
mkdir -p <span class="nv">$HOME</span>/.kube
sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</pre></div>
</div>
<ul class="simple">
<li><p>部署 flannel 网络插件</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</pre></div>
</div>
<ul class="simple">
<li><p>查看 kube-system 命名空间中运行的 pods</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>查看 k8s 集群组件的状态</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get ComponentStatus
</pre></div>
</div>
<ul class="simple">
<li><p>配置命令补全</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>yum install -y bash-completion
<span class="nb">source</span> /usr/share/bash-completion/bash_completion
<span class="nb">source</span> &lt;<span class="o">(</span>kubectl completion bash<span class="o">)</span>
<span class="nb">echo</span> <span class="s2">&quot;source &lt;(kubectl completion bash)&quot;</span> &gt;&gt; ~/.bashrc
</pre></div>
</div>
</div>
</div>
<div class="section" id="node">
<h2><a class="toc-backref" href="#id189">3.3 部署 Node</a><a class="headerlink" href="#node" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>本小节的所有的操作，只在 Node 节点上进行。</p>
</div></blockquote>
<div class="section" id="id12">
<h3><a class="toc-backref" href="#id190">3.3.1 加入集群</a><a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>加入集群，注意在命令尾部加上 –ignore-preflight-errors=Swap ，以忽略
k8s 对主机 swap 的检查（k8s为了性能所以要求进制 swap ）</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubeadm join <span class="m">172</span>.16.100.9:6443 --token 2dyd69.hrfsjkkxs4stim7n <span class="se">\</span>
    --discovery-token-ca-cert-hash sha256:4e30c1f41aefb177b708a404ccb7e818e31647c7dbdd2d42f6c5c9894b6f41e7 --ignore-preflight-errors<span class="o">=</span>Swap
</pre></div>
</div>
<ul class="simple">
<li><p>返回结果，表示加入集群成功</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span class="s1">&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.
</pre></div>
</div>
</div>
<div class="section" id="id13">
<h3><a class="toc-backref" href="#id191">3.3.2 查看进度</a><a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>当 node 节点加入 K8S 集群中后，Master 会调度到 Node
节点上一些组件，用于处理集群事务，这些组件没有下载完成之前 Node
节点在集群中还是未就绪状态</p>
<ul class="simple">
<li><p>在 node 执行下面命令，可以查看镜像的下载进度，下面是最终结果显示</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ docker image ls
REPOSITORY               TAG                 IMAGE ID            CREATED             SIZE
k8s.gcr.io/kube-proxy    v1.14.0             5cd54e388aba        <span class="m">6</span> weeks ago         <span class="m">82</span>.1MB
quay.io/coreos/flannel   v0.11.0-amd64       ff281650a721        <span class="m">3</span> months ago        <span class="m">52</span>.6MB
k8s.gcr.io/pause         <span class="m">3</span>.1                 da86e6ba6ca1        <span class="m">16</span> months ago       742kB
</pre></div>
</div>
<ul class="simple">
<li><p>可以在 Master 上使用下面命令来查看新加入的节点状态</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get nodes
NAME     STATUS   ROLES    AGE     VERSION
master   Ready    master   3d21h   v1.14.1
node1    Ready    &lt;none&gt;   3d21h   v1.14.1
node2    Ready    &lt;none&gt;   3d21h   v1.14.1
</pre></div>
</div>
<ul class="simple">
<li><p>查看集群状态</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl cluster-info</span>
Kubernetes master is running at https://10.234.2.204:6443
KubeDNS is running at https://10.234.2.204:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Metrics-server is running at https://10.234.2.204:6443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy

To further debug and diagnose cluster problems, use <span class="s1">&#39;kubectl cluster-info dump&#39;</span>.
<span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl get componentstatuses</span>
NAME                 STATUS    MESSAGE             ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
etcd-0               Healthy   <span class="o">{</span><span class="s2">&quot;health&quot;</span>:<span class="s2">&quot;true&quot;</span><span class="o">}</span>
</pre></div>
</div>
<p>如果嫌网络pull镜像慢可以在一台上面将镜像打包发送至其他node节点</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>拷贝到node节点
for i in /tmp/*.tar; do scp -i $i root@172.16.0.15:/root/;done


node节点还原
for i in *.tar ;do docker load -i $i;done
</pre></div>
</div>
<ul class="simple">
<li><p>查看 kube-system 这个 k8s
命名空间中有哪些组件，分别运行在哪个节点，-o wide 是以详细方式显示。</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl get pods -n kube-system -o wide

NAME                                 READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES
coredns-fb8b8dccf-cp24r              <span class="m">1</span>/1     Running   <span class="m">0</span>          26m     <span class="m">10</span>.244.0.2      i-xeahpl98   &lt;none&gt;           &lt;none&gt;
coredns-fb8b8dccf-ljswp              <span class="m">1</span>/1     Running   <span class="m">0</span>          26m     <span class="m">10</span>.244.0.3      i-xeahpl98   &lt;none&gt;           &lt;none&gt;
etcd-i-xeahpl98                      <span class="m">1</span>/1     Running   <span class="m">0</span>          25m     <span class="m">172</span>.16.100.9    i-xeahpl98   &lt;none&gt;           &lt;none&gt;
kube-apiserver-i-xeahpl98            <span class="m">1</span>/1     Running   <span class="m">0</span>          25m     <span class="m">172</span>.16.100.9    i-xeahpl98   &lt;none&gt;           &lt;none&gt;
kube-controller-manager-i-xeahpl98   <span class="m">1</span>/1     Running   <span class="m">0</span>          25m     <span class="m">172</span>.16.100.9    i-xeahpl98   &lt;none&gt;           &lt;none&gt;
kube-flannel-ds-amd64-crft8          <span class="m">1</span>/1     Running   <span class="m">3</span>          16m     <span class="m">172</span>.16.100.6    i-me87b6gw   &lt;none&gt;           &lt;none&gt;
kube-flannel-ds-amd64-nckw4          <span class="m">1</span>/1     Running   <span class="m">0</span>          6m41s   <span class="m">172</span>.16.100.10   i-qhcc2owe   &lt;none&gt;           &lt;none&gt;
kube-flannel-ds-amd64-zb7sg          <span class="m">1</span>/1     Running   <span class="m">0</span>          23m     <span class="m">172</span>.16.100.9    i-xeahpl98   &lt;none&gt;           &lt;none&gt;
kube-proxy-7kjkf                     <span class="m">1</span>/1     Running   <span class="m">0</span>          6m41s   <span class="m">172</span>.16.100.10   i-qhcc2owe   &lt;none&gt;           &lt;none&gt;
kube-proxy-c5xs2                     <span class="m">1</span>/1     Running   <span class="m">2</span>          16m     <span class="m">172</span>.16.100.6    i-me87b6gw   &lt;none&gt;           &lt;none&gt;
kube-proxy-rdzq2                     <span class="m">1</span>/1     Running   <span class="m">0</span>          26m     <span class="m">172</span>.16.100.9    i-xeahpl98   &lt;none&gt;           &lt;none&gt;
kube-scheduler-i-xeahpl98            <span class="m">1</span>/1     Running   <span class="m">0</span>          25m     <span class="m">172</span>.16.100.9    i-xeahpl98   &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
</div>
<div class="section" id="id14">
<h3><a class="toc-backref" href="#id192">3.3.3 镜像下载太慢</a><a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>node 节点需要翻墙下载镜像太慢，建议使用 docker 镜像的导入导出功能
先将master的三个镜像打包发送到node节点，load后再jion</p>
<ul class="simple">
<li><p>导出</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker image save -o /tmp/kube-proxy.tar k8s.gcr.io/kube-proxy
docker image save -o /tmp/flannel.tar quay.io/coreos/flannel
docker image save -o /tmp/pause.tar k8s.gcr.io/pause
</pre></div>
</div>
<ul class="simple">
<li><p>导入</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker image load -i /tmp/kube-proxy.tar
docker image load -i /tmp/pause.tar
docker image load -i /tmp/flannel.tar
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id15">
<h1><a class="toc-backref" href="#id193">四 入门命令</a><a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h1>
<div class="section" id="kubectl">
<h2><a class="toc-backref" href="#id194">4.1 kubectl</a><a class="headerlink" href="#kubectl" title="Permalink to this headline">¶</a></h2>
<p>kubectl 是 apiserver 的客户端程序，这个客户端程序是通过连接 master
节点上的 apiserver ，实现各种 k8s 对象的增删改查等基本操作，在 k8s
可被管理的对象有很多个</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>基本命令 <span class="o">(</span>初级<span class="o">)</span>:
  create         从文件或标准输入创建资源
  expose         获取一个复制控制器, 服务, 部署或者暴露一个 POD 将其作为新的 Kubernetes 服务公开
  run            创建并运行特定的镜像, 创建使用 deployment 或 job 管理的容器
  <span class="nb">set</span>            设置对象的特定功能, 例如发布, 每次去set 不用的image tag

基本命令 <span class="o">(</span>中级<span class="o">)</span>:
  explain        文档或者资源, 可以用来查看资源清单写法
  get            显示一个或多个资源
  edit           编辑服务器上的资源
  delete         按文件名, 标准输入, 资源和名称或资源和标签选择器删除资源

部署命令:
  rollout        管理资源的部署
  scale          为部署设置新大小, ReplicaSet, Replication Controller, Job
  autoscale      自动扩展一个部署, ReplicaSet, 或者 ReplicationController

群集管理命令:
  certificate    修改证书资源
  cluster-info   显示群集信息
  top            显示资源<span class="o">(</span>CPU / 内存/ 存储<span class="o">)</span>使用情况, 需要安装metrics-server
  cordon         将节点标记为不可调度
  uncordon       将节点标记为可调度
  drain          设定 node 进入维护模式
  taint          更新一个或多个节点上的污点

故障排除和调试命令:
  describe       显示特定资源或资源组的详细信息
  logs           在容器中打印容器的日志
  attach         附加到正在运行的容器
  <span class="nb">exec</span>           在容器中执行命令
  port-forward   将一个或多个本地端口转发到 pod
  proxy          运行代理到 Kubernetes API 服务器
  cp             将文件和目录复制到容器, 和从容器复制, 跨容器复制文件
  auth           检查授权

高级命令:
  diff           针对将要应用的版本的 Diff 实时版本
  apply          通过文件名或标准输入将配置应用于资源
  patch          使用策略合并补丁更新资源的字段
  replace        用文件名或标准输入替换资源
  <span class="nb">wait</span>           实验阶段命令: 在一个或多个资源上等待特定条件, 定义一个触发器
  convert        在不同的API版本之间转换配置文件
  kustomize      从目录或远程 URL 构建 kustomization 目标

设置命令:
  label          更新资源上的标签
  annotate       更新资源上的注释
  completion     命令补全相关功能

其他命令:
  api-resources  在服务器上打印支持的API资源
  api-versions   以 <span class="s2">&quot;group/version&quot;</span> 的形式在服务器上打印支持的API版本
  config         修改 kubeconfig 文件
  plugin         提供与插件交互的实用程序
  version        打印客户端和服务器版本信息
</pre></div>
</div>
</div>
<div class="section" id="run">
<h2><a class="toc-backref" href="#id195">4.2 run</a><a class="headerlink" href="#run" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>创建控制器并运行镜像</p></li>
</ul>
<p>创建一个名为 nginx 的 deployment，镜像为 nginx:latest
,如果不知道副本数，则为1</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl run nginx --image<span class="o">=</span>nginx:latest
</pre></div>
</div>
<ul class="simple">
<li><p>指定运行的 POD 数量</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl run nginx --image<span class="o">=</span>nginx --replicas<span class="o">=</span><span class="m">5</span>  <span class="c1"># 启动 5 个 POD</span>
</pre></div>
</div>
<ul class="simple">
<li><p>不运行容器的默认命令，使用自定义的指令</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl run nginx --image<span class="o">=</span>nginx --command -- &lt;cmd&gt; &lt;arg1&gt; ... &lt;argN&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>运行一个周期任务</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl run pi --schedule<span class="o">=</span><span class="s2">&quot;0/5 * * * ?&quot;</span> --image<span class="o">=</span>perl --restart<span class="o">=</span>OnFailure -- perl -Mbignum<span class="o">=</span>bpi -wle <span class="s1">&#39;print bpi(2000)&#39;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>指定控制器名称运行 nginx 指定端口和副本数量，以测试模式运行</p></li>
</ul>
<p>指定参数 dry-run 可以用来验证写的 yaml 文件是否存在异常，不会真正执行</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl run nginx-deploy --image<span class="o">=</span>nginx --port<span class="o">=</span><span class="m">80</span> --replicas<span class="o">=</span><span class="m">1</span> --dry-run<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看容器是否运行</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get deployment
</pre></div>
</div>
<ul class="simple">
<li><p>查看被调度的主机</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pod -o wide
</pre></div>
</div>
<ul class="simple">
<li><p>通过 ip 地址直接访问，由于所有的 POD
处于同一个网络中，所以在集群内部是可以访问的</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl <span class="m">10</span>.244.2.2
</pre></div>
</div>
<ul class="simple">
<li><p>假如现在删除刚创建的这个 POD，那么副本控制器会自动在其他的 node
上重建这个 POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl delete pods nginx-deploy-5c9b546997-jsmk6
</pre></div>
</div>
<ul class="simple">
<li><p>再次执行查看，会发现容器已经被调度到其他节点上运行了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pod -o wide
</pre></div>
</div>
</div>
<div class="section" id="expose">
<h2><a class="toc-backref" href="#id196">4.3 expose</a><a class="headerlink" href="#expose" title="Permalink to this headline">¶</a></h2>
<p>现在存在一个问题，就是 POD 的 IP
地址可能随时发生变动，所以不能作为访问的入口，那么就需要 service 来代理
POD 来创建一个固定的端点。</p>
<ul class="simple">
<li><p>创建一个 service 来暴露一个服务</p></li>
</ul>
<p>在控制器 nginx-deploy 上创建名字为 nginx 的 service , 它工作端口为 80,
代理的后端容器端口 80, 协议为 TCP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl expose deployment nginx-deploy --name<span class="o">=</span>nginx --port<span class="o">=</span><span class="m">80</span> --target-port<span class="o">=</span><span class="m">80</span> --protocol<span class="o">=</span>TCP
</pre></div>
</div>
<ul class="simple">
<li><p>可以看到刚刚创建的名字为 nginx 的 service ，现在就可以在集群内用
service 的地址来访问了, 如果外部访问可以使用 NodePort 模式</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get service
</pre></div>
</div>
<ul class="simple">
<li><p>删除一个任务</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl delete deployment nginx-deploy
</pre></div>
</div>
</div>
<div class="section" id="cp">
<h2><a class="toc-backref" href="#id197">4.4 cp</a><a class="headerlink" href="#cp" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>拷贝宿主机文件或目录到pod中，⚠️要求tar二进制文件已经存在容器中，不然拷贝会失败</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>kubectl cp /tmp/foo_dir &lt;some-pod&gt;:/tmp/bar_dir

<span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl cp flannel.tar  nginx-58cd4d4f44-8pwb7:/usr/share/nginx/html</span>
<span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl cp mainfile/  nginx-58cd4d4f44-8pwb7:/usr/share/nginx/html</span>
<span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl exec -it nginx-58cd4d4f44-8pwb7 -- /bin/bash</span>
root@nginx-58cd4d4f44-8pwb7:/# ls -l /usr/share/nginx/html/
total <span class="m">54108</span>
-rw-r--r-- <span class="m">1</span> root root      <span class="m">537</span> Jul <span class="m">11</span>  <span class="m">2017</span> 50x.html
-rw-r--r-- <span class="m">1</span> root root      <span class="m">355</span> May <span class="m">27</span> <span class="m">06</span>:47 dashboard-adminuser.yaml
-rw------- <span class="m">1</span> root root <span class="m">55390720</span> May <span class="m">27</span> <span class="m">01</span>:49 flannel.tar
-rw-r--r-- <span class="m">1</span> root root      <span class="m">612</span> Jul <span class="m">11</span>  <span class="m">2017</span> index.html
drwxr-xr-x <span class="m">4</span> root root       <span class="m">51</span> Aug <span class="m">17</span> <span class="m">14</span>:16 mainfile
</pre></div>
</div>
</div>
<div class="section" id="port-forward">
<h2><a class="toc-backref" href="#id198">4.5 port-forward</a><a class="headerlink" href="#port-forward" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>端口转发，将svc地址或着pods端口利用kubelet映射到宿主机上,将访问宿主机的8888端口的所有流量转发到8111svc</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>kubectl port-forward --address <span class="m">0</span>.0.0.0 service/nginx <span class="m">8888</span> <span class="m">8111</span>
</pre></div>
</div>
<ul class="simple">
<li><p>转发pods端口,将访问宿主机的8888端口流量转发到pod的5000端口</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>kubectl port-forward pod/mypod <span class="m">8888</span>:5000
</pre></div>
</div>
</div>
<div class="section" id="coredns">
<h2><a class="toc-backref" href="#id199">4.6 coredns</a><a class="headerlink" href="#coredns" title="Permalink to this headline">¶</a></h2>
<p>service 提供了对 pod 的固定访问端点，但是 service
本身的变动我们无法知晓，需要 coredns 对 service 做域名解析。</p>
<ul class="simple">
<li><p>查看 coredns 运行状态</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods -n kube-system -o wide <span class="p">|</span>grep coredns
</pre></div>
</div>
<ul class="simple">
<li><p>查看各个 kube-system 命名空间运行的服务，可以看到 kube-dns 运行的 IP
地址</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get service -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>使用 kube-dns 来解析 nginx 这个 service 的地址就可以正常解析了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>dig -t A nginx.default.svc.cluster.local @10.96.0.10
</pre></div>
</div>
<ul class="simple">
<li><p>创建一个访问 nginx 客户端容器，并进入交互式模式，这个容器默认的 dns
服务器就是 kube-dns 所在的服务器</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl run client --image<span class="o">=</span>busybox --replicas<span class="o">=</span><span class="m">1</span> -it --restart<span class="o">=</span>Never
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/ <span class="c1"># cat /etc/resolv.conf</span>
nameserver <span class="m">10</span>.96.0.10                                               <span class="c1"># kube-dns 地址</span>
search default.svc.cluster.local svc.cluster.local cluster.local    <span class="c1"># 默认的解析搜索域</span>
options ndots:5
</pre></div>
</div>
<ul class="simple">
<li><p>在 busybox 这个容器中请求 nginx 这个域名的 service ，能够正常访问</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget -O - -q http://nginx:80/
</pre></div>
</div>
</div>
<div class="section" id="pod">
<h2><a class="toc-backref" href="#id200">4.7 模拟 POD 被删除</a><a class="headerlink" href="#pod" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>现在我们删除 service 后端的 POD ，副本控制器会自动创建新的 POD，而
service 则会自动指向新创建的 POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl delete pods nginx-deploy-5c9b546997-4w24n
</pre></div>
</div>
<ul class="simple">
<li><p>查看由副本控制器自动创建的 POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods
</pre></div>
</div>
<ul class="simple">
<li><p>在 busybox 这个容器中请求 nginx 这个域名的 service ，访问没有受到影响</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget -O - -q http://nginx:80/
</pre></div>
</div>
</div>
<div class="section" id="id16">
<h2><a class="toc-backref" href="#id201">4.8 模拟 service 被删除</a><a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>当我们删除 service 并且重新建立一个 service 再次查看 service
的地址已经发生变化了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl delete service nginx
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl expose deployment nginx-deploy --name<span class="o">=</span>nginx --port<span class="o">=</span><span class="m">80</span> --target-port<span class="o">=</span><span class="m">80</span> --protocol<span class="o">=</span>TCP
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get service
</pre></div>
</div>
<ul class="simple">
<li><p>在 busybox 这个容器中请求 nginx 这个域名的 service
，访问没有仍然没有受到影响</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget -O - -q http://nginx:80/
</pre></div>
</div>
</div>
<div class="section" id="labels">
<h2><a class="toc-backref" href="#id202">4.9 labels</a><a class="headerlink" href="#labels" title="Permalink to this headline">¶</a></h2>
<p>为什么 Pod 被删除后，servic 仍然能够正确的调度到新的 POD 上，这就是 k8s
的 labels 这个机制来保证的。</p>
<p>能够使用标签机制不止有 pod、在 k8s
中很多对象都可以使用标签，例如：node、service</p>
<ul class="simple">
<li><p>查看 service 的详细信息，会发现标签选择器</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl describe service nginx
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Name:              nginx
Namespace:         default
Labels:            <span class="nv">run</span><span class="o">=</span>nginx-deploy
Annotations:       &lt;none&gt;
Selector:          <span class="nv">run</span><span class="o">=</span>nginx-deploy       <span class="c1"># 这个选择器会自动选中 run 标签，且值为 nginx-deploy 的 POD</span>
Type:              ClusterIP
IP:                <span class="m">10</span>.101.149.4
Port:              &lt;unset&gt;  <span class="m">80</span>/TCP
TargetPort:        <span class="m">80</span>/TCP
Endpoints:         <span class="m">10</span>.244.2.4:80          <span class="c1"># 当 service 的后端，当 POD 发生变动则立即会更新</span>
Session Affinity:  None
Events:            &lt;none&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>查看 POD 的标签，会看到拥有 run=nginx-deploy
标签的容器，而人为删除一个 POD
后，副本控制器创建的副本上的标签不会变化，所以标签又被 service 关联。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods --show-labels
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME                            READY   STATUS    RESTARTS   AGE     LABELS
client                          <span class="m">1</span>/1     Running   <span class="m">0</span>          21m     <span class="nv">run</span><span class="o">=</span>client
nginx-deploy-5c9b546997-kh88w   <span class="m">1</span>/1     Running   <span class="m">0</span>          8m37s   pod-template-hash<span class="o">=</span>5c9b546997,run<span class="o">=</span>nginx-deploy
</pre></div>
</div>
<ul class="simple">
<li><p>查看 POD 的详细信息，也可以查看到 POD 的详细信息</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl describe deployment nginx-deploy
</pre></div>
</div>
<ul class="simple">
<li><p>根据标签过滤，使用 -l 来指定标签名称或同时过滤其值</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods --show-labels -l <span class="nv">run</span><span class="o">=</span>nginx-deploy
</pre></div>
</div>
<ul class="simple">
<li><p>标签选择器集中运算</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>关系与:  KEY,KEY <span class="nv">KEY</span><span class="o">=</span>VALUE2,KEY<span class="o">=</span>VALUE2       <span class="c1"># -l run,app</span>
等值关系:KEY <span class="o">=</span> VALUE KEY !<span class="o">=</span> VALUE           <span class="c1"># -l run=nginx-deploy,app!=myapp</span>
集合关系:KYE in<span class="p">|</span>not in <span class="o">(</span>VALUE1,VALUE2<span class="o">)</span>      <span class="c1"># -l &quot;release in (canary,bata,alpha)&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>显示指定的标签的值，下面显示了两个标签</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods --show-labels -L run,pod-template-hash
</pre></div>
</div>
<ul class="simple">
<li><p>为指定的 POD 打标签，为 client 这个 POD 打上一个 release 标签，其值为
canary</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl label pods client <span class="nv">release</span><span class="o">=</span>canary
</pre></div>
</div>
<ul class="simple">
<li><p>修改 POD 的标签，使用 –overwrite 进行修改原有标签</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl label pods client <span class="nv">release</span><span class="o">=</span>stable --overwrite
</pre></div>
</div>
<ul class="simple">
<li><p>删除指定的 nodes 上的标签，使用标签名称加 - 符号</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl label nodes node2 disktype-
</pre></div>
</div>
<ul class="simple">
<li><p>许多资源支持内嵌字段来定义其使用的标签选择器，例如 service 关联 pod
时候：</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>matchLabels: 直接给定键值
matchExpressions: 基于给定的表达式来定义使用标签选择器: <span class="o">{</span>key:<span class="s2">&quot;KEY&quot;</span>,operator:<span class="s2">&quot;OPERATOR&quot;</span>,value:<span class="o">[</span>VAL1,VAL2,...<span class="o">]}</span>
    使用 key 与 value 进行 operator 运算, 复合条件的才被选择
    操作符:
        In, NotIn: 其 value 列表必须有值
        Exists, NotExists: 其 value 必须为空
</pre></div>
</div>
<ul class="simple">
<li><p>k8s 中很多对象都可以打标签，例如给 nodes
打一个标记，随后在添加资源时候就可以让资源对节点有倾向性了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl label nodes node2 <span class="nv">disktype</span><span class="o">=</span>ssd
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get nodes --show-labels
</pre></div>
</div>
</div>
<div class="section" id="id17">
<h2><a class="toc-backref" href="#id203">4.10 动态扩容</a><a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>扩容一个集群的的 POD，下面命令表示修改 deployment 控制器下的
nginx-deply 容器的副本数量为2</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl scale --replicas<span class="o">=</span><span class="m">5</span> deployment nginx-deploy
</pre></div>
</div>
</div>
<div class="section" id="id18">
<h2><a class="toc-backref" href="#id204">4.11 滚动升级</a><a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>更换 nginx-deploy 这个控制器下的 nginx-deploy 容器镜像为
ikubernetes/myapp:v2</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">set</span> image deployment nginx-deploy nginx-deploy<span class="o">=</span>ikubernetes/myapp:v2
</pre></div>
</div>
<ul class="simple">
<li><p>查看更新的过程，直到 5 个容器中运行的镜像全部更新完</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl rollout status deployment nginx-deploy
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@node1 ~<span class="o">]</span><span class="c1"># kubectl rollout status deployment nginx-deploy</span>
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">3</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">3</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">3</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">3</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">3</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">4</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">4</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">4</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">4</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">4</span> out of <span class="m">5</span> new replicas have been updated...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">2</span> old replicas are pending termination...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">2</span> old replicas are pending termination...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">2</span> old replicas are pending termination...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">1</span> old replicas are pending termination...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">1</span> old replicas are pending termination...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">1</span> old replicas are pending termination...
Waiting <span class="k">for</span> deployment <span class="s2">&quot;nginx-deploy&quot;</span> rollout to finish: <span class="m">4</span> of <span class="m">5</span> updated replicas are available...
deployment <span class="s2">&quot;nginx-deploy&quot;</span> successfully rolled out
</pre></div>
</div>
<ul class="simple">
<li><p>回滚操作，不指定任何的镜像则为上一个版本的镜像</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl rollout undo deployment nginx-deploy
</pre></div>
</div>
<blockquote>
<div><p>如果防止更新过程中被调度，那么就需要学习就绪性检测才能实现</p>
</div></blockquote>
</div>
<div class="section" id="id19">
<h2><a class="toc-backref" href="#id205">4.12 集群外访问</a><a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>修改 service 的网络类型为 NodePort</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl edit service nginx
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>type: ClusterIP -&gt; type: NodePort
</pre></div>
</div>
<ul class="simple">
<li><p>查看 service 的信息，发现多了一个 30982 端口</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get service
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>        AGE
kubernetes   ClusterIP   <span class="m">10</span>.96.0.1      &lt;none&gt;        <span class="m">443</span>/TCP        15h
nginx        NodePort    <span class="m">10</span>.105.27.11   &lt;none&gt;        <span class="m">80</span>:30982/TCP   42m
</pre></div>
</div>
<ul class="simple">
<li><p>在集群外部使用任意的 node IP 地址 + 端口来访问</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>http://172.16.100.101:30982/
</pre></div>
</div>
</div>
<div class="section" id="id20">
<h2><a class="toc-backref" href="#id206">4.13 排查日志</a><a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>查看一个 pod 的某个容器的运行日志</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl logs pod-demo busybox
</pre></div>
</div>
</div>
<div class="section" id="id21">
<h2><a class="toc-backref" href="#id207">4.14 连入 POD 容器</a><a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">exec</span> -it pod-demo -c myapp -- /bin/sh
</pre></div>
</div>
</div>
</div>
<div class="section" id="id22">
<h1><a class="toc-backref" href="#id208">五 配置清单使用</a><a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h1>
<p>apiserver 仅接收 json 格式的资源定义，yaml
格式定义提供的配置清单，apiserver 可自动将其转换为 json
格式，而后再进行执行。</p>
<div class="section" id="id23">
<h2><a class="toc-backref" href="#id209">5.1 可配置的对象</a><a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>可用资源清单配置的对象</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>workload：Pod、ReplicaSet、Deployment、StatefulSet、DaemonSet、Job、CronJob
服务发现及均衡：Service、Ingress
配置与存储：Volume、CSI
    ConfigMap、Secret
    DownwardAPI
集群级资源
    Namespace、None、Role、ClusterRole、RoleBinding、ClusterRoleBinding
元数据类型资源
    HPA、PodTemplate、LimitRange
</pre></div>
</div>
</div>
<div class="section" id="id24">
<h2><a class="toc-backref" href="#id210">5.2 配置清单组成</a><a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>配置清单组成部分，大部分资源使用配置清单方式来创建</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion
    <span class="c1"># 以 &quot;group/version&quot; 形式指明，这个对象属于哪个 API 组（版本）</span>
kind:
    <span class="c1"># 资源类别，标记创建什么类型的资源</span>
metadata:
    <span class="c1"># 元数据内部是嵌套的字段</span>
    <span class="c1"># 定义了资源对象的名称、命名空间（k8s级别的不是系统的）等、标签、注解等</span>
spec:
    <span class="c1"># 规范定义资源应该拥有什么样的特性，依靠控制器确保特性能够被满足</span>
    <span class="c1"># 它是用户定义的所期望了资源状态</span>
status:
    <span class="c1"># 显示资源的当前状态，k8s 就是确保当前状态向目标状态无限靠近从而满足用户期望</span>
    <span class="c1"># 它是只读的，代表了资源当前状态</span>
</pre></div>
</div>
<ul class="simple">
<li><p>获取全部的 api 版本</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl api-versions
</pre></div>
</div>
<ul class="simple">
<li><p>获取全部的 api 资源对象</p></li>
</ul>
<p>从内容可以看到一些缩写，方便我们日常命令后简写</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl api-resources

kubectl get po          <span class="c1"># 查看pod</span>
kubectl get deploy      <span class="c1"># 查看deployment</span>
kubectl get svc         <span class="c1"># 查看service</span>
kubectl get cm          <span class="c1"># 查看 configmap</span>
...
</pre></div>
</div>
</div>
<div class="section" id="id25">
<h2><a class="toc-backref" href="#id211">5.3 获取清单帮助</a><a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>查看 k8s 某个内置对象的配置清单格式，应该包含哪些字段，使用 .
来显示字段的格式帮助信息</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl explain pods
kubectl explain pods.metadata
</pre></div>
</div>
</div>
<div class="section" id="id26">
<h2><a class="toc-backref" href="#id212">5.4 清单基本格式</a><a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>定义一个资源清单</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: v1
kind: Pod
metadata:
  name: pod-deme
  namespace: default
  labels:
    app: myapp
    tier: frontend
spec:
  containers:
  - name: myapp
    image: ikubernetes/myapp:v1
  - name: busybox
    image: busybox:latest
    command:
    - <span class="s2">&quot;/bin/sh&quot;</span>
    - <span class="s2">&quot;-c&quot;</span>
    - <span class="s2">&quot;sleep 10&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id27">
<h2><a class="toc-backref" href="#id213">5.5 快捷获取清单</a><a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>使用 -o 参数来指定对象数据的输出格式，使用 –dry-run
来测试性执行一个指令，它两个结合起来，就可以通过命令创建，且生成 yaml
格式配置文件了 -o yaml –dry-run</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create secret docker-registry regsecret --docker-server<span class="o">=</span>registry-vpc.cn-hangzhou.aliyuncs.com --docker-username<span class="o">=</span>admin --docker-password<span class="o">=</span><span class="m">123456</span> --docker-email<span class="o">=</span><span class="m">420123641</span>@qq.com -o yaml --dry-run
</pre></div>
</div>
</div>
<div class="section" id="create">
<h2><a class="toc-backref" href="#id214">5.6 create 创建</a><a class="headerlink" href="#create" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>创建资源清单中的资源，这样创建的为裸 POD
，没有控制器管理，所以删除后不会自动重建，成为自主式 POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create -f pod-demo.yaml
</pre></div>
</div>
</div>
<div class="section" id="delete">
<h2><a class="toc-backref" href="#id215">5.7 delete 删除</a><a class="headerlink" href="#delete" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>删除资源清单中定义的 POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl delete -f pod-demo.yaml
</pre></div>
</div>
</div>
<div class="section" id="apply">
<h2><a class="toc-backref" href="#id216">5.8 apply 创建或更新</a><a class="headerlink" href="#apply" title="Permalink to this headline">¶</a></h2>
<p>apply 可以执行多次，如果发现文件不同，则更新</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f pod-demo.yaml
</pre></div>
</div>
</div>
</div>
<div class="section" id="id28">
<h1><a class="toc-backref" href="#id217">六 POD 配置清单</a><a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h1>
<div class="section" id="pods-metadata-pod">
<h2><a class="toc-backref" href="#id218">6.1 pods.metadata POD元数据</a><a class="headerlink" href="#pods-metadata-pod" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id29">
<h3><a class="toc-backref" href="#id219">6.1.1 labels 标签</a><a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>labels 定义标签，键值对组成的标签</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>labels:
  app: myapp
  tier: frontend
</pre></div>
</div>
</div>
</div>
<div class="section" id="pods-spec">
<h2><a class="toc-backref" href="#id220">6.2 pods.spec 规范</a><a class="headerlink" href="#pods-spec" title="Permalink to this headline">¶</a></h2>
<div class="section" id="nodename">
<h3><a class="toc-backref" href="#id221">6.2.1 nodeName 运行节点</a><a class="headerlink" href="#nodename" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>在使用资源清单定义 pod 时候，使用 nodeName 可以直接绑定资源对象在哪个
POD 运行的节点</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-deme</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">nodeName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">node2</span>                           <span class="c1"># 直接指定 POD 运行的节点</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
</pre></div>
</div>
</div>
<div class="section" id="nodeselector">
<h3><a class="toc-backref" href="#id222">6.2.2 nodeSelector 节点选择</a><a class="headerlink" href="#nodeselector" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>在使用资源清单定义 pod 时候，使用 nodeSelector
（节点标签选择器）字段，来定义节点的倾向性</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-deme</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">nodeSelector</span><span class="p">:</span>                            <span class="c1"># 在 spec 中定义这个 POD 的节点倾向性</span>
    <span class="nt">disktype</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ssd</span>                         <span class="c1"># 这个 POD 最终会运行在拥有 disktype 标签且值为 ssd 的 nodes 上</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
    <span class="nt">ports</span><span class="p">:</span>
</pre></div>
</div>
<ul class="simple">
<li><p>从文件启动 pod，观察 pod 运行的节点，会发现已经运行在有标签的 node
节点上了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create -f pod-demo.yaml
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pods</span> <span class="o">-</span><span class="n">o</span> <span class="n">wide</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME       READY   STATUS    RESTARTS   AGE   IP            NODE    NOMINATED NODE   READINESS GATES
pod-demo   <span class="m">1</span>/1     Running   <span class="m">0</span>          21s   <span class="m">10</span>.244.2.29   node3   &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
</div>
<div class="section" id="restartpolicy-pod">
<h3><a class="toc-backref" href="#id223">6.2.3 restartPolicy POD重启策略</a><a class="headerlink" href="#restartpolicy-pod" title="Permalink to this headline">¶</a></h3>
<p>Always：一旦容器挂了，那么总是重启它，k8s 每次重启策略为 30
秒的两倍，直到等待 300 秒重启。</p>
<p>OnFailure：只有其状态为错误的时候才去重启它</p>
<p>Never：从来不重启，挂了就挂了</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>一旦某个 POD 被调度到某个节点上，只要这个节点在，那么它就不会被重新调度，只能被重启，除非 POD 被删除才会被重新调度，或者 node 挂了，才会被重新调度，否则只要 node 在，那么 POD 就不会被重新调度，如果 POD 启动失败，那么将不断的重启 POD。
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>当需要终止 POD ，k8s 发送 <span class="nb">kill</span> -15 信号，让容器平滑的终止，等待 <span class="m">30</span> 秒的宽限期，如果没有终止，那么则发送 <span class="nb">kill</span> 信号
</pre></div>
</div>
</div>
<div class="section" id="hostnetwork">
<h3><a class="toc-backref" href="#id224">6.2.4 hostNetwork 主机网络空间</a><a class="headerlink" href="#hostnetwork" title="Permalink to this headline">¶</a></h3>
<p>使用布尔值指定是否让 POD 使用主机的网络名称空间</p>
</div>
<div class="section" id="hostpid-pid">
<h3><a class="toc-backref" href="#id225">6.2.5 hostPID 主机PID空间</a><a class="headerlink" href="#hostpid-pid" title="Permalink to this headline">¶</a></h3>
<p>使用布尔值指定是否让 POD 使用主机的PID名称空间</p>
</div>
<div class="section" id="containers">
<h3><a class="toc-backref" href="#id226">6.2.6 containers 配置</a><a class="headerlink" href="#containers" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>kubectl explain pods.spec.containers</p>
</div></blockquote>
<p>描述 POD 内所运行容器，语法：containers
&lt;[]Object&gt;，表示它的值为数组，数组内使用对象的方式来描述一个容器，对象可以有以下参数：</p>
<ul class="simple">
<li><p>可用参数</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 57%" />
<col style="width: 43%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数</p></th>
<th class="head"><p>作用</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>args</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>command</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>env</p></td>
<td><p>向容器传递环境变量</p></td>
</tr>
<tr class="row-odd"><td><p>envFrom</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>image</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>imagePullPolicy</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>lifecycle</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>livenessProbe</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>name</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>ports</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>readinessProbe</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>resources</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>securityContext</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>stdin</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>stdinOnce</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>terminationMessagePath</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>terminationMessagePolicy</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>tty</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>volumeDevices</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>volumeMounts</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>workingDir</p></td>
<td></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>示例型配置</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: v1
kind: Pod
metadata:
  name: pod-deme                     <span class="c1"># pod 的名称</span>
  namespace: default
  labels:
    app: myapp
    tier: frontend
spec:
  containers:
    - name: myapp                      <span class="c1"># 运行的容器名称</span>
      image: ikubernetes/myapp:v1      <span class="c1"># 容器的镜像</span>
      imagePullPolicy: IfNotPresent    <span class="c1"># 从仓库获取镜像的策略</span>
      ports:                           <span class="c1"># 定义容器暴漏的端口</span>
    - name: busybox
      image: busybox:latest
      command:
        - <span class="s2">&quot;/bin/sh&quot;</span>
        - <span class="s2">&quot;-c&quot;</span>
        - <span class="s2">&quot;sleep 10&quot;</span>
</pre></div>
</div>
<div class="section" id="imagepullpolicy">
<h4>6.2.6.1 imagePullPolicy下载策略<a class="headerlink" href="#imagepullpolicy" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>imagePullPolicy
镜像获取的策略，详见：<code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">explain</span> <span class="pre">pods.spec.containers</span></code></p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Always            <span class="c1"># 总是从仓库下载</span>
Never             <span class="c1"># 从不下载，本地有就用，没有就失败</span>
IfNotPresent      <span class="c1"># 如果本地存在就直接使用，如果不存在就下载</span>
</pre></div>
</div>
<blockquote>
<div><p>如果标签是 latest 那么则始终从仓库下载</p>
</div></blockquote>
</div>
<div class="section" id="ports">
<h4>6.2.6.2 ports 端口信息<a class="headerlink" href="#ports" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>ports
定义容器保暴露的，详见：<code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">explain</span> <span class="pre">pods.spec.containers.ports</span></code></p></li>
</ul>
<p>在此处暴露的端口可为系统提供有关容器的网络连接的信息，但主要是信息性的，此处没有指定的端口也不会阻止容器暴露该端口，容器中任何侦听
0.0.0.0 地址的端口都可以从网络访问</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">ports</span><span class="p">:</span>                    <span class="c1"># 定义两个端口对象一个 http 一个 https</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>              <span class="c1"># 定义这个端口的名称，方便别的对象取引用</span>
  <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>       <span class="c1"># 端口号</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https</span>             <span class="c1"># 方便引用的名称</span>
  <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>      <span class="c1"># 这个端口号仅仅是起到信息的作用，方便查看和使用名称引用</span>
</pre></div>
</div>
</div>
<div class="section" id="env">
<h4>6.2.6.3 env 传递环境变量<a class="headerlink" href="#env" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Use Pod fields</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">env</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_NODE_NAME</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">fieldRef</span><span class="p">:</span>
        <span class="nt">fieldPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">spec.nodeName</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_POD_NAME</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">fieldRef</span><span class="p">:</span>
        <span class="nt">fieldPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">metadata.name</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_POD_NAMESPACE</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">fieldRef</span><span class="p">:</span>
        <span class="nt">fieldPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">metadata.namespace</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_POD_IP</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">fieldRef</span><span class="p">:</span>
        <span class="nt">fieldPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">status.podIP</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_POD_SERVICE_ACCOUNT</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">fieldRef</span><span class="p">:</span>
        <span class="nt">fieldPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">spec.serviceAccountName</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Use Container fields</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">env</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_CPU_REQUEST</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">resourceFieldRef</span><span class="p">:</span>
        <span class="nt">containerName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">test-container</span>
        <span class="nt">resource</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">requests.cpu</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_CPU_LIMIT</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">resourceFieldRef</span><span class="p">:</span>
        <span class="nt">containerName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">test-container</span>
        <span class="nt">resource</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">limits.cpu</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_MEM_REQUEST</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">resourceFieldRef</span><span class="p">:</span>
        <span class="nt">containerName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">test-container</span>
        <span class="nt">resource</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">requests.memory</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MY_MEM_LIMIT</span>
    <span class="nt">valueFrom</span><span class="p">:</span>
      <span class="nt">resourceFieldRef</span><span class="p">:</span>
        <span class="nt">containerName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">test-container</span>
        <span class="nt">resource</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">limits.memory</span>
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">在容器中获取 POD 的信息</span>

<span class="l l-Scalar l-Scalar-Plain">可以使用环境变量</span>
<span class="l l-Scalar l-Scalar-Plain">可以使用 downwardAPI</span>
<span class="l l-Scalar l-Scalar-Plain">https://kubernetes.io/zh/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/</span>
</pre></div>
</div>
</div>
<div class="section" id="command-entrypoint">
<h4>6.2.6.4 command ENTRYPOINT<a class="headerlink" href="#command-entrypoint" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>command 定义容器运行的程序，详见：</p></li>
</ul>
<p><a class="reference external" href="https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/">https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/</a></p>
<p>一个 entrypoint array 而 command 启动的程序是不会运行在 Shell
中的，如果想要运行在 Shell
中需要自己填写，如果没有提供这个指令，那么将运行 docker 镜像中的
ENTRYPOINT。</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 21%" />
<col style="width: 17%" />
<col style="width: 22%" />
<col style="width: 18%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Image Entrypoint</p></th>
<th class="head"><p>Image Cmd</p></th>
<th class="head"><p>Container command</p></th>
<th class="head"><p>Container args</p></th>
<th class="head"><p>Command run</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">[/ep-1]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[foo</span> <span class="pre">bar]</span></code></p></td>
<td></td>
<td></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[ep-1</span> <span class="pre">foo</span> <span class="pre">bar]</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">[/ep-1]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[foo</span> <span class="pre">bar]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[/ep-2]</span></code></p></td>
<td></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[ep-2]</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">[/ep-1]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[foo</span> <span class="pre">bar]</span></code></p></td>
<td></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[zoo</span> <span class="pre">boo]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[ep-1</span> <span class="pre">zoo</span> <span class="pre">boo]</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">[/ep-1]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[foo</span> <span class="pre">bar]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[/ep-2]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[zoo</span> <span class="pre">boo]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[ep-2</span> <span class="pre">zoo</span> <span class="pre">boo]</span></code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="args-cmd">
<h4>6.2.6.5 args CMD<a class="headerlink" href="#args-cmd" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>args 向 command 传递参数的</p></li>
</ul>
<p>如果你没有定义 args 而镜像中又存在 ENTRYPOINT 指令和 CMD
指令，那么镜像自己的 CMD 将作为参数传递给 ENTRYPOINT。如果手动指定了
args 那么镜像中的 CMD 字段不再作为参数进行传递。</p>
<p>如果在 args 中引用了变量，则需要使用 $(VAR_NAME)
来引用一个变量，如果不想在这里进行命令替换，那么可以
$$(VAR_NAME)，转义后在容器内使用。</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">env</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MESSAGE</span>
  <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;hello</span><span class="nv"> </span><span class="s">kaliarch&quot;</span>
<span class="nt">command</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;/bin/echo&quot;</span><span class="p p-Indicator">]</span>
<span class="nt">args</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;$(MESSAGE)&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</div>
<div class="section" id="annotations">
<h4>6.2.6.6 annotations 注解信息<a class="headerlink" href="#annotations" title="Permalink to this headline">¶</a></h4>
<p>annotations 与 label
不同的地方在于，它不能用于挑选资源对象，仅为对象提供元数据，它的长度不受限制</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-deme</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
  <span class="nt">annotations</span><span class="p">:</span>                                      <span class="c1"># 注解关键字</span>
    <span class="nt">kaliarch/created-by</span><span class="p">:</span> <span class="s">&quot;xuel&quot;</span>                     <span class="c1"># 添加键值对的资源注解</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
</pre></div>
</div>
</div>
<div class="section" id="id30">
<h4>6.2.6.7 POD 生命周期<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>一般状态</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Pending：已经创建但是没有适合运行它的节点，已经调度，但是尚未完成
Running：运行状态
Failed： 启动失败
Succeed：成功，这个状态很短
Unkown： 未知的状态，如果 Apiserver 与 kubelet 通信失败则会处于这个状态
</pre></div>
</div>
<ul class="simple">
<li><p>创建 POD 阶段</p></li>
</ul>
<p>用户的创建请求提交给 apiserver ，而 apiserver 会将请求的目标状态保存在
etcd 中，而后 apiserver 会请求 schedule 进行调度，并且把调度的结果更新在
etcd 的 pod 状态中，随后一旦保存在 etcd 中，并完成 schedule
更新后目标节点的 kubelet 就会从 etcd
的状态变化得知有新任务给自己，所以此时会拿到用户所希望的资源清单目标状态，根据清单在当前节点运行这个
POD，如果创建成功或者失败，则将结果发回给 apiserver ，apiserver
再次保存在 etcd 中。</p>
</div>
<div class="section" id="livenessprobe">
<h4>6.2.6.8 livenessProbe 存活性探测<a class="headerlink" href="#livenessprobe" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><p>详细见：kubectl explain pods.spec.containers.livenessProbe</p>
</div></blockquote>
<ul class="simple">
<li><p>livenessProbe / readinessProbe 是 k8s
两个生命周期，这两个生命周期都可以定义探针来探测容器状态做出不同反应</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>livenessProbe     <span class="c1"># 指示容器是否正在运行。如果存活探测失败，则依据 restartPolicy 策略来进行重启</span>
readinessProbe    <span class="c1"># 指示容器是否准备好服务请求。如果就绪探测失败端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址</span>
</pre></div>
</div>
<ul class="simple">
<li><p>livenessProbe / readinessProbe
可用的探针和探针特性，探针只能定义一种类型，例如：HTTPGetAction</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">exec</span>          <span class="c1"># 在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。</span>
tcpSocket     <span class="c1"># 对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的。</span>
httpGet       <span class="c1"># HTTP GET 请求指定端口和路径上的容器。如果响应码大于等于200 且小于 400，则诊断被认为是成功的。</span>
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">failureThreshold</span>    <span class="c1"># 探测几次才判定为探测失败，默认为 3 次。</span>
<span class="l l-Scalar l-Scalar-Plain">periodSeconds</span>       <span class="c1"># 每次探测周期的间隔时长。</span>
<span class="l l-Scalar l-Scalar-Plain">timeoutSeconds</span>      <span class="c1"># 每次探测发出后等待结果的超时时间，默认为 1 秒。</span>
<span class="l l-Scalar l-Scalar-Plain">initalDelaySeconds</span>  <span class="c1"># 在容器启动后延迟多久去进行探测，默认为启动容器后立即探测。</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用 exec 探针，实验结果应该为 39 秒后 POD 显示 ERROR ，但不自动重启
POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: v1
kind: Pod
metadata:
  name: execlive
  namespace: default
  labels:
    app: myapp
    tier: frontend
spec:
  containers:
    - name: busybox
      image: busybox
      command:
        - <span class="s2">&quot;/bin/sh&quot;</span>
        - <span class="s2">&quot;-c&quot;</span>
        - <span class="s2">&quot;touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 3600&quot;</span>    <span class="c1"># 创建一个文件等待 30 秒，这个时间探针应该是成功的，30 秒后则失败</span>
      livenessProbe:                                   <span class="c1"># 容器的存活性检测，如果失败则按照 restartPolicy 策略来重启 POD</span>
        exec:                                          <span class="c1"># exec 类型探针，进入容器执行一条命令</span>
          command: <span class="o">[</span><span class="s2">&quot;test&quot;</span>, <span class="s2">&quot;-e&quot;</span> ,<span class="s2">&quot;/tmp/healthy&quot;</span><span class="o">]</span>      <span class="c1"># 执行的命令为测试文件存在性</span>
        initialDelaySeconds: <span class="m">2</span>                         <span class="c1"># 容器启动后延迟多久进行探测</span>
        periodSeconds: <span class="m">3</span>                               <span class="c1"># 每次探测周期的间隔时长为 3 秒</span>
        failureThreshold: <span class="m">3</span>                            <span class="c1"># 3 次失败后则判定为容器探测存活性失败</span>
  restartPolicy: Never                                 <span class="c1"># 当探测到容器失败是否重启 POD</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用 httpGet 探针，实验结果应该大约 40 秒后探测存活性失败，自动重启
POD，第一次重启会立即进行，随后是 30 秒的2倍直到 300 秒。</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">httpgetlive</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>
      <span class="nt">livenessProbe</span><span class="p">:</span>                   <span class="c1"># 容器的存活性检测，如果失败则按照 restartPolicy 策略来重启 POD</span>
        <span class="nt">httpGet</span><span class="p">:</span>                       <span class="c1"># httpget 探针</span>
          <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/error.html</span>            <span class="c1"># 探测的页面，为了效果这个页面不存在</span>
          <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>                   <span class="c1"># 探测的端口，使用名称引用容器的端口</span>
          <span class="nt">httpHeaders</span><span class="p">:</span>                 <span class="c1"># httpget 时候设置请求头</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">X-Custom-Header</span>
              <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Awesome</span>
        <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>        <span class="c1"># 容器启动后延迟多久进行探测</span>
        <span class="nt">timeoutSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>              <span class="c1"># 每次探测发出等待结果的时长</span>
  <span class="nt">restartPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Always</span>                <span class="c1"># 当探测到容器失败是否重启 POD</span>
</pre></div>
</div>
</div>
<div class="section" id="readinessprobe">
<h4>6.2.6.9 readinessProbe 就绪性检测<a class="headerlink" href="#readinessprobe" title="Permalink to this headline">¶</a></h4>
<p>例如有一个容器运行的是 tomcat ，而 tomcat 展开 war
包，部署完成的时间可能较长，而默认 k8s 会在容器启动就标记为 read
状态，接收 service 的调度请求，但是容器启动不代表 tomcat
已经成功运行，所以需要 readinessProbe 进行就绪性探测，来决定是否可以接入
service 上。</p>
<ul class="simple">
<li><p>livenessProbe / readinessProbe
可用的探针和探针特性基本一样，探针只能定义一种类型，例如：HTTPGetAction</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>livenessProbe     <span class="c1"># 指示容器是否正在运行。如果存活探测失败，则依据 restartPolicy 策略来进行重启</span>
readinessProbe    <span class="c1"># 指示容器是否准备好服务请求。如果就绪探测失败端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用 httpGet 探针，实验结果应该大约 40 秒后探测存活性失败，自动重启
POD，第一次重启会立即进行，随后是 30 秒的2倍直到 300 秒。</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">httpgetread</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>
      <span class="nt">livenessProbe</span><span class="p">:</span>                   <span class="c1"># 容器的存活性检测，如果失败则按照 restartPolicy 策略来重启 POD</span>
        <span class="nt">httpGet</span><span class="p">:</span>                       <span class="c1"># httpget 探针</span>
          <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/error.html</span>            <span class="c1"># 探测的页面，为了效果这个页面不存在</span>
          <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>                   <span class="c1"># 探测的端口，使用名称引用容器的端口</span>
          <span class="nt">httpHeaders</span><span class="p">:</span>                 <span class="c1"># httpget 时候设置请求头</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">X-Custom-Header</span>
              <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Awesome</span>
        <span class="nt">initialDelaySeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>        <span class="c1"># 容器启动后延迟多久进行探测</span>
        <span class="nt">timeoutSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>              <span class="c1"># 每次探测发出等待结果的时长</span>
  <span class="nt">restartPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Always</span>                <span class="c1"># 当探测到容器失败是否重启 POD</span>
</pre></div>
</div>
<ul class="simple">
<li><p>手动进入容器，删除 index.html 以触发就绪性探针的检测</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">exec</span> -it httpgetread -- /bin/sh
$ rm -f /usr/share/nginx/html/index.html
</pre></div>
</div>
<ul class="simple">
<li><p>结果这个 POD 的 READY 状态已经变成非就绪了，此时 service
不会再调度到这个节点了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@node1 ~<span class="o">]</span><span class="c1"># kubectl get pods -w</span>
NAME                            READY   STATUS    RESTARTS   AGE
httpgetread                     <span class="m">0</span>/1     Running   <span class="m">0</span>          2m50s
</pre></div>
</div>
<ul class="simple">
<li><p>在容器内再创建一个文件，以触发就绪性探针的检测</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">exec</span> -it httpgetread -- /bin/sh
$ <span class="nb">echo</span> <span class="s2">&quot;hello worlld&quot;</span> &gt;&gt;/usr/share/nginx/html/index.html
</pre></div>
</div>
<ul class="simple">
<li><p>结果这个 POD 的的 READY 状态已经编程就绪了，此时 service
会调度到这个节点了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@node1 ~<span class="o">]</span><span class="c1"># kubectl get pods -w</span>
NAME                            READY   STATUS    RESTARTS   AGE
httpgetread                     <span class="m">1</span>/1     Running   <span class="m">0</span>          8m15s
</pre></div>
</div>
</div>
<div class="section" id="lifecycle">
<h4>6.2.6.10 lifecycle 生命周期钩子<a class="headerlink" href="#lifecycle" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><p>详见：kubectl explain pods.spec.containers.lifecycle</p>
</div></blockquote>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>postStart           <span class="c1"># 在容器启动后立即执行的命令，如果这个操作失败了，那么容器会终止，且根据 restartPolicy 来决定是否重启</span>
preStop             <span class="c1"># 在容器终止前立即执行的命令</span>
</pre></div>
</div>
<ul class="simple">
<li><p>postStart / preStop 的基本使用</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: v1
kind: Pod
metadata:
  name: lifecycle-demo
spec:
  containers:
  - name: lifecycle-demo-container
    image: nginx

    lifecycle:
      postStart:
        exec:
          command: <span class="o">[</span><span class="s2">&quot;/bin/sh&quot;</span>, <span class="s2">&quot;-c&quot;</span>, <span class="s2">&quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;</span><span class="o">]</span>
      preStop:
        exec:
          command: <span class="o">[</span><span class="s2">&quot;/usr/sbin/nginx&quot;</span>,<span class="s2">&quot;-s&quot;</span>,<span class="s2">&quot;quit&quot;</span><span class="o">]</span>
</pre></div>
</div>
<p>POD控制器</p>
<p>控制器管理的 POD 可以实现，自动维护 POD 副本数量，它能实现 POD
的扩容和缩容，但是不能实现滚动更新等高级功能。</p>
</div>
</div>
</div>
</div>
<div class="section" id="id31">
<h1><a class="toc-backref" href="#id227">七 控制器配置清单</a><a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h1>
<div class="section" id="replicaset">
<h2><a class="toc-backref" href="#id228">7.1 ReplicaSet 控制器</a><a class="headerlink" href="#replicaset" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>详见：kubectl explain replicaset</p>
</div></blockquote>
<ul class="simple">
<li><p>清单规范</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion  &lt;string&gt;    <span class="c1"># api 版本号，一般为 apps/v1</span>
kind        &lt;string&gt;    <span class="c1"># 资源类别，标记创建什么类型的资源</span>
metadata    &lt;Object&gt;    <span class="c1"># POD 元数据</span>
spec        &lt;Object&gt;    <span class="c1"># 元数据</span>
</pre></div>
</div>
<div class="section" id="replicaset-spec">
<h3><a class="toc-backref" href="#id229">7.1.1 replicaset.spec 规范</a><a class="headerlink" href="#replicaset-spec" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>replicas 副本数量，指定一个数字</p></li>
<li><p>selector 标签选择器，可以使用 matchLabels、matchExpressions
两种类型的选择器来选中目标 POD</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>matchLabels：直接给定键值
matchExpressions：基于给定的表达式来定义使用标签选择器：<span class="o">{</span>key:<span class="s2">&quot;KEY&quot;</span>,operator:<span class="s2">&quot;OPERATOR&quot;</span>,value:<span class="o">[</span>VAL1,VAL2,...<span class="o">]}</span>
    使用 key 与 value 进行 operator 运算，复合条件的才被选择
    操作符：
        In、NotIn：其 value 列表必须有值
        Exists、NotExists：其 value 必须为空
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>template 模板，这里面定义的就是一个 POD 对象，这个对象只包含了
pod.metadata 和 pod.spec 两部分。</p></li>
</ol>
</div>
<div class="section" id="id32">
<h3><a class="toc-backref" href="#id230">7.1.2 清单示例</a><a class="headerlink" href="#id32" title="Permalink to this headline">¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ReplicaSet</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myrs</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-pod</span>     <span class="c1"># 这个其实没用，因为创建的 POD 以 rs 的名字开头</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>        <span class="c1"># 标签一定要符合 replicaset 标签选择器的规则，否则将陷入创建 pod 的死循环，直到资源耗尽</span>
        <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-containers</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="deployment">
<h2><a class="toc-backref" href="#id231">7.2 Deployment控制器</a><a class="headerlink" href="#deployment" title="Permalink to this headline">¶</a></h2>
<p>Deployment 通过控制 ReplicaSet 来实现功能，除了支持 ReplicaSet
的扩缩容意外，还支持滚动更新和回滚等，还提供了声明式的配置，这个是我们日常使用最多的控制器。它是用来管理无状态的应用。</p>
<p>Deployment 在滚动更新时候，通过控制多个 ReplicaSet 来实现，ReplicaSet
又控制多个 POD，多个 ReplicaSet 相当于多个应用的版本。</p>
<p><img alt="image0" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315174806.png" /></p>
<div class="highlight-mermaid notranslate"><div class="highlight"><pre><span></span>graph TB
Deployment[Deployment] --&gt; replicaset1(replicaset1)
Deployment[Deployment] --&gt; replicaset2(replicaset2)
Deployment[Deployment] --&gt; replicaset3(replicaset3)
replicaset1(replicaset1) --&gt; POD1{POD}
replicaset1(replicaset1) --&gt; POD2{POD}
replicaset2(replicaset1) --&gt; POD5{POD}
replicaset2(replicaset1) --&gt; POD6{POD}
replicaset3(replicaset1) --&gt; POD9{POD}
replicaset3(replicaset1) --&gt; POD10{POD}
</pre></div>
</div>
<ul class="simple">
<li><p>清单规范，详见：kubectl explain deployment</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion  &lt;string&gt;    <span class="c1"># apps/v1</span>

kind        &lt;string&gt;    <span class="c1"># 资源类别，标记创建什么类型的资源</span>

metadata    &lt;Object&gt;    <span class="c1"># POD 元数据</span>

spec        &lt;Object&gt;    <span class="c1"># 元数据</span>
</pre></div>
</div>
<div class="section" id="id33">
<h3><a class="toc-backref" href="#id232">7.2.1 replicaset.spec 对象规范</a><a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>replicas 副本数量，指定一个数字</p></li>
<li><p>selector 标签选择器，可以使用 matchLabels、matchExpressions
两种类型的选择器来选中目标 POD</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>matchLabels：直接给定键值
matchExpressions：基于给定的表达式来定义使用标签选择器：<span class="o">{</span>key:<span class="s2">&quot;KEY&quot;</span>,operator:<span class="s2">&quot;OPERATOR&quot;</span>,value:<span class="o">[</span>VAL1,VAL2,...<span class="o">]}</span>
    使用 key 与 value 进行 operator 运算，复合条件的才被选择
    操作符：
        In、NotIn：其 value 列表必须有值
        Exists、NotExists：其 value 必须为空
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>template 模板，这里面定义的就是一个 POD 对象，这个对象只包含了
pod.metadata 和 pod.spec 两部分。</p></li>
<li><p>strategy 更新策略，支持滚动更新、支持滚动更新的更新方式</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>type：                <span class="c1"># 更新类型，Recreate 替换更新，RollingUpdate 滚动更新策略</span>
rollingUpdate：       <span class="c1"># 滚动更新时候的策略，这是默认的更新策略</span>
    maxSurge：        <span class="c1"># 滚动更新时候允许临时超出多少个，可以指定数量或者百分比，默认 25%</span>
    maxUnavailable：  <span class="c1"># 最多允许多少个 POD 不可用，默认 25%</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Recreate：替换更新会先删除旧的容器组，在创建新的容器组，升级过程中业务会中断</p></li>
<li><p>RollingUpdate：滚动更新将逐步用新版本的实例替代旧版本的实例，升级过程中，业务流量会同时负载到新旧两个版本的POD上，因此业务不会中断。</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>revisionHistoryLimit
滚动更新后最多保存多少个更新的历史版本，值为一个数字</p></li>
<li><p>paused 当更新启动后控制是否暂停</p></li>
</ol>
</div>
<div class="section" id="id34">
<span id="id35"></span><h3><a class="toc-backref" href="#id233">7.2.2 清单示例</a><a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-deploy</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
</pre></div>
</div>
</div>
<div class="section" id="id36">
<h3><a class="toc-backref" href="#id234">7.2.3 关于更新</a><a class="headerlink" href="#id36" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>直接修改清单文件，kubectl apply -f deployment.yaml</p></li>
<li><p>使用 kubectl patch 使用 json 格式给出更新的内容</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl patch deployment myapp-deploy -p <span class="s1">&#39;{&quot;spec&quot;:{&quot;replicas&quot;:5}}&#39;</span>    <span class="c1"># 修改 POD 副本数量</span>

kubectl patch deployment myapp-deploy -p <span class="s1">&#39;{&quot;spec&quot;:{&quot;strategy&quot;:{&quot;rollingUpdate&quot;:{&quot;maxSurge&quot;:1,&quot;maxUnavailable&quot;:0}}}}&#39;</span>                                 <span class="c1"># 修改更新策略</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>仅更新镜像 kubectl set image</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">set</span> image deployment myapp-deploy <span class="nv">myapp</span><span class="o">=</span>ikubernetes/myapp:v3
</pre></div>
</div>
</div>
<div class="section" id="id37">
<h3><a class="toc-backref" href="#id235">7.2.4 模拟金丝雀发布</a><a class="headerlink" href="#id37" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>在更新刚刚启动的时候，将更新过程暂停，那么只能更新一个，这实现了在集群中增加一个金丝雀版本</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">set</span> image deployment myapp-deploy <span class="nv">myapp</span><span class="o">=</span>ikubernetes/myapp:v3 <span class="o">&amp;&amp;</span> kubectl rollout pause deployment myapp-deploy
</pre></div>
</div>
<ul class="simple">
<li><p>查看已经被更新中被暂停的控制器状态，可以看到一直处于暂停状态的
deployment</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl rollout status deployment myapp-deploy
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Waiting <span class="k">for</span> deployment <span class="s2">&quot;myapp-deploy&quot;</span> rollout to finish: <span class="m">1</span> out of <span class="m">5</span> new replicas have been updated...

等待部署<span class="s2">&quot;myapp-deploy&quot;</span>部署完成: 5个新副本中的1个已更新...
</pre></div>
</div>
<ul class="simple">
<li><p>如果金丝雀没有问题，那么继续可以使用继续更新的命令</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl rollout resume deployment myapp-deploy
</pre></div>
</div>
</div>
<div class="section" id="id38">
<h3><a class="toc-backref" href="#id236">7.2.5 更新策略</a><a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>最大不可用为 0 ，更新时候可以临时超出1个</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl patch deployment myapp-deploy -p <span class="s1">&#39;{&quot;spec&quot;:{&quot;strategy&quot;:{&quot;rollingUpdate&quot;:{&quot;maxSurge&quot;:1,&quot;maxUnavailable&quot;:0}}}}&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="id39">
<h3><a class="toc-backref" href="#id237">7.2.6 关于回滚</a><a class="headerlink" href="#id39" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>rollout undo 是回滚的命令，默认滚回上一版本</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl rollout undo deployment myapp-deploy
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>查看可以回滚的版本</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl rollout <span class="nb">history</span> deployment myapp-deploy
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>rollout undo 指定回滚的版本</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl rollout undo deployment myapp-deploy --to-revision<span class="o">=</span><span class="m">2</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>查看当前的工作版本</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get rs -o wide
</pre></div>
</div>
</div>
</div>
<div class="section" id="daemonset">
<h2><a class="toc-backref" href="#id238">7.3 DaemonSet控制器</a><a class="headerlink" href="#daemonset" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>清单规范，详见 kubectl explain daemonset</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion  &lt;string&gt;    <span class="c1"># apps/v1</span>

kind        &lt;string&gt;    <span class="c1"># 资源类别，标记创建什么类型的资源</span>

metadata    &lt;Object&gt;    <span class="c1"># POD 元数据</span>

spec        &lt;Object&gt;    <span class="c1"># 元数据</span>
</pre></div>
</div>
<div class="section" id="daemonset-spec">
<h3><a class="toc-backref" href="#id239">7.3.1 DaemonSet.spec规范</a><a class="headerlink" href="#daemonset-spec" title="Permalink to this headline">¶</a></h3>
<p>此处只列举不同之处</p>
<ol class="arabic simple">
<li><p>updateStrategy
更新策略，支持滚动更新、支持滚动更新的更新方式，默认滚动更新每个 node</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rollingUpdate   <span class="c1"># 滚动更新，它只有一个 rollingUpdate 参数，表示每次更新几个 node 上的  DaemonSet 任务</span>
OnDelete        <span class="c1"># 在删除时更新</span>
</pre></div>
</div>
</div>
<div class="section" id="id40">
<span id="id41"></span><h3><a class="toc-backref" href="#id240">7.3.2 清单示例</a><a class="headerlink" href="#id40" title="Permalink to this headline">¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
      <span class="nt">role</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">logstor</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
        <span class="nt">role</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">logstor</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis:4.0-alpine</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6379</span>
<span class="nn">---</span>                                         <span class="c1"># 可以使用 --- 来分隔多个记录</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DaemonSet</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">filebeat-daemonset</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">filebeat</span>
      <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">stalbe</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">filebeat</span>
        <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">stalbe</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">filebeat</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/filebeat:5.6.5-alpine</span>
          <span class="nt">env</span><span class="p">:</span>                                         <span class="c1"># 向容器传递环境变量</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">REDIS_HOST</span>                         <span class="c1"># 容器内的环境变量名称</span>
              <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis.default.svc.cluster.local</span>   <span class="c1"># 环境变量值，指向 redis service</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">REDIS_LOG_LEVEL</span>
              <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">info</span>
</pre></div>
</div>
</div>
<div class="section" id="id42">
<span id="id43"></span><h3><a class="toc-backref" href="#id241">7.3.3 关于更新</a><a class="headerlink" href="#id42" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>更新 filebeat-daemonset 这个 daemonset 控制器下的 filebeat 容器的镜像</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">set</span> image daemonsets filebeat-daemonset <span class="nv">filebeat</span><span class="o">=</span>ikubernetes/filebeat:5.6.6-alpine
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id44">
<h1><a class="toc-backref" href="#id242">八 Service 配置清单</a><a class="headerlink" href="#id44" title="Permalink to this headline">¶</a></h1>
<p>Service 为 POD 控制器控制的 POD 集群提供一个固定的访问端点，Service
的工作还依赖于 K8s 中的一个附件，就是 CoreDNS ，它将 Service
地址提供一个域名解析。</p>
<div class="section" id="id45">
<h2><a class="toc-backref" href="#id243">8.1 Service 工作模式</a><a class="headerlink" href="#id45" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>userspace: 1.1 之前版本</p></li>
<li><p>iptables: 1.10 之前版本</p></li>
<li><p>ipvs：1.11 之后版本</p></li>
</ol>
</div>
<div class="section" id="id46">
<h2><a class="toc-backref" href="#id244">8.2 Service 类型</a><a class="headerlink" href="#id46" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18%" />
<col style="width: 82%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>类型</p></th>
<th class="head"><p>作用</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ClusterIP</p></td>
<td><p>默认值，分配一个 Service 网络的地址，仅用于集群内部通信</p></td>
</tr>
<tr class="row-odd"><td><p>NodePort</p></td>
<td><p>如果需要集群外部访问，可以使用这个类型</p></td>
</tr>
<tr class="row-even"><td><p>ExternalName</p></td>
<td><p>把集群外部的服务引入到集群内部，方便在集群内部使用</p></td>
</tr>
<tr class="row-odd"><td><p>LoadBalancer</p></td>
<td><p>K8S 工作在云环境中，调用云环境创建负载均衡器</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id47">
<h2><a class="toc-backref" href="#id245">8.3 资源记录</a><a class="headerlink" href="#id47" title="Permalink to this headline">¶</a></h2>
<p>SVC_NAME.NS_NAME.DOMAIN.LTD</p>
<p>例如：redis.default.svc.cluster.local.</p>
</div>
<div class="section" id="id48">
<h2><a class="toc-backref" href="#id246">8.4 Service 清单</a><a class="headerlink" href="#id48" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>清单组成</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion  &lt;string&gt;    <span class="c1"># api 版本号，v1</span>
kind        &lt;string&gt;    <span class="c1"># 资源类别，标记创建什么类型的资源</span>
metadata    &lt;Object&gt;    <span class="c1"># POD 元数据</span>
spec        &lt;Object&gt;    <span class="c1"># 元数据</span>
</pre></div>
</div>
</div>
<div class="section" id="service-spec">
<h2><a class="toc-backref" href="#id247">8.5 service.spec 规范</a><a class="headerlink" href="#service-spec" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>clusterIP：指定 Service 处于 service 网络的哪个 IP，默认为动态分配</p></li>
<li><p>type： service 类型，可用：ExternalName, ClusterIP, NodePort, and
LoadBalancer</p></li>
</ol>
</div>
<div class="section" id="clusterip-service">
<h2><a class="toc-backref" href="#id248">8.6 ClusterIP 类型的 service</a><a class="headerlink" href="#clusterip-service" title="Permalink to this headline">¶</a></h2>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
    <span class="nt">role</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">logstor</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterIP</span>
  <span class="nt">clusterIP</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.96.0.100</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6379</span>         <span class="c1"># service 端口</span>
      <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6379</span>   <span class="c1"># pod 监听的端口</span>
      <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
</pre></div>
</div>
</div>
<div class="section" id="nodeport-service">
<h2><a class="toc-backref" href="#id249">8.7 NodePort 类型的 service</a><a class="headerlink" href="#nodeport-service" title="Permalink to this headline">¶</a></h2>
<p>NodePort 是在 ClusterIP 类型上增加了一个暴露在了 node
的网络命名空间上的一个
nodePort，所以用户可以从集群外部访问到集群了，因而用户的请求流程是：Client
-&gt; NodeIP:NodePort -&gt; ClusterIP:ServicePort -&gt; PodIP:ContainerPort。</p>
<p>可以理解为 NodePort 增强了 ClusterIP
的功能，让客户端可以在每个集群外部访问任意一个 nodeip 从而访问到
clusterIP，再由 clusterIP 进行负载均衡至 POD。</p>
<ul class="simple">
<li><p>清单示例</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NodePort</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>         <span class="c1"># service 端口</span>
      <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>   <span class="c1"># pod 监听的端口</span>
      <span class="nt">nodePort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">30080</span>    <span class="c1"># service 会在每个 node 上添加 iptables/ipvs 规则重定向这个端口的访问，所以必须保证所有 node 的这个端口没被占用</span>
      <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>在集群外部就可以使用: http://172.16.100.102:30080 来访问这个 service 地址了
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>在集群内可以使用 service 的域名在 coredns 上解析得到 service 地址: dig -t A myapp.default.svc.cluster.local @10.96.0.10
</pre></div>
</div>
</div>
<div class="section" id="loadbalancerip">
<h2><a class="toc-backref" href="#id250">8.8 loadBalancerIP 类型</a><a class="headerlink" href="#loadbalancerip" title="Permalink to this headline">¶</a></h2>
<p>service 在每台主机的 iptables/ipvs 规则内，访问任意一台 node 都可以到达
pod，所以应该在这些 nodeip 前加负载均衡器，如果工作在公有云，可以使用
k8s 内置的
loadBalancerIP，操作公有云的负载均衡器即服务，实现动态的增删。</p>
<p>可以理解为 loadBalancerIP 增强了 NodePort 类型的 service
，在集群外部对每台 nodeip 进行负载均衡。</p>
</div>
<div class="section" id="id49">
<h2><a class="toc-backref" href="#id251">8.9 无集群地址的 Service</a><a class="headerlink" href="#id49" title="Permalink to this headline">¶</a></h2>
<p>无头 service 表示 service 没有 ClusterIP 也不映射 NodePort，而是将
service 的域名直接解析为 nodeIP 从而直接访问 nodeIP 上的 POD。</p>
<ul class="simple">
<li><p>清单示例</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">Service</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">myapp</span><span class="o">-</span><span class="n">nohead</span>
  <span class="n">namespace</span><span class="p">:</span> <span class="n">default</span>
<span class="n">spec</span><span class="p">:</span>
  <span class="n">selector</span><span class="p">:</span>
    <span class="n">app</span><span class="p">:</span> <span class="n">myapp</span><span class="o">-</span><span class="n">nohead</span>
    <span class="n">release</span><span class="p">:</span> <span class="n">canary</span>
  <span class="nb">type</span><span class="p">:</span> <span class="n">ClusterIP</span>
  <span class="n">clusterIP</span><span class="p">:</span> <span class="kc">None</span>
  <span class="n">ports</span><span class="p">:</span>
    <span class="o">-</span> <span class="n">port</span><span class="p">:</span> <span class="mi">80</span>         <span class="c1"># service 端口</span>
      <span class="n">targetPort</span><span class="p">:</span> <span class="mi">80</span>   <span class="c1"># pod 监听的端口</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看 CoreDNS 服务器的地址</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get svc -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>在集群内使用 CoreDNS 的地址解析无头的 serive 域名，得到的直接为
nodeip 中的 pod 地址，利用 dns 的多条 A 记录来负载均衡</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>dig -t A myapp-nohead.default.svc.cluster.local. @10.96.0.10
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">;;</span> <span class="n">ANSWER</span> <span class="n">SECTION</span><span class="p">:</span>
<span class="n">myapp</span><span class="o">-</span><span class="n">nohead</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="n">svc</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">local</span><span class="o">.</span> <span class="mi">5</span> <span class="n">IN</span> <span class="n">A</span>  <span class="mf">10.244</span><span class="o">.</span><span class="mf">1.75</span>
<span class="n">myapp</span><span class="o">-</span><span class="n">nohead</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="n">svc</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">local</span><span class="o">.</span> <span class="mi">5</span> <span class="n">IN</span> <span class="n">A</span>  <span class="mf">10.244</span><span class="o">.</span><span class="mf">2.74</span>
</pre></div>
</div>
</div>
<div class="section" id="externalname">
<h2><a class="toc-backref" href="#id252">8.10 externalName 类型</a><a class="headerlink" href="#externalname" title="Permalink to this headline">¶</a></h2>
<p>当 POD 需要访问一个集群外部的服务时候，externalName
可以映射一个集群外部的服务到集群内部，供集群内 POD 访问。</p>
<p>就是把外部的一个域名地址，映射为集群内部 coredns
解析的一个内部地址，提供集群内部访问。</p>
</div>
</div>
<div class="section" id="ingress">
<h1><a class="toc-backref" href="#id253">九 ingress 控制器</a><a class="headerlink" href="#ingress" title="Permalink to this headline">¶</a></h1>
<p>如果 k8s 需要提供一个网站，并且这个站点需要以 https 访问，而
iptables/ipvs 工作在 4 层，客户发出的 ssl 请求根本不被解析就被调度到后端
POD了。解决方法有两个：</p>
<ol class="arabic simple">
<li><p>可以在公有云的负载均衡器上配置上 ssl 证书。</p></li>
<li><p>新建一个负载均衡器的 POD ，例如 nignx ，这个 POD
共享主机的网络命名空间，也就是说可以直接通过 nodeip
访问到负载均衡器，ssl 证书配置在这个负载均衡器上，对外连接为 https
而对内的代理为 http 协议到 POD 网络的 POD 上。</p></li>
</ol>
<ul class="simple">
<li><p>存在的问题</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>- 负载均衡器 POD 使用节点的网络名称空间, 那么它只   能在这个 node 节点上运行一个了,否则就出现端口冲突
- 负载均衡器是代理 POD 卸载 ssl 证书的关键节点, 它不能只运行一个, 它需要在所有节点运行一个
</pre></div>
</div>
<ul class="simple">
<li><p>解决方法</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>- 负载均衡器使用 DaemonSet 在每个 node 节点运行一个,代理请求至 POD 网络的中的 POD 上
- 如果集群节点非常的多,其实不必在每个 node 节点都必须运行一个负载均衡器 POD
- 控制负载均衡器 POD 运行的数量可以通过 lables 指定运行那几个 node 节点上
- 然后可以在负载均衡器 POD 所在的 node 节点上打上 <span class="s2">&quot;污点&quot;</span> 使其他的 POD 不会再被调度上来, 而只有负载均衡器 POD 可以容忍这些 <span class="s2">&quot;污点&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>负载均衡器可选，按照优先级先后排序</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Envoy            <span class="c1"># 云原生高性能服务代理,已从cncf毕业</span>
Traefik          <span class="c1"># 为微服务而生的反向代理</span>
Nginx            <span class="c1"># 改造后可以适用于微服务环境</span>
HAproxy          <span class="c1"># 不推荐使用</span>
</pre></div>
</div>
<p>新建一个 service 将需要代理的不同服务的 pod 分类</p>
<p>新建一个 ingress 资源，从 service 中取得分类结果，映射进 Envoy 中，重载
Envoy 软件。</p>
<div class="section" id="ingress-spec">
<h2><a class="toc-backref" href="#id254">9.1 ingress.spec 规范</a><a class="headerlink" href="#ingress-spec" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>API 和 kind</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: extensions

kind: ingress
</pre></div>
</div>
<ul class="simple">
<li><p>ingress.spec</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>backend         <span class="c1"># 后端有哪些 POD</span>
rules           <span class="c1"># 调度规则</span>
    host        <span class="c1"># 虚拟主机</span>
    http        <span class="c1"># http 路径</span>
</pre></div>
</div>
</div>
<div class="section" id="ingress-nginx">
<h2><a class="toc-backref" href="#id255">9.2 ingress-nginx 代理</a><a class="headerlink" href="#ingress-nginx" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>后端 service 和 pods</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service-ingress-myapp</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
      <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v2</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
</pre></div>
</div>
<ul class="simple">
<li><p>创建 ingress-nginx</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.21.0/deploy/mandatory.yaml
</pre></div>
</div>
<ul class="simple">
<li><p>让 ingress-nginx 在集群外部访问</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.21.0/deploy/provider/baremetal/service-nodeport.yaml
</pre></div>
</div>
<ul class="simple">
<li><p>创建 ingress 对象，它能将 ingress-nginx 与 service 关联，从而在
service 后主机发生变动的时候，反应在 ingress-nginx
这个容器的配置文件中</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">extensions/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ingress-deploy-myapp</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">annotations</span><span class="p">:</span>
    <span class="nt">kubernetes.io/ingress.class</span><span class="p">:</span> <span class="s">&quot;nginx&quot;</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">rules</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">host</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp.kaliarch.com</span>                       <span class="c1"># 基于主机名的访问</span>
      <span class="nt">http</span><span class="p">:</span>
        <span class="nt">paths</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">path</span><span class="p">:</span>                                   <span class="c1"># 空的时候代表根，访问根的时候映射到 backend</span>
            <span class="nt">backend</span><span class="p">:</span>                                <span class="c1"># 后端的 service 的配置</span>
              <span class="nt">serviceName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service-ingress-myapp</span>    <span class="c1"># 关联 service 从而获取到后端主机的变动</span>
              <span class="nt">servicePort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>                       <span class="c1"># 关联 service 的地址</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看 ingress-nginx 对外暴露的端口，这里为30080，和 30443 两个</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get service -n ingress-nginx
</pre></div>
</div>
<ul class="simple">
<li><p>使用 nodeip + ingress-nginx 暴露端口访问，由于上面创建的 ingress
为基于主机名称的，所以需要在访问时在 /etc/hosts 做好映射到 node。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>http://myapp.kaliarch.com:30080/index.html
</pre></div>
</div>
</div>
<div class="section" id="ingress-tomcat">
<h2><a class="toc-backref" href="#id256">9.3 ingress-tomcat 代理</a><a class="headerlink" href="#ingress-tomcat" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>后端 service 和 pods</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service-ingress-tomcat</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tomcat</span>
    <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
      <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ajp</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8009</span>
      <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ajp</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">deploy-tomcat</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tomcat</span>
      <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tomcat</span>
        <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tomcat</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tomcat:8.5.32-jre8-alpine</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ajp</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8009</span>
</pre></div>
</div>
<ul class="simple">
<li><p>制作自签名证书，让 ingress-nginx 带有证书来访问</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 生成 key</span>
openssl genrsa -out tls.key <span class="m">2048</span>

<span class="c1"># 生成自签证书，CN=域名必须要与自己的域名完全一致</span>
openssl req -new -x509 -key tls.key -out tls.crt -subj /C<span class="o">=</span>CN/ST<span class="o">=</span>Beijing/L<span class="o">=</span>Beijing/O<span class="o">=</span>DevOps/CN<span class="o">=</span>tomcat.kaliarch.com
</pre></div>
</div>
<ul class="simple">
<li><p>创建 secret 证书对象，它是标准的 k8s 对象</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create secret tls tomcat-ingress-secret --cert<span class="o">=</span>tls.crt --key<span class="o">=</span>tls.key
</pre></div>
</div>
<ul class="simple">
<li><p>创建带证书的 ingress 对象，它能将 ingress-tomcat 与 service
关联，从而在 service 后主机发生变动的时候，反应在 ingress-tomcat
这个容器的配置文件中</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">extensions/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ingress-deploy-tomcat-tls</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">annotations</span><span class="p">:</span>
    <span class="nt">kubernetes.io/ingress.class</span><span class="p">:</span> <span class="s">&quot;nginx&quot;</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">tls</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">hosts</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">tomcat.kaliarch.com</span>
      <span class="nt">secretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tomcat-ingress-secret</span>
  <span class="nt">rules</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">host</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tomcat.kaliarch.com</span>
      <span class="nt">http</span><span class="p">:</span>
        <span class="nt">paths</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">path</span><span class="p">:</span>
            <span class="nt">backend</span><span class="p">:</span>
              <span class="nt">serviceName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">service-ingress-tomcat</span>
              <span class="nt">servicePort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看 ingress-nginx 对外暴露的端口，这里为30080，和 30443 两个</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get service -n ingress-nginx
</pre></div>
</div>
<ul class="simple">
<li><p>使用 nodeip + ingress-nginx 暴露端口访问，由于上面创建的 ingress
为基于主机名称的，所以需要在访问时在 /etc/hosts 做好映射到 node。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>https://tomcat.kaliarch.com:30443
</pre></div>
</div>
</div>
</div>
<div class="section" id="id50">
<h1><a class="toc-backref" href="#id257">十 POD 存储卷</a><a class="headerlink" href="#id50" title="Permalink to this headline">¶</a></h1>
<p>大部分有状态的应用都有持久存储，在 Docker
上我们将容器所需要的存储卷放在宿主机上，但是 k8s 上不行，因为 POD
会被在不同的 node 节点上创建删除，所以 k8s
需要一套另外的存储卷机制，它能脱离节点为整个集群提供持久存储。</p>
<p>k8s 提供了多种不同的存储卷，k8s 中存储卷属于 POD 而不是容器，POD
可以挂载，POD 为什么能有存储卷呢？这是因为在所有节点上运行了一个 Pause
的镜像，它是 POD 的基础架构容器，它拥有存储卷，同一个 POD
内的所有容器是一个网络名称空间的。</p>
<div class="section" id="id51">
<h2><a class="toc-backref" href="#id258">10.1 卷的类型</a><a class="headerlink" href="#id51" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>查看 POD 支持的存储类型：kubectl explain pods.spec.volumes</p>
</div></blockquote>
<ol class="arabic simple">
<li><p>HostPath：在节点本地新建一个路径，与容器建立关联关系，但节点挂了的数据也不存在了，所以也不具有持久性，容器被调度到别的
node 时候不能跨节点使用HostPath。</p></li>
<li><p>Local：直接使用节点的设备、也支持一个目录类似于 HostPath。</p></li>
<li><p>EmptyDir：只在节点本地使用，一旦 POD
删除，存储卷也会删除，它不具有持久性，当临时目录或者缓存。</p></li>
<li><p>网络存储：iSCSI、NFS、Cifs、glusterfs、cephfs、EBS（AWS)、Disk（Azone）</p></li>
</ol>
</div>
<div class="section" id="id52">
<h2><a class="toc-backref" href="#id259">10.2 容器挂载选项</a><a class="headerlink" href="#id52" title="Permalink to this headline">¶</a></h2>
<p>在 K8S 中卷是属于 POD 的，而不是容器，所以卷的定义在 POD 中，一个 POD
中可以定义多个卷。</p>
<ul class="simple">
<li><p>在 POD 中挂载使用，kubectl explain pods.spec.containers.volumeMounts</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: v1
kind: Pod
metadata:
  name: myapp
  namespace: default
  labels:
    app: myapp
spec:
  containers:
  - name: myapp
    image: ikubernetes/myapp:v1
    volumeMounts        &lt;<span class="o">[]</span>Object&gt;  <span class="c1"># 卷挂载对象</span>
      mountPath         &lt;string&gt;    <span class="c1"># 挂载路径</span>
      mountPropagation  &lt;string&gt;    <span class="c1"># 确定挂载如何从主机传播到容器</span>
      name              &lt;string&gt;    <span class="c1"># 挂载哪个卷</span>
      readOnly          &lt;boolean&gt;   <span class="c1"># 是否只读挂载</span>
      subPath           &lt;string&gt;    <span class="c1"># 挂载在子路径下</span>
      subPathExpr       &lt;string&gt;    <span class="c1"># 与 subPath 类似，挂载在子路径下，不同的是可以使用 $(VAR_NAME) 表示容器扩展这个变量</span>
</pre></div>
</div>
</div>
<div class="section" id="id53">
<h2><a class="toc-backref" href="#id260">10.3 节点存储</a><a class="headerlink" href="#id53" title="Permalink to this headline">¶</a></h2>
<div class="section" id="hostpath">
<h3><a class="toc-backref" href="#id261">10.3.1 hostpath存储卷</a><a class="headerlink" href="#hostpath" title="Permalink to this headline">¶</a></h3>
<p>在宿主机的路径挂载到 POD 上，POD 删除后，卷数据是不会随之删除的，但如果
node 节点挂掉，那么数据有可能丢失，如果 POD
被调度到其他的节点，那么原来卷的数据就访问不到了。</p>
<blockquote>
<div><p><a class="reference external" href="https://kubernetes.io/docs/concepts/storage/volumes/#hostpath">https://kubernetes.io/docs/concepts/storage/volumes/#hostpath</a></p>
</div></blockquote>
<ul class="simple">
<li><p>定义参数，kubectl explain pods.spec.volumes.hostPath</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>path    &lt;string&gt;  <span class="c1"># 主机上目录的路径。 如果路径是符号链接，则会跟随真实路径的链接。</span>
<span class="nb">type</span>    &lt;string&gt;  <span class="c1"># 见下表</span>
</pre></div>
</div>
<ul class="simple">
<li><p>示例</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
    <span class="nt">volumeMounts</span><span class="p">:</span>                       <span class="c1"># 容器挂载哪些卷</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">webstore</span>                    <span class="c1"># 挂载哪个卷</span>
      <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html</span>  <span class="c1"># 挂载到容器内哪个目录</span>
      <span class="nt">readOnly</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>                   <span class="c1"># 是否只读</span>
  <span class="nt">volumes</span><span class="p">:</span>                              <span class="c1"># 存储卷属于POD的（不属于容器)</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">webstore</span>                      <span class="c1"># 存储卷对象名字</span>
    <span class="nt">hostPath</span><span class="p">:</span>                           <span class="c1"># hostpath 类型的存储卷对象</span>
      <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/myapp</span>                 <span class="c1"># 处于宿主机的目录</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DirectoryOrCreate</span>           <span class="c1"># 不存在则创建</span>
</pre></div>
</div>
</div>
<div class="section" id="gitrepo">
<h3><a class="toc-backref" href="#id262">10.3.2 gitRepo卷</a><a class="headerlink" href="#gitrepo" title="Permalink to this headline">¶</a></h3>
<p>将 git 仓库的内容当作存储使用，在 POD
创建时候连接到仓库，并拉取仓库，并将它挂载到容器内当作一个存储卷。</p>
<p>它其实是建立在 emptyDir 的基础上，但是对卷的操作不会同步到 gitrepo 上。</p>
<p>注意：需要在各运行pod的node节点上安装git工具，用于git的拉取</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">run</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gitrepo</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gitrepo</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx:latest</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gitrepo</span>
    <span class="nt">volumeMounts</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gitrepo</span>
        <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html</span>
  <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gitrepo</span>
      <span class="nt">gitRepo</span><span class="p">:</span>
        <span class="nt">repository</span><span class="p">:</span> <span class="s">&quot;https://gitee.com/rocket049/mysync.git&quot;</span>
        <span class="nt">revision</span><span class="p">:</span> <span class="s">&quot;master&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="emptydir">
<h3><a class="toc-backref" href="#id263">10.3.3 emptyDir缓存卷</a><a class="headerlink" href="#emptydir" title="Permalink to this headline">¶</a></h3>
<p>它使用宿主机一个目录作为挂载点，随着 POD
生命周期的结束，其中的数据也会丢失，但是它有一个非常大的优点就是可以使用内存当作存储空间挂载使用。</p>
<p>它可以用在 POD 中两个容器中有一些数据需要共享时候选用。</p>
<ul class="simple">
<li><p>定义 emptyDir 参数，<code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">explain</span> <span class="pre">pods.spec.volumes.emptyDir</span></code></p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>medium      &lt;string&gt;    <span class="c1"># 使用 &quot;&quot; 表示使用 Disk 来存储，使用 Memory 表示使用内存</span>
sizeLimit   &lt;string&gt;    <span class="c1"># 限制存储空间的大小</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用示例</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-volume-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
      <span class="nt">emptyDir</span><span class="p">:</span> <span class="p p-Indicator">{}</span>      <span class="c1"># 使用磁盘，且没有容量限制</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
      <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
          <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html/</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox:latest</span>
      <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
      <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
          <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/</span>
      <span class="nt">command</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;/bin/sh&quot;</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;-c&quot;</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;while</span><span class="nv"> </span><span class="s">true;</span><span class="nv"> </span><span class="s">do</span><span class="nv"> </span><span class="s">date</span><span class="nv"> </span><span class="s">&gt;&gt;</span><span class="nv"> </span><span class="s">/data/index.html;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">10;</span><span class="nv"> </span><span class="s">done&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用示例</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-volume-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
      <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
          <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html/</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox:latest</span>
      <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
      <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
          <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/</span>
      <span class="nt">command</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;/bin/sh&quot;</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;-c&quot;</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;while</span><span class="nv"> </span><span class="s">true;</span><span class="nv"> </span><span class="s">do</span><span class="nv"> </span><span class="s">date</span><span class="nv"> </span><span class="s">&gt;&gt;</span><span class="nv"> </span><span class="s">/data/index.html;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">10;</span><span class="nv"> </span><span class="s">done&quot;</span>
  <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
      <span class="nt">emptyDir</span><span class="p">:</span>
        <span class="nt">medium</span><span class="p">:</span> <span class="s">&quot;&quot;</span>
        <span class="nt">sizeLimit</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1536Mi</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id54">
<h2><a class="toc-backref" href="#id264">10.4 网络存储</a><a class="headerlink" href="#id54" title="Permalink to this headline">¶</a></h2>
<p>网络存储，就是脱离了节点生命周期的存储设备，即使 pod 被调度到别的 node
节点上，仍然可以挂载使用其中的数据。</p>
<div class="section" id="nfs">
<h3><a class="toc-backref" href="#id265">10.4.1 nfs</a><a class="headerlink" href="#nfs" title="Permalink to this headline">¶</a></h3>
<p>nfs 服务器是存在于集群之外的服务器，它不受 node 节点的影响，因而在 node
节点宕机后仍然能够提供持久存储给其他 POD。</p>
<ul class="simple">
<li><p>在 k8s 的 node 找一个主机，安装配置 nfs 服务器并启动</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ yum install nfs-utils                                                     <span class="c1"># 安装 nfs 服务</span>
$ mkdir -p /data/volumes                                                    <span class="c1"># 创建 volume 卷目录</span>
<span class="nb">echo</span> <span class="s1">&#39;/data/volumes  172.16.100.0/16(rw,no_root_squash)&#39;</span> &gt;&gt; /etc/exports    <span class="c1"># 配置 nfs 服务器</span>
$ systemctl start nfs                                                       <span class="c1"># 启动 nfs 服务器</span>
$ ss -tnl                                                                   <span class="c1"># 确认监听端口，nfs 监听 TCP 2049 端口</span>
</pre></div>
</div>
<ul class="simple">
<li><p>在 k8s 集群的 node 节点安装 nfs 驱动，测试挂载是否正常</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ yum install nfs-utils
$ mount -t nfs <span class="m">172</span>.16.100.104:/data/volumes /mnt
</pre></div>
</div>
<ul class="simple">
<li><p>定义 nfs 参数，kubectl explain pods.spec.volumes.nfs</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>path      &lt;string&gt;       <span class="c1"># nfs 服务器的路径</span>
readOnly  &lt;boolean&gt;      <span class="c1"># 是否只读</span>
server    &lt;string&gt;       <span class="c1"># nfs 服务器地址</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用示例</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-vol-nfs-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
    <span class="nt">volumeMounts</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
        <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html/</span>
  <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
      <span class="nt">nfs</span><span class="p">:</span>
        <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/volumes</span>
        <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.16.100.104</span>
</pre></div>
</div>
<p>注意⚠️：各个node节点也需要安装<code class="docutils literal notranslate"><span class="pre">yum</span> <span class="pre">install</span> <span class="pre">nfs-utils</span></code>,不让在挂载的时候会出现异常。</p>
</div>
</div>
<div class="section" id="id55">
<h2><a class="toc-backref" href="#id266">10.5 分布式存储</a><a class="headerlink" href="#id55" title="Permalink to this headline">¶</a></h2>
<p>分布式存储能提供脱离节点生命周期的存储，又比网络存储更加健壮，它是分布式的，有很强的高可用性，但是分布式存储配置复杂，在由
NFS 提供的网络储存中，用户需要知道分配给 POD 的 NFS
存储的地址才能使用，而在由分布式提供的存储能力的存储上，用户需要充分了解该分布式存储的配置参数，才能够使用这个分布式存储。</p>
<p>由此 K8S 提供了 PV、PVC
两种机制，让普通用户无需关心底层存储参数的配置，只需要说明需要使用多大的持久存储，就可以了。</p>
<p>一般 PV 与 PVC 是一对绑定的，PV属于全局，PVC 属于某个名称空间，当一个 PV
被一个 PVC 绑定，别的名称空间 PVC 就不可以再绑定了。请求绑定某个 PV
就是由 PVC 来完成的，被 PVC 绑定的 PV 称作 PV 的绑定状态。</p>
<p>PVC 绑定了一个 PV，那么 PVC 所处名称空间定义的 POD 就可以使用
persistentVolumeClaim 类型的 volumes 了，然后容器就可以通过 volumeMounts
挂载 PVC 类型的卷了。</p>
<p>persistentVolumeClaim 卷是否允许多路读写，这取决于 PV
定义时候的读写特性：单路读写、多路读写、多路只读。</p>
<p>如果某个 POD 不在需要了，我们把它删除了、同时也删除了 PVC、那么此时 PV
还可以有自己的回收策略： delete删除PV、Retain什么都不做。</p>
<div class="section" id="persistentvolume">
<h3><a class="toc-backref" href="#id267">10.5.1 PersistentVolume</a><a class="headerlink" href="#persistentvolume" title="Permalink to this headline">¶</a></h3>
<p>由管理员添加的的一个存储的描述，是一个集群级别的全局资源，包含存储的类型，存储的大小和访问模式等。它的生命周期独立于Pod，例如当使用它的
Pod 销毁时对 PV 没有影响。</p>
<blockquote>
<div><p>见：kubectl explain PersistentVolume.spec</p>
</div></blockquote>
<ul class="simple">
<li><p>在 nfs 上定义存储，/etc/exports，并且导出 nfs 定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/data/volumes/v1    <span class="m">172</span>.16.100.0/16<span class="o">(</span>rw,no_root_squash<span class="o">)</span>
/data/volumes/v2    <span class="m">172</span>.16.100.0/16<span class="o">(</span>rw,no_root_squash<span class="o">)</span>
/data/volumes/v3    <span class="m">172</span>.16.100.0/16<span class="o">(</span>rw,no_root_squash<span class="o">)</span>
/data/volumes/v4    <span class="m">172</span>.16.100.0/16<span class="o">(</span>rw,no_root_squash<span class="o">)</span>
/data/volumes/v5    <span class="m">172</span>.16.100.0/16<span class="o">(</span>rw,no_root_squash<span class="o">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>exportfs -arv
</pre></div>
</div>
<ul class="simple">
<li><p>将 nfs 在 k8s 中定义为 PersistentVolume，详见：kubectl explain
PersistentVolume.spec.nfs</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolume</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pv-001</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pv001</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">accessModes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteOnce</span>
  <span class="nt">capacity</span><span class="p">:</span>
    <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1Gi</span>
  <span class="nt">nfs</span><span class="p">:</span>
    <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/volumes/v1</span>
    <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.16.100.104</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolume</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pv-002</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pv003</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">accessModes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteOnce</span>
  <span class="nt">capacity</span><span class="p">:</span>
    <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2Gi</span>
  <span class="nt">nfs</span><span class="p">:</span>
    <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/volumes/v2</span>
    <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.16.100.104</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolume</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pv-003</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pv003</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">accessModes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteOnce</span>
  <span class="nt">capacity</span><span class="p">:</span>
    <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3Gi</span>
  <span class="nt">nfs</span><span class="p">:</span>
    <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/volumes/v3</span>
    <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.16.100.104</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get persistentvolume
NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
pv-001   1Gi        RWO,RWX        Retain           Available                                   3m38s
pv-002   2Gi        RWO,RWX        Retain           Available                                   3m38s
pv-003   3Gi        RWO,RWX        Retain           Available                                   3m38s
</pre></div>
</div>
</div>
<div class="section" id="persistentvolumeclaim">
<h3><a class="toc-backref" href="#id268">10.5.2. PersistentVolumeClaim</a><a class="headerlink" href="#persistentvolumeclaim" title="Permalink to this headline">¶</a></h3>
<p>是 Namespace 级别的资源，描述对 PV
的一个请求。请求信息包含存储大小，访问模式等。</p>
<ul class="simple">
<li><p>定义 PVC，kubectl explain PersistentVolumeClaim.spec</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>accessModes         &lt;<span class="o">[]</span>string&gt;  <span class="c1"># 设置访问模式</span>
    ReadWriteOnce               <span class="c1"># 单个节点以读写方式挂载</span>
    ReadOnlyMany                <span class="c1"># - 多节点以只读方式挂载</span>
    ReadWriteMany               <span class="c1"># - 多节点以读写方式挂载</span>

dataSource          &lt;Object&gt;    <span class="c1"># 如果配置程序可以支持 Volume Snapshot 数据源，它将创建一个新卷，并且数据将同时还原到该卷。</span>
resources           &lt;Object&gt;    <span class="c1"># 资源表示 PersistentVolume 应具有的最小资源</span>
selector            &lt;Object&gt;    <span class="c1"># 选择哪个 PersistentVolume</span>
storageClassName    &lt;string&gt;    <span class="c1"># 存储类名称</span>
volumeMode          &lt;string&gt;    <span class="c1"># 定义声明所需的 PersistentVolume 类型才能被选中</span>
volumeName          &lt;string&gt;    <span class="c1"># 后端 PersistentVolume ，就是精确选择 PersistentVolume ，而不是使用 selector 来选定</span>
</pre></div>
</div>
<ul class="simple">
<li><p>在 volumes 中使用 PVC，kubectl explain
pods.spec.volumes.persistentVolumeClaim</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">persistentVolumeClaim</span>
    <span class="l l-Scalar l-Scalar-Plain">claimName    &lt;string&gt;</span>  <span class="c1"># 在当前名称空间已经创建号的 PVC 名称</span>
    <span class="l l-Scalar l-Scalar-Plain">readOnly     &lt;boolean&gt;</span> <span class="c1"># 是否只读</span>
</pre></div>
</div>
<ul class="simple">
<li><p>定义 PersistentVolumeClaim，详见：kubectl explain
PersistentVolumeClaim.spec</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolumeClaim</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-pvc</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">accessModes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>        <span class="c1"># 访问模式</span>
  <span class="nt">resources</span><span class="p">:</span>               <span class="c1"># 资源条件</span>
    <span class="nt">requests</span><span class="p">:</span>              <span class="c1"># 挑选 PV 时候必须满足的条件，不满足则一直等待</span>
      <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2Gi</span>         <span class="c1"># 存储大小</span>
</pre></div>
</div>
<ul class="simple">
<li><p>在 pod 清单中定义 persistentVolumeClaim 类型的 volumes
，并在容器中挂载 volumeMounts。</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-vol-nfs-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
    <span class="nt">volumeMounts</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
        <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html/</span>
  <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">html</span>
      <span class="nt">persistentVolumeClaim</span><span class="p">:</span>
        <span class="nt">claimName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-pvc</span>            <span class="c1"># 使用的 PVC 的名称</span>
</pre></div>
</div>
</div>
<div class="section" id="storageclass">
<h3><a class="toc-backref" href="#id269">10.5.3 StorageClass</a><a class="headerlink" href="#storageclass" title="Permalink to this headline">¶</a></h3>
<p>PVC 申请 PV 的时候，未必有符合条件的 PV，k8s 为我们准备了 StorageClass
可以在 PVC 申请 PV 的时候通过 StorageClass 动态生成 PV。</p>
<p>StorageClass 可以动态的到 CephFS 、NFS 等存储（或者云端存储）产生一个
PV，要求存储设备必须支持 RESTfull 风格的接口。</p>
</div>
</div>
<div class="section" id="storageclass-ceph-rbd">
<h2><a class="toc-backref" href="#id270">10.6 StorageClass Ceph RBD</a><a class="headerlink" href="#storageclass-ceph-rbd" title="Permalink to this headline">¶</a></h2>
<div class="section" id="ceph">
<h3><a class="toc-backref" href="#id271">10.6.1 配置 Ceph 储存池</a><a class="headerlink" href="#ceph" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>创建 ceph 存储池</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>yum install -y ceph-common                                                                   <span class="c1"># 在所有节点安装 ceph-common</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ceph osd pool create kube <span class="m">4096</span>                                                               <span class="c1"># 创建 pool</span>
ceph osd pool ls                                                                             <span class="c1"># 查看 pool</span>

ceph auth get-or-create client.kube mon <span class="s1">&#39;allow r&#39;</span> osd <span class="s1">&#39;allow rwx pool=kube&#39;</span> -o /etc/ceph/ceph.client.kube.keyring
ceph auth list                                                                               <span class="c1"># 授权 client.kube 用户访问 kube 这个 pool</span>

scp /etc/ceph/ceph.client.kube.keyring node1:/etc/ceph/                                      <span class="c1"># 将用户 keyring 文件拷贝到各个 ceph 节点</span>
scp /etc/ceph/ceph.client.kube.keyring node1:/etc/ceph/
</pre></div>
</div>
</div>
<div class="section" id="rbd-provisioner">
<h3><a class="toc-backref" href="#id272">10.6.2 安装 rbd-provisioner</a><a class="headerlink" href="#rbd-provisioner" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>1.12 版本后 kube-controller-manager 不再内置 rbd 命令，所以
StorageClass 的 provisioner 而是通过外部的插件来实现</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/rbd/deploy/rbac    <span class="c1"># rbd-provisioner</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/kubernetes-incubator/external-storage.git                     <span class="c1"># 下载 rbd-provisioner</span>
$ cat &gt;&gt;external-storage/ceph/rbd/deploy/rbac/clusterrole.yaml<span class="s">&lt;&lt;EOF                          # 允许 rbd-provisioner 访问 ceph 的密钥</span>
<span class="s">  - apiGroups: [&quot;&quot;]</span>
<span class="s">    resources: [&quot;secrets&quot;]</span>
<span class="s">    verbs: [&quot;create&quot;, &quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span>
<span class="s">EOF</span>
$ kubectl apply -f external-storage/ceph/rbd/deploy/rbac/                                    <span class="c1"># 安装 rbd-provisioner</span>
</pre></div>
</div>
</div>
<div class="section" id="id56">
<h3><a class="toc-backref" href="#id273">10.6.3 使用 StorageClass</a><a class="headerlink" href="#id56" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>创建 CephX 验证 secret</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/rbd/examples</span>       <span class="c1"># rbd-provisioner 使用 ceph rbd 的示例</span>
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Secret</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-admin-secret</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">type</span><span class="p">:</span> <span class="s">&quot;kubernetes.io/rbd&quot;</span>
<span class="nt">data</span><span class="p">:</span>
  <span class="c1"># ceph auth get-key client.admin | base64                                                  # 从这个命令中取得 keyring 认证的 base64 密钥串复制到下面</span>
  <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">QVFER3U5TmM1NXQ4SlJBQXhHMGltdXZlNFZkUXRvN2tTZ1BENGc9PQ==</span>


<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Secret</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-secret</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">type</span><span class="p">:</span> <span class="s">&quot;kubernetes.io/rbd&quot;</span>
<span class="nt">data</span><span class="p">:</span>
  <span class="c1"># ceph auth get-key client.kube | base64                                                  # 从这个命令中取得 keyring 认证的 base64 密钥串复制到下面</span>
  <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">QVFCcUM5VmNWVDdQRlJBQWR1NUxFNzVKeThiazdUWVhOa3N2UWc9PQ==</span>
</pre></div>
</div>
<ul class="simple">
<li><p>创建 StorageClass 指向 rbd-provisioner，</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">StorageClass</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">storage.k8s.io/v1</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-rbd</span>
<span class="nt">provisioner</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph.com/rbd</span>
<span class="nt">reclaimPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Retain</span>
<span class="nt">parameters</span><span class="p">:</span>
  <span class="nt">monitors</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.16.100.9:6789</span>
  <span class="nt">pool</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube</span>
  <span class="nt">adminId</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">admin</span>
  <span class="nt">adminSecretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-admin-secret</span>
  <span class="nt">adminSecretNamespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
  <span class="nt">userId</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube</span>
  <span class="nt">userSecretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-secret</span>
  <span class="nt">userSecretNamespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
  <span class="nt">fsType</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ext4</span>
  <span class="nt">imageFormat</span><span class="p">:</span> <span class="s">&quot;2&quot;</span>
  <span class="nt">imageFeatures</span><span class="p">:</span> <span class="s">&quot;layering&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>创建 PersistentVolumeClaim</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolumeClaim</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-rbd-pvc  data-kong-postgresql-0</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">storageClassName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-rbd</span>
  <span class="nt">accessModes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteOnce</span>
  <span class="nt">resources</span><span class="p">:</span>
    <span class="nt">requests</span><span class="p">:</span>
      <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1Gi</span>
</pre></div>
</div>
<ul class="simple">
<li><p>在 POD 中使用 PVC，最后在容器中挂载 PVC。</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-sc-pvc-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
    <span class="nt">volumeMounts</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pvc-volume</span>
        <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html/</span>
  <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pvc-volume</span>
      <span class="nt">persistentVolumeClaim</span><span class="p">:</span>
        <span class="nt">claimName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-rbd-pvc</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id57">
<h1><a class="toc-backref" href="#id274">十一 配置信息容器化</a><a class="headerlink" href="#id57" title="Permalink to this headline">¶</a></h1>
<p>k8s 提供了 configMap、secret 这两种特殊类型的存储卷，多数情况下不是为
POD 提供存储空间，而是为用户提供了从集群外部到 POD
内部注入配置信息的方式。</p>
<ul class="simple">
<li><p>配置信息容器化有哪些方式</p></li>
</ul>
<ol class="arabic simple">
<li><p>自定义命令行参数，例如：command、args，根据 args
传递不同的参数来将容器运行为不同的特性</p></li>
<li><p>直接把配置信息制作为 image
中，但是这种方式非常不灵活，这个镜像只能适用于一种使用场景，过度耦合</p></li>
<li><p>环境变量，Cloud Native 支持通过环境变量来加载配置，或者使用
ENTRYPOINT 脚本来预处理环境变量为配置信息</p></li>
<li><p>存储卷，在容器启动时候挂载一个存储卷，或者专用的配置存储卷，挂载到应用程序的配置文件目录</p></li>
</ol>
<ul class="simple">
<li><p>Secret与ConfigMap对比</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>相同点：
-   key / value 的形式
-   属于某个特定的 namespace
-   可以导出到环境变量
-   可以通过目录/文件形式挂载(支持挂载所有key和部分key)

不同点：
-   Secret 可以被 ServerAccount 关联(使用)
-   Secret 可以存储 register 的鉴权信息，用在 ImagePullSecret 参数中，用于拉取私有仓库的镜像
-   Secret 支持 Base64 加密
-   Secret 分为 kubernetes.io/Service Account，kubernetes.io/dockerconfigjson，Opaque三种类型, Configmap 不区分类型
-   Secret 文件存储在tmpfs文件系统中，Pod 删除后 Secret文件也会对应的删除。
</pre></div>
</div>
<div class="section" id="id58">
<h2><a class="toc-backref" href="#id275">11.1 POD 获取环境变量</a><a class="headerlink" href="#id58" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>env，详见：kubectl explain pods.spec.containers.env</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">name              &lt;string&gt;</span>  <span class="c1"># 变量名称</span>
<span class="l l-Scalar l-Scalar-Plain">value             &lt;string&gt;</span>  <span class="c1"># 变量的值</span>
<span class="l l-Scalar l-Scalar-Plain">valueFrom         &lt;Object&gt;</span>  <span class="c1"># 引用值，如：configMap 的某个键、POD 定义中的字段名，如：metadata.labels</span>
<span class="l l-Scalar l-Scalar-Plain">resourceFieldRef  &lt;Object&gt;</span>  <span class="c1"># 引用资源限制中的值</span>
<span class="l l-Scalar l-Scalar-Plain">secretKeyRef      &lt;Object&gt;</span>  <span class="c1"># 引用 secretKey</span>
</pre></div>
</div>
</div>
<div class="section" id="configmap">
<h2><a class="toc-backref" href="#id276">11.2 configMap</a><a class="headerlink" href="#configmap" title="Permalink to this headline">¶</a></h2>
<p>假如我们现在要启动一个 POD ，这个 POD
启动时候，需要读取不同的配置信息，那么我们有两种方式：</p>
<ol class="arabic simple">
<li><p>可以将 configMap 资源关联到当前 POD 上，POD 从 configMap
读取一个数据，传递给 POD
内部容器的一个变量，变量被注入后，可以重启容器。</p></li>
<li><p>可以将 configMap 资源挂载到当前 POD
上，作为一个文件系统的路径，这个目录正好是应用程序读取配置文件的路径，容器就可以读取到配置信息了，当
configMap 修改了，那么就会通知 POD ，POD 可以进行重载配置。</p></li>
</ol>
<p>在每个 configMap 中所有的配置信息都保存为键值的配置形式。</p>
<ul class="simple">
<li><p>清单格式，详见：kubectl explain configMap</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion  &lt;string&gt;              <span class="c1"># 版本号</span>
binaryData  &lt;map<span class="o">[</span>string<span class="o">]</span>string&gt;   <span class="c1"># 二进制的数据</span>
data        &lt;map<span class="o">[</span>string<span class="o">]</span>string&gt;   <span class="c1"># 键值对的数据</span>
kind        &lt;string&gt;              <span class="c1"># 对象类型</span>
metadata    &lt;Object&gt;              <span class="c1"># 对象元数据</span>
</pre></div>
</div>
<ul class="simple">
<li><p>命令行方式创建</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 创建名为 my-config 的 configMap，它的数据来自目录中的文件，键为文件名，值为文件内容</span>
kubectl create configmap my-config --from-file<span class="o">=</span>path/to/dir

<span class="c1"># 创建名为 my-config 的 configMap，它的数据来自文件中的键值对</span>
kubectl create configmap my-config --from-file<span class="o">=</span>path/to/file

<span class="c1"># 创建名为 my-config 的 configMap，也可以手动指定键的名称</span>
kubectl create configmap my-config --from-file<span class="o">=</span><span class="nv">key1</span><span class="o">=</span>/path/to/bar/file1.txt --from-file<span class="o">=</span><span class="nv">key2</span><span class="o">=</span>/path/to/bar/file2.txt

<span class="c1"># 从字面量中创建</span>
kubectl create configmap my-config --from-literal<span class="o">=</span><span class="nv">key1</span><span class="o">=</span>config1 --from-literal<span class="o">=</span><span class="nv">key2</span><span class="o">=</span>config2

<span class="c1"># 从env文件中命名 my-config</span>
kubectl create configmap my-config --from-env-file<span class="o">=</span>path/to/bar.env
</pre></div>
</div>
<div class="section" id="pod-env">
<h3><a class="toc-backref" href="#id277">11.2.1 注入 POD ENV</a><a class="headerlink" href="#pod-env" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>创建 ConfigMap 并在 POD ENV 中使用</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ConfigMap</span>                                        <span class="c1"># 创建 ConfigMap 对象</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-config</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">data</span><span class="p">:</span>
  <span class="nt">server_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp.kaliarch.com</span>                       <span class="c1"># 键值对数据</span>
  <span class="nt">nginx_port</span><span class="p">:</span> <span class="p p-Indicator">|</span>                                        <span class="c1"># 键值对数据，此处为 nginx 配置文件，需要注意换行的写法</span>
    <span class="no">server {</span>
        <span class="no">server_name  myapp.kaliarch.com;</span>
        <span class="no">listen  80;</span>
        <span class="no">root  /data/web/html;</span>
    <span class="no">}</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-configmap-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
  <span class="nt">annotations</span><span class="p">:</span>
    <span class="nt">kaliarch.com/created-by</span><span class="p">:</span> <span class="s">&quot;cluster</span><span class="nv"> </span><span class="s">amdin&quot;</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
      <span class="nt">env</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NGINX_SERVER_PORT</span>          <span class="c1"># 定义容器内变量的名字，容器需要在启动的时候使用 ENTRYPOINT 脚本将环境变量转换为应用的配置文件</span>
          <span class="nt">valueFrom</span><span class="p">:</span>                       <span class="c1"># 值来自于 configMap 对象中</span>
            <span class="nt">configMapKeyRef</span><span class="p">:</span>               <span class="c1"># 引用 configMap 对象</span>
              <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-config</span>           <span class="c1"># configMap 对象的名字</span>
              <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx_port</span>              <span class="c1"># 引用 configMap 中的哪个 key</span>
              <span class="nt">optional</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>               <span class="c1"># 相对 POD 启动是否为可选，如果 configMap 中不存在这个值，true 则不阻塞 POD 启动</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NGINX_SERVER_NAME</span>          <span class="c1"># 定义容器内变量的名字，使用 exec 进入容器会发现变量已经在启动容器前注入容器内部了。</span>
          <span class="nt">valueFrom</span><span class="p">:</span>
            <span class="nt">configMapKeyRef</span><span class="p">:</span>
              <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-config</span>
              <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">server_name</span>
</pre></div>
</div>
</div>
<div class="section" id="id59">
<h3><a class="toc-backref" href="#id278">11.2.2 挂载为 POD 卷</a><a class="headerlink" href="#id59" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>configMap 中的数据可以在容器内挂载为文件，并且当 configMap
中的数据发生变动的时候，容器内的文件相应也会发生变动，但不会重载容器内的进程。</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ConfigMap</span>                                     <span class="c1"># 创建 ConfigMap</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-config-volumes</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">data</span><span class="p">:</span>                                               <span class="c1"># ConfigMap 中保存了两个数据，</span>
  <span class="nt">index</span><span class="p">:</span> <span class="p p-Indicator">|</span>                                          <span class="c1"># 数据1，它可以在 container 中使用 ENV 注入环境变量，也可以在 container 中使用 volumeMounts 挂载成为文件</span>
    <span class="no">&lt;h1&gt;this is a test page&lt;h1&gt;</span>
  <span class="nt">vhost</span><span class="p">:</span> <span class="p p-Indicator">|</span>                                          <span class="c1"># 数据2，它可以在 container 中使用 ENV 注入环境变量，也可以在 container 中使用 volumeMounts 挂载成为文件</span>
    <span class="no">server {</span>
        <span class="no">listen       80;</span>
        <span class="no">server_name  localhost;</span>

        <span class="no">location / {</span>
            <span class="no">root   /usr/share/nginx/html;</span>
            <span class="no">index  index.html index.htm;</span>
        <span class="no">}</span>

        <span class="no">error_page   500 502 503 504  /50x.html;</span>
        <span class="no">location = /50x.html {</span>
            <span class="no">root   /usr/share/nginx/html;</span>
        <span class="no">}</span>

        <span class="no">location = /hostname.html {</span>
            <span class="no">alias /etc/hostname;</span>
        <span class="no">}</span>
    <span class="no">}</span>
    <span class="no">server {</span>
        <span class="no">server_name  myapp.kaliarch.com;</span>
        <span class="no">listen  80;</span>
        <span class="no">root  /data/web/html;</span>
    <span class="no">}</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-configmap-volumes-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
  <span class="nt">annotations</span><span class="p">:</span>
    <span class="nt">kaliarch.com/created-by</span><span class="p">:</span> <span class="s">&quot;cluster</span><span class="nv"> </span><span class="s">amdin&quot;</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
      <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-conf</span>
          <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/nginx/conf.d</span>
          <span class="nt">readOnly</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-page</span>
          <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data/web/html/</span>
          <span class="nt">readOnly</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">volumes</span><span class="p">:</span>                                               <span class="c1"># 定义卷</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-conf</span>                                   <span class="c1"># 定义卷的名字</span>
      <span class="nt">configMap</span><span class="p">:</span>                                         <span class="c1"># 该卷的类型为 configMap</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-config-volumes</span>                       <span class="c1"># 从命名空间中读取哪个名字的 configMap</span>
        <span class="nt">items</span><span class="p">:</span>                                           <span class="c1"># 定义 configMap 数据到文件的映射，如果不定义则使用 configMap 中的键为文件名称，值为文件内容</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vhost</span>                                   <span class="c1"># 使用 configMap 哪个键</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">www.conf</span>                               <span class="c1"># 将 configMap 中的数据，映射为容器内哪个文件名称</span>
            <span class="nt">mode</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">644</span>                                    <span class="c1"># 指明文件的权限</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-page</span>
      <span class="nt">configMap</span><span class="p">:</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-config-volumes</span>
        <span class="nt">items</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">index</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">index.html</span>
            <span class="nt">mode</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">644</span>
</pre></div>
</div>
<ul class="simple">
<li><p>启动后进入容器查看文件是否正常挂载</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">exec</span> -it pod-configmap-volumes-demo -c myapp -- /bin/sh
</pre></div>
</div>
<ul class="simple">
<li><p>使用 curl 命令验证，是否能够正常使用</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl <span class="m">10</span>.244.2.104
Hello MyApp <span class="p">|</span> Version: v1 <span class="p">|</span> &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;hostname.html&quot;</span>&gt;Pod Name&lt;/a&gt;

$ curl -H <span class="s2">&quot;Host:myapp.kaliarch.com&quot;</span> <span class="m">10</span>.244.2.104
&lt;h1&gt;this is a <span class="nb">test</span> page&lt;h1&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="secret">
<h2><a class="toc-backref" href="#id279">11.3 secret</a><a class="headerlink" href="#secret" title="Permalink to this headline">¶</a></h2>
<p>configMap 是明文存储数据的，如果需要存储敏感数据，则需要使用 secret
，secret 与 configMap 的作用基本一致，且 secret
中的数据不是明文存放的，而是 base64 编码保存的。</p>
<ul class="simple">
<li><p>secret 类型</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker-registry    <span class="c1"># 创建一个 Docker registry 使用的 secret</span>
generic            <span class="c1"># 从本地文件，目录或字面值创建一个 secret</span>
tls                <span class="c1"># 创建一个 TLS  secret</span>
</pre></div>
</div>
<ul class="simple">
<li><p>清单格式，详见：kubectl explain secret</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion  &lt;string&gt;               <span class="c1"># API 版本</span>
data        &lt;map<span class="o">[</span>string<span class="o">]</span>string&gt;    <span class="c1"># 以键值对列出数据，值需要经过 base64 加密</span>
kind        &lt;string&gt;               <span class="c1"># 对象类型</span>
metadata    &lt;Object&gt;               <span class="c1"># 元数据</span>
stringData  &lt;map<span class="o">[</span>string<span class="o">]</span>string&gt;    <span class="c1"># 明文的数据</span>
<span class="nb">type</span>        &lt;string&gt;               <span class="c1"># 数据类型</span>
</pre></div>
</div>
<div class="section" id="id60">
<h3><a class="toc-backref" href="#id280">11.3.1 私有仓库认证1</a><a class="headerlink" href="#id60" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>首先通过命令行创建出来 secret</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create secret docker-registry regsecret --docker-server<span class="o">=</span>registry-vpc.cn-hangzhou.aliyuncs.com --docker-username<span class="o">=</span>admin --docker-password<span class="o">=</span><span class="m">123456</span> --docker-email<span class="o">=</span><span class="m">420123641</span>@qq.com
</pre></div>
</div>
<ul class="simple">
<li><p>如果想保存为文件可以</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get secret regsecret -o yaml
</pre></div>
</div>
<ul class="simple">
<li><p>POD 创建时候，从 docker hub 拉取镜像使用的用户名密码，kubectl explain
pods.spec 的 imagePullSecrets 字段</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">secret-file-pod</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">mypod</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
  <span class="nt">imagePullSecrets</span><span class="p">:</span>                         <span class="c1"># 获取镜像需要的用户名密码</span>
   <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">regsecret</span>                        <span class="c1"># secret 对象</span>
</pre></div>
</div>
</div>
<div class="section" id="id61">
<h3><a class="toc-backref" href="#id281">11.3.2 私有仓库认证2</a><a class="headerlink" href="#id61" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>首先通过命令行创建出来 secret</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create secret docker-registry regsecret --docker-server<span class="o">=</span>registry-vpc.cn-hangzhou.aliyuncs.com --docker-username<span class="o">=</span>admin --docker-password<span class="o">=</span><span class="m">123456</span> --docker-email<span class="o">=</span><span class="m">420123641</span>@qq.com
</pre></div>
</div>
<ul class="simple">
<li><p>创建自定义的 serviceaccount 对象，在 serviceaccount 对象上定义 image
pull secrets</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ServiceAccount</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">admin</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">imagePullSecrets</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">regsecret</span>                       <span class="c1"># 指定 secret</span>
</pre></div>
</div>
<ul class="simple">
<li><p>创建 POD 使用指定的 serviceaccount 对象</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-serviceaccount-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
  <span class="nt">serviceAccountName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">admin</span>                          <span class="c1"># 使用 serviceaccount 进行拉取镜像的认证，这样更加安全</span>
</pre></div>
</div>
</div>
<div class="section" id="tls">
<h3><a class="toc-backref" href="#id282">11.3.3 创建 TLS 证书</a><a class="headerlink" href="#tls" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>首先通过命令行创建出来</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create secret tls nginx-secret --cert<span class="o">=</span>tls.crt --key<span class="o">=</span>tls.key
</pre></div>
</div>
<ul class="simple">
<li><p>secret 中的数据可以在容器内挂载为文件，然后在 nginx
容器内使用证书文件</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-configmap-volumes-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
  <span class="nt">annotations</span><span class="p">:</span>
    <span class="nt">kaliarch.com/created-by</span><span class="p">:</span> <span class="s">&quot;cluster</span><span class="nv"> </span><span class="s">amdin&quot;</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
      <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-conf</span>
          <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/nginx/secret</span>
          <span class="nt">readOnly</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">volumes</span><span class="p">:</span>                                               <span class="c1"># 定义卷</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-conf</span>                                   <span class="c1"># 定义卷的名字</span>
      <span class="nt">configMap</span><span class="p">:</span>                                         <span class="c1"># 该卷的类型为 secret</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx-secret</span>                               <span class="c1"># 从命名空间中读取哪个名字的 secret</span>
        <span class="nt">items</span><span class="p">:</span>                                           <span class="c1"># 定义 secret 数据到文件的映射，如果不定义则使用 secret 中的键为文件名称，值为文件内容</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tls.key</span>                                 <span class="c1"># 使用 secret 哪个键</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">www.conf</span>                               <span class="c1"># 将 secret 中的数据，映射为容器内哪个文件名称</span>
            <span class="nt">mode</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">644</span>                                    <span class="c1"># 指明文件的权限</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tls.crt</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">index.html</span>
            <span class="nt">mode</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">644</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="statefulset">
<h1><a class="toc-backref" href="#id283">十二 StatefulSet 控制器</a><a class="headerlink" href="#statefulset" title="Permalink to this headline">¶</a></h1>
<p>StatefulSet 适用于有状态的应用，一般它管理的具有一下特点的 POD 资源</p>
<ol class="arabic simple">
<li><p>稳定且唯一的网络标识符</p></li>
<li><p>稳定且持久的存储</p></li>
<li><p>有序、平滑的部署和扩展</p></li>
<li><p>有序、平滑的终止和删除</p></li>
<li><p>有序的滚动更新</p></li>
</ol>
<p>一个典型的 StatefulSet 应用一般包含三个组件：</p>
<ol class="arabic simple">
<li><p>headless service （无头 service）</p></li>
<li><p>StatefulSet （控制器）</p></li>
<li><p>volumeClaimTemplate（存储卷申请模板）</p></li>
</ol>
<p>各个 POD 用到的存储卷必须使用由 StorageClass
动态供给或者由管理员事先创建好的 PV。</p>
<p>删除 StatefulSet 或者缩减其规模导致 POD
被删除时不会自动删除其存储卷以确保数据安全。</p>
<p>StatefulSet 控制器依赖于一个事先存在的 headless Service 对象实现 POD
对象的持久、唯一的标识符配置；此 headless Service
需要由用户手动配置，它能实现在 POD
出现故障被重构时候，依然能够使用之前的主机名。</p>
<div class="section" id="id62">
<h2><a class="toc-backref" href="#id284">12.1 清单格式</a><a class="headerlink" href="#id62" title="Permalink to this headline">¶</a></h2>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">podManagementPolicy    &lt;string&gt;</span>      <span class="c1"># 控制扩展时候的顺序策略</span>
<span class="l l-Scalar l-Scalar-Plain">replicas               &lt;integer&gt;</span>     <span class="c1"># 模板运行的副本数</span>
<span class="l l-Scalar l-Scalar-Plain">revisionHistoryLimit   &lt;integer&gt;</span>     <span class="c1"># 更新历史最大保存数量</span>
<span class="l l-Scalar l-Scalar-Plain">selector               &lt;Object&gt;</span>      <span class="c1"># 标签选择器</span>
<span class="l l-Scalar l-Scalar-Plain">serviceName            &lt;string&gt;</span>      <span class="c1"># headless service 的名称，基于这个 service 为 POD 分配标识符</span>
<span class="l l-Scalar l-Scalar-Plain">template               &lt;Object&gt;</span>      <span class="c1"># POD 对象模板，需要配置挂载存储卷，应该使用 PCV 类型</span>
<span class="l l-Scalar l-Scalar-Plain">updateStrategy         &lt;Object&gt;</span>      <span class="c1"># StatefulSet 更新策略</span>
<span class="l l-Scalar l-Scalar-Plain">volumeClaimTemplates   &lt;[]Object&gt;</span>    <span class="c1"># pvs 的列表</span>
</pre></div>
</div>
<ul class="simple">
<li><p>POD 关联使用 PVC 逻辑</p></li>
</ul>
<p>每个 POD 中应该定义一个 PVC 类型的 volume ，这个 PVC 类型的 volume
应该关联到一个当前同一个名称空间的 PVC，这个 PVC 应该关联到集群级别的 PV
上。</p>
<p>statefullset 会为 POD 自动创建 PVC 类型的 Volume ，并且在 POD
所在的名称空间中自动创建 PVC。</p>
<p>在 StatefulSet 中，每一个 POD
的名字是固定且唯一的，即有序的数字来标识，例如：web-0 挂了，重建的 POD
还叫做 web-0。</p>
<p>访问 Service
时候的格式：<span class="math notranslate nohighlight">\((servicename).\)</span>(namespace).svc.cluster.local，这个无头
Service 名字在解析时，解析为 POD 名称的别名。</p>
<p>headless 能保证，对 service 的访问能够解析为 POD
IP，但是现在需要标识的是每个 POD 的名字，所以，只需要在 Service 前加上
POD 的名称即可。</p>
<p>例如：pod 名称为 web-0，服务名为：myapp，那么访问这个 POD 就使用</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>web-0.myapp.default.svc.cluster.local
</pre></div>
</div>
</div>
<div class="section" id="nfs-pv">
<h2><a class="toc-backref" href="#id285">12.2 创建 NFS PV</a><a class="headerlink" href="#nfs-pv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-001
  labels:
    name: pv001
spec:
  accessModes:
    - ReadWriteMany
    - ReadWriteOnce
  capacity:
    storage: 5Gi
  nfs:
    path: /data/volumes/v1
    server: <span class="m">172</span>.16.100.104
---

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-002
  labels:
    name: pv003
spec:
  accessModes:
    - ReadWriteMany
    - ReadWriteOnce
  capacity:
    storage: 5Gi
  nfs:
    path: /data/volumes/v2
    server: <span class="m">172</span>.16.100.104

---

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-003
  labels:
    name: pv003
spec:
  accessModes:
    - ReadWriteMany
    - ReadWriteOnce
  capacity:
    storage: 5Gi
  nfs:
    path: /data/volumes/v3
    server: <span class="m">172</span>.16.100.104

---

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-004
  labels:
    name: pv004
spec:
  accessModes:
    - ReadWriteMany
    - ReadWriteOnce
  capacity:
    storage: 10Gi
  nfs:
    path: /data/volumes/v4
    server: <span class="m">172</span>.16.100.104

---

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-005
  labels:
    name: pv005
spec:
  accessModes:
    - ReadWriteMany
    - ReadWriteOnce
  capacity:
    storage: 10Gi
  nfs:
    path: /data/volumes/v5
    server: <span class="m">172</span>.16.100.104
</pre></div>
</div>
</div>
<div class="section" id="id63">
<h2><a class="toc-backref" href="#id286">12.3 创建 statefulSet</a><a class="headerlink" href="#id63" title="Permalink to this headline">¶</a></h2>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">web</span>
  <span class="nt">clusterIP</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-pod</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">StatefulSet</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">serviceName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-pod</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-pod</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
              <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">web</span>
          <span class="nt">volumeMounts</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myappdata</span>
              <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/nginx/html</span>
  <span class="nt">volumeClaimTemplates</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">metadata</span><span class="p">:</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myappdata</span>
      <span class="nt">spec</span><span class="p">:</span>
        <span class="nt">accessModes</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteOnce</span>
        <span class="nt">resources</span><span class="p">:</span>
          <span class="nt">requests</span><span class="p">:</span>
            <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5Gi</span>
</pre></div>
</div>
<ul class="simple">
<li><p>访问 pod</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pod_name.service_name.ns_name.svc.cluster.local
</pre></div>
</div>
</div>
<div class="section" id="id64">
<h2><a class="toc-backref" href="#id287">12.4 扩容和升级</a><a class="headerlink" href="#id64" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>扩容和缩容</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl scale sts myapp --replicas<span class="o">=</span><span class="m">5</span>
</pre></div>
</div>
<ul class="simple">
<li><p>升级策略，kubectl explain
sts.spec.updateStrategy.rollingUpdate.partition</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>可以实现金丝雀发布，首先仅仅更新大于等于多少的部分，然后更新大于 <span class="m">0</span> 的，就可以全部更新了
kubectl patch sta myapp -p <span class="s1">&#39;{&quot;spec&quot;:{&quot;updateStrategy&quot;:{&quot;rollingUpdate&quot;:{&quot;partition&quot;:4}}}}&#39;</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">set</span> image statefulset/myapp <span class="nv">myapp</span><span class="o">=</span>ikubernetes/myapp:v2kubectl
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl patch sta myapp -p <span class="s1">&#39;{&quot;spec&quot;:{&quot;updateStrategy&quot;:{&quot;rollingUpdate&quot;:{&quot;partition&quot;:0}}}}&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id65">
<h1><a class="toc-backref" href="#id288">十三 用户认证系统</a><a class="headerlink" href="#id65" title="Permalink to this headline">¶</a></h1>
<p>apiserver
是所有请求访问的网关接口，请求过程中，认证用于实现身份识别，授权用于实现权限检查，实际上，我们使用命令行：kubectl
apply -f ment.yaml，实际上是转换为 HTTP 协议向 apiserver
发起请求的，而认证是信息由 ~/.kube/config
这个文件提供的，这个文件记录了管理员权限的用户信息。</p>
<ul class="simple">
<li><p>k8s 的 API 是 RESTfull 风格的，所以资源是由路径标明的，在 k8s
中，资源只能属于两个地方：属于集群 或 属于名称空间。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>集群级别：namespace、pv
名称空间：POD、deployment、daemonSet、 service、PCV
</pre></div>
</div>
<p>例如：请求 delfault 名称空间下的 myapp-deploy 控制器，就是下面的写法</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>http://172.16.100.100/apis/apps/v1/namespaces/default/deployments/myapp-deploy
</pre></div>
</div>
<p>上面表示：<a class="reference external" href="http://172.16.100.100:6443">http://172.16.100.100:6443</a> 集群的 apis 下的 apps 组的 v1
版本的 namespaces 下寻找 default 下的 myapp-deploy 控制器</p>
<div class="section" id="id66">
<h2><a class="toc-backref" href="#id289">13.1 用户的类型</a><a class="headerlink" href="#id66" title="Permalink to this headline">¶</a></h2>
<p>我们使用 kubectl 连接 k8s 集群进行控制，实际上是使用用户家目录下
.kube/config 这个文件中的用户连接到 apiserver 实现认证的，而有些 POD
（如：CoreDNS）也需要获取集群的信息，它们也需要连接到 k8s 集群中，所以
k8s 中用户的类型有两种：</p>
<ol class="arabic simple">
<li><p>人类使用的用户：useraccount，处于用户家目录 .kube/config
文件中，可使用 kubectl config –help 获取帮助创建</p></li>
<li><p>POD 使用的用户：serviceaccunt，是一种 k8s 对象，它可以使用 kubectl
create serviceaccount –help 获取帮助创建</p></li>
</ol>
</div>
<div class="section" id="id67">
<h2><a class="toc-backref" href="#id290">13.2 POD如何连接集群</a><a class="headerlink" href="#id67" title="Permalink to this headline">¶</a></h2>
<p>POD 需要使用 serviceaccount 连接并认证到集群，POD
之所以能够连接到集群是因为有一个内置的 service 将 POD 的请求代理至
apiserver 的地址了。</p>
<ul class="simple">
<li><p>名字为 kubernetes 的 servie 为 POD 连接到 apiserver 提供了通信</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl describe service kubernetes                            <span class="c1"># 集群内部的 POD 与 apiserver 通信使用的 service ，但是注意 apiserver 需要认证的</span>

Name:              kubernetes
Namespace:         default
Labels:            <span class="nv">component</span><span class="o">=</span>apiserver
                   <span class="nv">provider</span><span class="o">=</span>kubernetes
Annotations:       &lt;none&gt;
Selector:          &lt;none&gt;
Type:              ClusterIP
IP:                <span class="m">10</span>.96.0.1                                     <span class="c1"># 集群内部访问 apiserver 的网关</span>
Port:              https  <span class="m">443</span>/TCP
TargetPort:        <span class="m">6443</span>/TCP
Endpoints:         <span class="m">172</span>.16.100.101:6443                           <span class="c1"># apiserver 工作的地址</span>
Session Affinity:  None
Events:            &lt;none&gt;
</pre></div>
</div>
</div>
<div class="section" id="serviceaccount">
<h2><a class="toc-backref" href="#id291">13.3 serviceaccount 对象</a><a class="headerlink" href="#serviceaccount" title="Permalink to this headline">¶</a></h2>
<p>k8s 的认证有两种一种是：human user、一种是 serviceaccount，下面就是创建
serviceaccount 它是 POD 访问 apiserver 所用的一种对象，而 human
user，即使 kubectl 命令行通过读取 config 中的用户而认证到 apiserver 的。</p>
<ul class="simple">
<li><p>创建一个 serviceaccount 对象，它会自动创建并关联一个 secret，这个
serviceaccount 可以到 apiserver
上进行认证，但是认证不代表有权限，所以需要授权</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl create serviceaccount admin
$ kubectl get secret
</pre></div>
</div>
<ul class="simple">
<li><p>创建 POD 使用指定的 serviceaccount 对象</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-serviceaccount-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
      <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
      <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
          <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
  <span class="nt">serviceAccountName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">admin</span>
</pre></div>
</div>
<div class="section" id="pod-serviceaccount">
<h3><a class="toc-backref" href="#id292">13.3.1 在 POD 中使用 serviceaccount</a><a class="headerlink" href="#pod-serviceaccount" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>POD 连接 apiserver 时候，需要在清单中指定 serviceAccountName
这个字段，详见：kubectl explain pods.spec</p></li>
</ul>
<p>每个 POD 默认自带一个 volumes，这是一个 secret，这个存储卷保存着
default-token-bq2gn 用来访问 apiserver ，而这个 secret 权限仅仅能通过
api 访问当前 POD 自身的信息，如果想要一个 POD
拥有管理集群的权限，那么可以手动创建一个 secret 并通过 volumes 挂载到
POD 上。</p>
<p>serviceaccout 也属于标准的 k8s
对象，这个对象提供了账号信息，但是账号由没有权限需要 rbac 机制来决定。</p>
</div>
</div>
<div class="section" id="id68">
<h2><a class="toc-backref" href="#id293">13.4 kubectl 配置文件</a><a class="headerlink" href="#id68" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>kubectl 配置文件解析，详见：kubectl config view</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Config</span>
<span class="nt">clusters</span><span class="p">:</span>                                             <span class="c1"># 集群列表</span>
<span class="p p-Indicator">-</span> <span class="nt">cluster</span><span class="p">:</span>                                            <span class="c1"># 列表中的一个集群对象</span>
    <span class="nt">certificate-authority-data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DATA+OMITTED</span>          <span class="c1"># 服务器认证方式</span>
    <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https://172.16.100.101:6443</span>               <span class="c1"># 集群的 apiserver 地址</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes</span>                                    <span class="c1"># 集群名称</span>
<span class="nt">users</span><span class="p">:</span>                                                <span class="c1"># 用户列表</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes-admin</span>                              <span class="c1"># 列表中的一个用户对象</span>
  <span class="nt">user</span><span class="p">:</span>                                               <span class="c1">#</span>
    <span class="nt">client-certificate-data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">REDACTED</span>                 <span class="c1"># 客户端证书</span>
    <span class="nt">client-key-data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">REDACTED</span>                         <span class="c1"># 客户端私钥</span>
<span class="nt">contexts</span><span class="p">:</span>                                             <span class="c1"># 上下文列表</span>
<span class="p p-Indicator">-</span> <span class="nt">context</span><span class="p">:</span>                                            <span class="c1"># 列表中的一个上下文对象</span>
    <span class="nt">cluster</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes</span>                               <span class="c1"># 集群名称</span>
    <span class="nt">user</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes-admin</span>                            <span class="c1"># 用户名称</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes-admin@kubernetes</span>                   <span class="c1"># 上下文名称</span>
<span class="nt">current-context</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes-admin@kubernetes</span>          <span class="c1"># 当前上下文</span>
<span class="nt">preferences</span><span class="p">:</span> <span class="p p-Indicator">{}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>配置文件保存了：多个集群、多用户的配置，kubectl
可以使用不同的用户访问不同的集群。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>集群列表：集群对象列表
用户列表：用户对象列表
上下文：是描述集群与用户的关系列表。
当前上下文：表示当前使用哪个用户访问哪个集群
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>自定义配置信息：详见：kubectl config  --help
ca 和证书保存路径：/etc/kubernetes 保存了所有的 ca 和签发的证书信息。
</pre></div>
</div>
</div>
<div class="section" id="config">
<h2><a class="toc-backref" href="#id294">13.5 添加证书用户到 config</a><a class="headerlink" href="#config" title="Permalink to this headline">¶</a></h2>
<p>k8s apiserver 认证方式有两种：ssl证书 和 token 认证，本次使用 ssl
证书创建用户</p>
<div class="section" id="ssl">
<h3><a class="toc-backref" href="#id295">13.5.1 创建SSL证书用户</a><a class="headerlink" href="#ssl" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>创建连接 apiserver 的用户证书</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 创建私钥</span>
<span class="o">(</span><span class="nb">umask</span> <span class="m">077</span><span class="p">;</span> openssl genrsa -out kaliarch.key <span class="m">2048</span><span class="o">)</span>

<span class="c1"># 生成证书签署请求，O 是组，CN 就是账号，这个账号被 k8s 用来识别身份，授权也需要授权这个账号</span>
openssl req -new -key kaliarch.key -out kaliarch.csr -subj <span class="s2">&quot;/CN=kaliarch&quot;</span>
<span class="c1">#penssl req -new -key kaliarch.key -out kaliarch.csr -subj &quot;O=system:masters/CN=kaliarch/&quot;</span>

<span class="c1"># 使用 CA 签署证书，并且在 1800 天内有效</span>
openssl x509 -req -in kaliarch.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out kaliarch.crt -days <span class="m">1800</span>

<span class="c1"># 查看证书</span>
openssl x509 -in kaliarch.crt -text -noout
</pre></div>
</div>
</div>
<div class="section" id="sslconfig">
<h3><a class="toc-backref" href="#id296">13.5.2 添加SSL证书用户到config</a><a class="headerlink" href="#sslconfig" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>将 kaliarch 用户添加到 k8s 的 config 中，设置客户端证书为
kaliarch.crt，设置客户端私钥为：kaliarch.key，使用 –embed-certs=true
来隐藏这些机密信息</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-credentials kaliarch --client-certificate<span class="o">=</span>./kaliarch.crt --client-key<span class="o">=</span>./kaliarch.key --embed-certs<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
</div>
<div class="section" id="id69">
<h3><a class="toc-backref" href="#id297">13.5.3 创建切换上下文</a><a class="headerlink" href="#id69" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>创建上下文对象，授权 kaliarch 用户访问名称为 kubernetes 的集群</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-context kaliarch@kubernetes --cluster<span class="o">=</span>kubernetes --user<span class="o">=</span>kaliarch
</pre></div>
</div>
<ul class="simple">
<li><p>切换当前使用的上下文，到授权 kaliarch 到 kubernetes 的上下文上</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config use-context kaliarch@kubernetes
</pre></div>
</div>
<ul class="simple">
<li><p>由于这个用户没有授权，所以这个用户是无法 get 到信息的，可以再切换回来</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get pods
$ kubectl config use-context kubernetes-admin@kubernetes
</pre></div>
</div>
</div>
</div>
<div class="section" id="id70">
<h2><a class="toc-backref" href="#id298">13.6 创建新 config 文件</a><a class="headerlink" href="#id70" title="Permalink to this headline">¶</a></h2>
<p>使用 kubectl config set-cluster 创建一个新的 config
文件，想要设定这个新创建的 config 文件可以使用
–kubeconfig=/tmp/test.conf 指明。</p>
<ul class="simple">
<li><p>设置集群的连接的 ca 机构证书，–kubeconfig 可以指定 kubectl
使用的配置文件位置，默认为用户家目录 .kube 目录中的 config</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-cluster k8s-cluster --server<span class="o">=</span>https://172.16.100.101:6443 --certificate-authority<span class="o">=</span>/etc/kubernetes/pki/ca.crt --embed-certs<span class="o">=</span><span class="nb">true</span> --kubeconfig<span class="o">=</span>/tmp/test.conf
</pre></div>
</div>
<ul class="simple">
<li><p>将 kaliarch 用户添加到 k8s 的 config 中，设置客户端证书为
kaliarch.crt，设置客户端私钥为：kaliarch.key，使用 –embed-certs=true
来隐藏这些机密信息</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-credentials kaliarch --client-certificate<span class="o">=</span>./kaliarch.crt --client-key<span class="o">=</span>./kaliarch.key --embed-certs<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<ul class="simple">
<li><p>创建上下文对象，授权 kaliarch 用户访问名称为 kubernetes 的集群</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-context def-ns-admin@k8s-cluster --cluster<span class="o">=</span>k8s-cluster --user<span class="o">=</span>def-ns-admin --kubeconfig<span class="o">=</span>/tmp/test.conf
</pre></div>
</div>
<ul class="simple">
<li><p>切换当前使用的上下文，到授权 kaliarch 到 kubernetes 的上下文上</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config use-context def-ns-admin@k8s-cluster --kubeconfig<span class="o">=</span>/tmp/test.con
</pre></div>
</div>
</div>
<div class="section" id="token">
<h2><a class="toc-backref" href="#id299">13.7 基于 token 认证</a><a class="headerlink" href="#token" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id71">
<h3><a class="toc-backref" href="#id300">13.7.1 创建 serviceaccount</a><a class="headerlink" href="#id71" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>为 POD 创建一个 serviceaccount 对象，它是 POD 访问 apiserver 的凭证</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create serviceaccount dashborad-admin -n kube-system
</pre></div>
</div>
</div>
<div class="section" id="id72">
<h3><a class="toc-backref" href="#id301">13.7.2 绑定集群管理员角色</a><a class="headerlink" href="#id72" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>创建 clusterrolebinding 将用户绑定至 cluster-admin
集群管理员（最高权限）</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create clusterrolebinding dashborad-cluster-admin --clusterrole<span class="o">=</span>cluster-admin --serviceaccount<span class="o">=</span>kube-system:dashborad-admin
</pre></div>
</div>
</div>
<div class="section" id="serviceaccount-token">
<h3><a class="toc-backref" href="#id302">13.7.3 通过 serviceaccount 得到 Token</a><a class="headerlink" href="#serviceaccount-token" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>找到刚才创建的 serviceaccount 对象</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get secret -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>得到 serviceaccount 对象中的 Token</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl describe secret -n kube-system dashborad-admin-token-skz95
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id73">
<h1><a class="toc-backref" href="#id303">十四 用户权限系统</a><a class="headerlink" href="#id73" title="Permalink to this headline">¶</a></h1>
<p>在 k8s 中的用户权限系统是使用 RBAC 模式的，RBAC 是 Role-Based AC
的缩写，全称：基于角色的访问控制。</p>
<p>我们可以让一个用户扮演一个角色，而这个角色拥有权限，而这个用户就拥有了这个权限，所以在
RBAC 中，用户授权就是授权某个角色。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>用户（user）：用户可以拥有某个角色。

角色（role）：角色可以拥有某些许可。
    <span class="m">1</span>. 操作
    <span class="m">2</span>. 对象

许可（permission）： 在一个对象上能施加的操作组合起来，称之为一个许可权限。
</pre></div>
</div>
<ul class="simple">
<li><p>用户类型</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Human User：              <span class="c1"># 用户账号</span>
Pod Service Account：     <span class="c1"># 服务账号</span>
</pre></div>
</div>
<ul class="simple">
<li><p>角色类型</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>- role（角色）、rolebinding（角色绑定）
- clusterrole（集群角色）、clusterrolebinding（集群角色绑定）
</pre></div>
</div>
<ul class="simple">
<li><p>授权类型</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>- 用户通过 rolebinding 去 <span class="nb">bind</span> rule，rolebinding 只能是当前命名空间中
- 通过 clusterrolebinding 去 <span class="nb">bind</span> clausterrole，clusterrolebinding会在所有名称空间生效
- 通过 rolebinding 去 <span class="nb">bind</span> clausterrole，由于 rolebinding 只在当前名称空间，所以 clusterrole 权限被限制为当前名称空间
</pre></div>
</div>
<ul class="simple">
<li><p>通过 rolebinding 去 bind clusterrole 的好处</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>如果有很多名称空间、如果用 rolebinding 绑定 role，那么则需要在每个名称空间都定义 role
如果使用 rolebinding 绑定一个 clausterrole ，由于 clusterrole 拥有所有名称空间的权限，而 rolebinding  只能绑定当前名称空间，那么就省去为每个名称空间都新建一个 role 的过程了。
</pre></div>
</div>
<div class="section" id="id74">
<h2><a class="toc-backref" href="#id304">14.1 权限列表</a><a class="headerlink" href="#id74" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get clusterrole admin -o yaml
</pre></div>
</div>
</div>
<div class="section" id="role">
<h2><a class="toc-backref" href="#id305">14.2 创建 Role</a><a class="headerlink" href="#role" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>命令行定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create role pods-reader --verb<span class="o">=</span>get,list,watch --resource<span class="o">=</span>pods
</pre></div>
</div>
<ul class="simple">
<li><p>使用清单方式定义</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Role</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pods-reder</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">rules</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">apiGroups</span><span class="p">:</span>                           <span class="c1"># 对哪些 api 群组内的资源进行操作</span>
  <span class="p p-Indicator">-</span> <span class="s">&quot;&quot;</span>
  <span class="nt">resources</span><span class="p">:</span>                           <span class="c1"># 对哪些资源授权</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">pods</span>
  <span class="nt">verbs</span><span class="p">:</span>                               <span class="c1"># 授权做哪些操作</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">get</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">list</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">watch</span>
</pre></div>
</div>
</div>
<div class="section" id="rolebinding">
<h2><a class="toc-backref" href="#id306">14.3 创建 rolebinding</a><a class="headerlink" href="#rolebinding" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>使用 rolebinding 对象创建，用户与 role 的绑定</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create rolebinding kaliarch-read-pods --role<span class="o">=</span>pods-reader --user<span class="o">=</span>kaliarch
</pre></div>
</div>
<ul class="simple">
<li><p>使用清单方式定义</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">RoleBinding</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kaliarch-read-pods</span>
<span class="nt">roleRef</span><span class="p">:</span>
  <span class="nt">apiGroup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io</span>
  <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Role</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pods-reader</span>
<span class="nt">subjects</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">apiGroup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io</span>
  <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">User</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kaliarch</span>
</pre></div>
</div>
<ul class="simple">
<li><p>切换用户和环境上下文</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl config use-context kaliarch@kubernetes
</pre></div>
</div>
<ul class="simple">
<li><p>测试用户是否拥有 get 权限</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods
</pre></div>
</div>
</div>
<div class="section" id="clusterrole">
<h2><a class="toc-backref" href="#id307">14.4 创建 clusterrole</a><a class="headerlink" href="#clusterrole" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>命令行定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create clusterrole cluster-reader --verb<span class="o">=</span>get,list,watch --resource<span class="o">=</span>pods
</pre></div>
</div>
<ul class="simple">
<li><p>使用清单方式定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-reader
rules:
- apiGroups:
  - <span class="s2">&quot;&quot;</span>
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
</pre></div>
</div>
<ul class="simple">
<li><p>系统内置有非常多的 clusterrole，详见：kubectl get clusterrole</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME                                                                   AGE
admin                                                                  5d16h
cluster-admin                                                          5d16h
cluster-reader                                                         4m32s
edit                                                                   5d16h
flannel                                                                5d6h
system:aggregate-to-admin                                              5d16h
system:aggregate-to-edit                                               5d16h
system:aggregate-to-view                                               5d16h
system:auth-delegator                                                  5d16h
system:aws-cloud-provider                                              5d16h
system:basic-user                                                      5d16h
system:certificates.k8s.io:certificatesigningrequests:nodeclient       5d16h
system:certificates.k8s.io:certificatesigningrequests:selfnodeclient   5d16h
system:controller:attachdetach-controller                              5d16h
system:controller:certificate-controller                               5d16h
system:controller:clusterrole-aggregation-controller                   5d16h
system:controller:cronjob-controller                                   5d16h
system:controller:daemon-set-controller                                5d16h
</pre></div>
</div>
</div>
<div class="section" id="clusterrolebinding">
<h2><a class="toc-backref" href="#id308">14.5 创建 clusterrolebinding</a><a class="headerlink" href="#clusterrolebinding" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>命令行定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create clusterrolebinding kaliarch-read-all-pods --clusterrole<span class="o">=</span>cluster-reader --user<span class="o">=</span>kaliarch
</pre></div>
</div>
<ul class="simple">
<li><p>清单定义</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterRoleBinding</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kaliarch-read-all-pods</span>
<span class="nt">roleRef</span><span class="p">:</span>
  <span class="nt">apiGroup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io</span>
  <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterRole</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cluster-reader</span>
<span class="nt">subjects</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">apiGroup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io</span>
  <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">User</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kaliarch</span>
</pre></div>
</div>
<ul class="simple">
<li><p>切换用户和环境上下文</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl config use-context kaliarch@kubernetes
</pre></div>
</div>
<ul class="simple">
<li><p>测试用户是否拥有 get 权限</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get pods -n kube-system
$ kubectl config use-context kubernetes-admin@kubernetes
</pre></div>
</div>
</div>
<div class="section" id="rolebinding-clusterrole">
<h2><a class="toc-backref" href="#id309">14.6 rolebinding 与 clusterrole</a><a class="headerlink" href="#rolebinding-clusterrole" title="Permalink to this headline">¶</a></h2>
<p>如果使用 rolebinding 绑定一个 clusterrole ，由于 clusterrole
拥有所有名称空间的权限，而 rolebinding
只能绑定当前名称空间，那么就省去为每个名称空间都新建一个 role 的过程了。</p>
<ul class="simple">
<li><p>命令定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl create rolebinding kaliarch-cluster-reader --clusterrole<span class="o">=</span>cluster-reader --user<span class="o">=</span>kaliarch
</pre></div>
</div>
<ul class="simple">
<li><p>清单定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kaliarch-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: admin
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: User
  name: kaliarch
</pre></div>
</div>
<ul class="simple">
<li><p>切换用户和环境上下文</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl config use-context kaliarch@kubernetes
</pre></div>
</div>
<ul class="simple">
<li><p>测试用户是否拥有 get 权限，由于使用了 rolebinding ，所以
cluster-reader 被限制到当前命名空间</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get pods -n kube-system
$ kubectl config use-context kubernetes-admin@kubernetes
</pre></div>
</div>
</div>
<div class="section" id="rbac">
<h2><a class="toc-backref" href="#id310">14.7 RBAC授权</a><a class="headerlink" href="#rbac" title="Permalink to this headline">¶</a></h2>
<p>在 bind 授权的时候，可以绑定的用户主体有：user、group</p>
<ul class="simple">
<li><p>使用 rolebinding 和 clusterrolebinding 绑定</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>绑定到 user：表示只有这一个用户拥有 role 或者 clusterrole 的权限
绑定到 group：表示这个组内的所有用户都具有了 role 或者 clusterrole 的权限
</pre></div>
</div>
<ul class="simple">
<li><p>创建用户时候加入组，加入组后账户自动集成该组的权限</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 创建私钥</span>
<span class="o">(</span><span class="nb">umask</span> <span class="m">077</span><span class="p">;</span> openssl genrsa -out kaliarch.key <span class="m">2048</span><span class="o">)</span>

<span class="c1"># 生成证书签署请求，O 是组，CN 就是账号，这个账号被 k8s 用来识别身份，授权也需要授权这个账号</span>
openssl req -new -key kaliarch.key -out kaliarch.csr -subj <span class="s2">&quot;O=system:masters/CN=kaliarch/&quot;</span>

<span class="c1"># 使用 CA 签署证书，并且在 1800 天内有效</span>
openssl x509 -req -in kaliarch.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out kaliarch.crt -days <span class="m">1800</span>

<span class="c1"># 查看证书</span>
openssl x509 -in kaliarch.crt -text -noout
</pre></div>
</div>
</div>
</div>
<div class="section" id="dashboard">
<h1><a class="toc-backref" href="#id311">十五 dashboard</a><a class="headerlink" href="#dashboard" title="Permalink to this headline">¶</a></h1>
<p>它作为 k8s 集群的附件存在，是 kubernetes
官方的项目之一，详见：<a class="reference external" href="https://github.com/kubernetes/dashboard">https://github.com/kubernetes/dashboard</a></p>
<div class="section" id="id75">
<h2><a class="toc-backref" href="#id312">15.1 部署流程</a><a class="headerlink" href="#id75" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>为 dashboard 提供 ssl 证书</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 生成私钥</span>
<span class="o">(</span><span class="nb">umask</span> <span class="m">077</span><span class="p">;</span> openssl genrsa -out dashboard.key <span class="m">2048</span><span class="o">)</span>

<span class="c1"># 生成一个自签证书，注意 CN 的值必须要与自己的域名完全一致</span>
openssl req -new -x509 -key dashboard.key -out dashboard.crt -subj <span class="s2">&quot;/O=dashboard/CN=k8s.dashboard.com&quot;</span>

<span class="c1"># 查看证书</span>
openssl x509 -in dashboard.crt -text -noout
</pre></div>
</div>
<ul class="simple">
<li><p>下载 dashboard 的清单文件</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span>
</pre></div>
</div>
<ul class="simple">
<li><p>为 dashboard 创建 secret 对象</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl -n kube-system create secret generic kubernetes-dashboard-certs --from-file<span class="o">=</span>dashboard.crt<span class="o">=</span>./dashboard.crt --from-file<span class="o">=</span>dashboard.key<span class="o">=</span>./dashboard.key
</pre></div>
</div>
<ul class="simple">
<li><p>修改 dashboard 清单中 service 的工作模式为 nodeport</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sed -i <span class="s1">&#39;/targetPort: 8443/a\ \ type: NodePort&#39;</span> kubernetes-dashboard.yaml
</pre></div>
</div>
<ul class="simple">
<li><p>注释掉 kubernetes-dashboard.yaml 清单文件中的 Dashboard Secret
这个证书的清单定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># ------------------- Dashboard Secret ------------------- #</span>

<span class="c1">#apiVersion: v1</span>
<span class="c1">#kind: Secret</span>
<span class="c1">#metadata:</span>
<span class="c1">#  labels:</span>
<span class="c1">#    k8s-app: kubernetes-dashboard</span>
<span class="c1">#  name: kubernetes-dashboard-certs</span>
<span class="c1">#  namespace: kube-system</span>
<span class="c1">#type: Opaque</span>

<span class="c1">#---</span>
</pre></div>
</div>
<ul class="simple">
<li><p>部署 dashboard 清单</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f kubernetes-dashboard.yaml
</pre></div>
</div>
<ul class="simple">
<li><p>取得 service 运行的端口</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get service -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>使用 chrome 访问 dashboard</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>https://172.16.100.102:31097/
</pre></div>
</div>
</div>
<div class="section" id="id76">
<h2><a class="toc-backref" href="#id313">15.2 使用令牌登录</a><a class="headerlink" href="#id76" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>为 POD 创建一个 serviceaccount 对象，它是 POD 访问 apiserver 的凭证</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create serviceaccount dashborad-admin -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>创建 clusterrolebinding 将用户绑定至 cluster-admin
集群管理员（最高权限）</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create clusterrolebinding dashborad-cluster-admin --clusterrole<span class="o">=</span>cluster-admin --serviceaccount<span class="o">=</span>kube-system:dashborad-admin
</pre></div>
</div>
<ul class="simple">
<li><p>找到刚才创建的 serviceaccount 对象</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get secret -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>得到 serviceaccount 对象中的 Token</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl describe secret -n kube-system dashborad-admin
</pre></div>
</div>
</div>
<div class="section" id="id77">
<h2><a class="toc-backref" href="#id314">15.3 分级管理</a><a class="headerlink" href="#id77" title="Permalink to this headline">¶</a></h2>
<p>现在需要创建一个只能管理 default 名称空间的用户，那么我们可以用
rolebinding 去绑定 admin 这个 clusterrolue
对象，那么就获得了当前名称空间的管理员权限了。</p>
<ul class="simple">
<li><p>创建 serviceaccount 登录</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create serviceaccount def-ns-admin -n default
</pre></div>
</div>
<ul class="simple">
<li><p>使用 rolebinding 对象，将 default 名称空间的 def-ns-admin 这个
serviceaccunt 与 admin 这个 clusterrole 绑定</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create rolebinding def-ns-admin --clusterrole<span class="o">=</span>admin --serviceaccount<span class="o">=</span>default:def-ns-admin
</pre></div>
</div>
<ul class="simple">
<li><p>找到刚才创建的 serviceaccount 对象</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get secret -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>得到 serviceaccount 对象中的 Token</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl describe secret def-ns-admin
</pre></div>
</div>
</div>
<div class="section" id="id78">
<h2><a class="toc-backref" href="#id315">15.4 配置文件认证</a><a class="headerlink" href="#id78" title="Permalink to this headline">¶</a></h2>
<p>与之前基于 SSL 证书的 config 文件不同，这次使用是基于 Token 的 config
文件，可以不用创建证书了，使用已有的 serviceaccount 对象的 token。</p>
<ul class="simple">
<li><p>设置集群的连接的 ca 机构证书，–kubeconfig 可以指定 kubectl
使用的配置文件位置，默认为用户家目录 .kube 目录中的 config</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-cluster k8s-cluster --server<span class="o">=</span>https://172.16.100.101:6443 --certificate-authority<span class="o">=</span>/etc/kubernetes/pki/ca.crt --embed-certs<span class="o">=</span><span class="nb">true</span> --kubeconfig<span class="o">=</span>/tmp/test.conf
</pre></div>
</div>
<ul class="simple">
<li><p>取得一个已经绑定角色的 serviceaccount 对象的 Token</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl describe secret def-ns-admin
</pre></div>
</div>
<ul class="simple">
<li><p>使用 Token 来创建配置文件中的用户</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-credentials def-ns-admin --token<span class="o">=</span>&lt;TOKEN&gt; --kubeconfig<span class="o">=</span>/tmp/test.conf
</pre></div>
</div>
<ul class="simple">
<li><p>创建上下文对象，授权 kaliarch 用户访问名称为 kubernetes 的集群</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config set-context def-ns-admin@k8s-cluster --cluster<span class="o">=</span>k8s-cluster --user<span class="o">=</span>def-ns-admin --kubeconfig<span class="o">=</span>/tmp/test.conf
</pre></div>
</div>
<ul class="simple">
<li><p>切换当前使用的上下文，到授权 kaliarch 到 kubernetes 的上下文上</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl config use-context def-ns-admin@k8s-cluster --kubeconfig<span class="o">=</span>/tmp/test.conf
</pre></div>
</div>
<ul class="simple">
<li><p>复制 /tmp/test.conf 这个文件到 dashboard 中就可以登录了</p></li>
</ul>
</div>
</div>
<div class="section" id="id79">
<h1><a class="toc-backref" href="#id316">十六 网络通信</a><a class="headerlink" href="#id79" title="Permalink to this headline">¶</a></h1>
<p>K8S 的网络通信完全由 CNI
接口上的插件来实现，插件需要实现以下集中通信模型。</p>
<p>目前比较流行的插件有：flannel、calico、canel、kube-router …</p>
<ul class="simple">
<li><p>如何加载插件</p></li>
</ul>
<p>k8s 在启动的时候会去：/etc/cni/net.d/ 目录下寻找网络插件的配置文件，POD
在创建时候 k8s 调用这个配置文件，由插件根据这个配置文件进行创建网络。</p>
<div class="section" id="id80">
<h2><a class="toc-backref" href="#id317">16.1 通信模型</a><a class="headerlink" href="#id80" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>容器间通信：同一个 POD 内多个容器间的通信，使用 lo 网卡通信</p></li>
<li><p>POD间通信：POD IP 直接与 POD IP 通信</p></li>
<li><p>POD 与 Service：POD IP 直接与 Cluster IP</p></li>
<li><p>Service 与集群外部客户端的通信，ingress、NodePort、Loadbacer</p></li>
</ol>
</div>
<div class="section" id="id81">
<h2><a class="toc-backref" href="#id318">16.2 通信模型底层</a><a class="headerlink" href="#id81" title="Permalink to this headline">¶</a></h2>
<p>无论哪一种网络插件，它们用到的底层方案都是以下几种：</p>
<ol class="arabic simple">
<li><p>虚拟网桥：brg，用纯软件实现一个虚拟网卡，一端在POD上，一端在宿主机上接入到网桥或物理接口桥上，称为隧道网络。</p></li>
<li><p>多路复用：MacVLAN，基于 MAC 的方式创建 VLAN
，为每个虚拟接口配置一个独立的 MAC
地址，使得一个物理网卡承载多个容器使用，这样容器直接使用物理网卡，基于
MacVLAN 进行跨节点通信。</p></li>
<li><p>硬件交换：网卡支持硬件交换，SR-IOV （单根-IO虚拟化）
方式，这种网卡支持直接在物理级别虚拟出多个接口，高性能。</p></li>
</ol>
</div>
<div class="section" id="id82">
<h2><a class="toc-backref" href="#id319">16.3 K8S 名称空间</a><a class="headerlink" href="#id82" title="Permalink to this headline">¶</a></h2>
<p>K8S 名称空间与 POD 网络名称空间不在一个维度，所以即使在不同的 K8S
集群名称空间内创建的不同 POD，也可以通过网络直接通信。</p>
<p>而目前应用最广的 flannel
网络插件，是不支持这种不同集群命名空间的网络隔离策略的。</p>
<p>calico
支持地址分配，也支持不同集群命名空间的网络隔离策略，但是它使用较为复杂，支持
BGP 三层网络转发，性能比 flannel 强。</p>
<p>也可以使用 flannel 来做网络管理，再安装 calico
仅仅做集群命名空间网路隔离策略，这种搭配方案。</p>
</div>
<div class="section" id="id83">
<h2><a class="toc-backref" href="#id320">16.4 K8S网络拓扑</a><a class="headerlink" href="#id83" title="Permalink to this headline">¶</a></h2>
<p>所有 POD 连接到，本机 cni0 接口这个网络，cni0 接口发出的报文到达
flannel.1
这个接口，这个接口将报文封装为隧道协议，通过本机的真实的物理网卡发出。</p>
<ul class="simple">
<li><p>查看本机的接口</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">1</span>: lo:                       <span class="c1"># 本地回环</span>
<span class="m">2</span>: ens33:                    <span class="c1"># 主机物理网卡</span>
<span class="m">3</span>: docker0:                  <span class="c1"># docker 默认的桥接网络，在 k8s 中无用可以删除</span>
<span class="m">4</span>: dummy0:                   <span class="c1">#</span>
<span class="m">5</span>: kube-ipvs0:               <span class="c1">#</span>
<span class="m">6</span>: flannel.1:                <span class="c1"># flannel 虚拟网卡，封装隧道报文</span>
<span class="m">7</span>: cni0:                     <span class="c1"># 所有容器处于这个网桥</span>
<span class="m">8</span>: veth0c014b8b@if3:         <span class="c1"># 容器的网卡连接到 cni0</span>
<span class="m">9</span>: veth97c048e5@if3:         <span class="c1"># 容器的网卡连接到 cni0</span>
<span class="m">11</span>: vethd2f0bf2b@if3:        <span class="c1"># 容器的网卡连接到 cni0</span>
<span class="m">12</span>: veth648a500f@if3:        <span class="c1"># 容器的网卡连接到 cni0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>下载 bridge-utils 包使用命令 brctl show cni0 查看 cni0 接口</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bridge    name    bridge id           STP    enabled    interfaces
cni0              <span class="m">8000</span>.9a6ec95f8285   no                veth0c014b8b
                                                        veth648a500f
                                                        veth7a3f56b7
                                                        veth97c048e5
                                                        vethd2f0bf2b
</pre></div>
</div>
</div>
<div class="section" id="flannel">
<h2><a class="toc-backref" href="#id321">16.5 flannel</a><a class="headerlink" href="#flannel" title="Permalink to this headline">¶</a></h2>
<p>flannel 是一个专为 kubernetes
定制的三层网络解决方案，主要用于解决容器的跨主机通信问题。</p>
<div class="section" id="id84">
<h3><a class="toc-backref" href="#id322">16.5.1 flannel 工作模式</a><a class="headerlink" href="#id84" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>flannel.1
这个虚拟网卡支持多种传输模式：VxLAN、host-gw、Directrouting、udp</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 16%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>模式</p></th>
<th class="head"><p>介绍</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>VXLAN</p></td>
<td><p>使用 VxLAN 作为隧道封装报文</p></td>
</tr>
<tr class="row-odd"><td><p>host-gw</p></td>
<td><p>不使用叠加网络，而是在主机的路由表中创建到其他主机
subnet 的路由条目，性能较好，缺陷是：所有 node
节点必须处于同一个二层网络中。</p></td>
</tr>
<tr class="row-even"><td><p>DirectRou
ting</p></td>
<td><p>当主机位于同一子网时启用直接路由，不在回退到 VxLAN。</p></td>
</tr>
<tr class="row-odd"><td><p>UDP</p></td>
<td><p>直接使用 UDP 协议，性能差</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="vxlan">
<h3><a class="toc-backref" href="#id323">16.5.2 VXLAN 通信过程</a><a class="headerlink" href="#vxlan" title="Permalink to this headline">¶</a></h3>
<p>Flannel VXLAN 实质上是一种 “覆盖网络(overlay network)”
，也就是将TCP数据包装在另一种网络包里面进行路由转发和通信，目前已经支持UDP、VxLAN、AWS
VPC和GCE路由等数据转发方式。</p>
<ul class="simple">
<li><p>flannel VXLAN 通信过程</p></li>
</ul>
<p>在 K8S 上 POD 与 POD 是直接通过对方的 IP 地址进行通信的，POD
发出的报文经过 cni0 网桥到达 flannel ，flannel 将报文封装上一层 VxLAN
的首部，外层又被封装一层 UDP
协议的首部，发送给本机物理网卡，本机物理网卡又将 flannel
发过来的报文外层封装上 IP 首部和以太网帧首部（MAC）由网卡发出，另外一个
node 节点收到报文，内核发现是一个 VxLAN 的包，拆掉 IP 首部送给 flannel
应用程序，flannel 拆掉 VxLAN 首部并将内部的数据发送给，cni0 网桥，cni0
收到后转发给 POD。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">|</span>                                               <span class="o">|</span>                                   <span class="o">|</span>
<span class="o">|&lt;------------------</span> <span class="n">VxLAN封装</span> <span class="o">-----------------&gt;|&lt;-----------</span> <span class="n">原始报文</span> <span class="o">-------------&gt;|</span>
<span class="o">+-----------+-----------+-----------+-----------+-----------+-----------+-----------+</span>
<span class="o">|</span>  <span class="n">node</span> <span class="n">网络</span> <span class="o">|</span>  <span class="n">node网络</span>  <span class="o">|</span> <span class="n">node</span> <span class="n">网络</span> <span class="o">|</span>  <span class="n">VxLan</span>    <span class="o">|</span>   <span class="n">POD</span> <span class="n">MAC</span> <span class="o">|</span>  <span class="n">POD</span> <span class="n">IP</span>   <span class="o">|</span>    <span class="n">data</span>   <span class="o">|</span>
<span class="o">|</span>  <span class="n">帧首部MAC</span> <span class="o">|</span>   <span class="n">IP首部</span>   <span class="o">|</span> <span class="n">UDP</span> <span class="n">首部</span>  <span class="o">|</span>   <span class="n">首部</span>     <span class="o">|</span>    <span class="n">首部</span>    <span class="o">|</span>   <span class="n">首部</span>    <span class="o">|</span>  <span class="n">Payload</span>  <span class="o">|</span>
<span class="o">+-----------+-----------+-----------+-----------+-----------+-----------+-----------+</span>
</pre></div>
</div>
</div>
<div class="section" id="id85">
<h3><a class="toc-backref" href="#id324">16.5.3 flannel 部署方式</a><a class="headerlink" href="#id85" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>在 k8s 集群启动前，flannel 直接部署到节点上，作为一个守护进程运行。</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>任何一个部署了 kubelet 的节点都应该部署 flannel ，因为 kubelet 要借助 flannel 为 POD 设置网络接口
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>使用 kube-admin 直接将 k8s 自己的组件包括 flannel 运行在 k8s
之上的静态 POD。</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>必须配置为共享 node 节点网络名称空间的 POD，所以 flannel POD 控制器为 DaemonSet。
</pre></div>
</div>
</div>
<div class="section" id="id86">
<h3><a class="toc-backref" href="#id325">16.5.4flannel 配置文件</a><a class="headerlink" href="#id86" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>配置文件选项含义</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>{
    &quot;Network&quot;: &quot;10.244.0.0/16&quot;,     // flannel 使用的 CIDR 格式的网络地址，用于为 POD 配置网络功能
    &quot;SubnetLen&quot;: 24,                // 把 Network 切分为子网供各 node 节点使用时，使用多长的掩码切分，默认为 24
    &quot;SubnetMin&quot;: &quot;10.244.10.0/24&quot;,  // 用于分配给 node 的子网起始地址，从这个网络开始分配网络
    &quot;SubnetMax&quot;: &quot;10.244.255.0/24&quot;  // 用于分配给 nide 的子网结束位置，这个是最大分配的网路
    &quot;Backend&quot;: {                    // 指明 POD 与 POD 跨节点通信时候使用的 flannel 工作模式
        &quot;Type&quot;: &quot;vxlan&quot;,            // 工作模式
        &quot;Directrouting&quot;: true       // 是否使用直接路由模式
    }
}
</pre></div>
</div>
<ul class="simple">
<li><p>flannel 托管到 k8s 上的配置文件，处于 kube-flannel-cfg 这个 configmap
中。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get configmap kube-flannel-cfg -n kube-system -o json
</pre></div>
</div>
</div>
<div class="section" id="id87">
<h3><a class="toc-backref" href="#id326">16.5.5 修改工作模式</a><a class="headerlink" href="#id87" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>修改 flannel 工作模式，添加 Directrouting，这个操作应该在刚刚部署完
k8s 集群时候修改，推荐修改</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl edit configmap kube-flannel-cfg -n kube-system
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;Backend&quot;</span>: <span class="o">{</span>
    <span class="s2">&quot;Type&quot;</span>: <span class="s2">&quot;vxlan&quot;</span>,
    <span class="s2">&quot;Directrouting&quot;</span>: <span class="nb">true</span>
<span class="o">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看本机路由表</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ip route show
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>default via <span class="m">172</span>.16.100.254 dev ens33 proto static metric <span class="m">100</span>
<span class="m">10</span>.244.1.0/24 via <span class="m">10</span>.244.1.0 dev ens33             <span class="c1"># 必须为 dev 物理网卡接口，否则 Directrouting 没有设置成功</span>
<span class="m">10</span>.244.2.0/24 via <span class="m">10</span>.244.2.0 dev ens33             <span class="c1"># 必须为 dev 物理网卡接口，否则 Directrouting 没有设置成功</span>
<span class="m">172</span>.16.100.0/24 dev ens33 proto kernel scope link src <span class="m">172</span>.16.100.101 metric <span class="m">100</span>
<span class="m">172</span>.17.0.0/16 dev docker0 proto kernel scope link src <span class="m">172</span>.17.0.1
</pre></div>
</div>
</div>
</div>
<div class="section" id="calico">
<h2><a class="toc-backref" href="#id327">16.6 Calico</a><a class="headerlink" href="#calico" title="Permalink to this headline">¶</a></h2>
<p>Calico 创建和管理⼀个扁平的三层网络(不需要
overlay)，每个容器会分配一个可路由的
ip。由于通信时不需要解包和封包，网络性能损耗小，易于排查，且易于水平扩展。</p>
<p>小规模部署时可以通过 bgp client 直接互联，大规模下可通过指定的 BGP route
reflector 来完成，这样保证所有的数据流量都是通过 IP
路由的方式完成互联的。</p>
<p>Calico 基于 iptables 还提供了丰富而灵活的网络
Policy，保证通过各个节点上的 ACLs 来提供 Workload
的多租户隔离、安全组以及其他可达性限制等功能。</p>
<p>有个新的项目：canel，它集合了 flannel 和 calico 的优点。</p>
<ul class="simple">
<li><p>注意</p></li>
</ul>
<p>Calico 目前不支持工作在 iptables 下的 kube-proxy，下面介绍 canal
网络策略的使用</p>
<div class="section" id="canal">
<h3><a class="toc-backref" href="#id328">16.6.1 安装 canal</a><a class="headerlink" href="#canal" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>下载清单文件，需要翻墙</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f https://docs.projectcalico.org/v3.6/getting-started/kubernetes/installation/hosted/canal/canal.yaml
</pre></div>
</div>
</div>
<div class="section" id="id88">
<h3><a class="toc-backref" href="#id329">16.6.2 清单定义</a><a class="headerlink" href="#id88" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>清单格式，详见：kubectl explain networkpolicy</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">egress                  &lt;[]Object&gt;</span>    <span class="c1"># 出站规则的对象列表</span>
  <span class="l l-Scalar l-Scalar-Plain">ports                 &lt;[]Object&gt;</span>    <span class="c1"># 目标端口的对象列表</span>
    <span class="l l-Scalar l-Scalar-Plain">port                &lt;string&gt;</span>      <span class="c1"># 数字形式或者是命名的端口</span>
    <span class="l l-Scalar l-Scalar-Plain">protocol</span>                          <span class="c1"># 协议 TCP、UDP</span>
  <span class="l l-Scalar l-Scalar-Plain">to                    &lt;[]Object&gt;</span>    <span class="c1"># 目标地址对象列表</span>
    <span class="l l-Scalar l-Scalar-Plain">ipBlock             &lt;Object&gt;</span>      <span class="c1"># 一组 IP 地址</span>
      <span class="l l-Scalar l-Scalar-Plain">cidr              &lt;string&gt;</span>      <span class="c1"># CIDR 表示的 IP 范围</span>
      <span class="l l-Scalar l-Scalar-Plain">except            &lt;[]string&gt;</span>    <span class="c1"># 排除 CIDR 中的某些地址</span>
    <span class="l l-Scalar l-Scalar-Plain">namespaceSelector   &lt;Object&gt;</span>      <span class="c1"># 名称空间选择器</span>
    <span class="l l-Scalar l-Scalar-Plain">podSelector         &lt;Object&gt;</span>      <span class="c1"># POD 选择器，目标地址可以也是一组 POD</span>
<span class="l l-Scalar l-Scalar-Plain">ingress                 &lt;[]Object&gt;</span>    <span class="c1"># 入站规则的对象列表</span>
  <span class="l l-Scalar l-Scalar-Plain">from                  &lt;[]Object&gt;</span>    <span class="c1"># 源地址对象列表</span>
    <span class="l l-Scalar l-Scalar-Plain">ipBlock             &lt;Object&gt;</span>      <span class="c1"># 一组 IP 地址</span>
      <span class="l l-Scalar l-Scalar-Plain">cidr              &lt;string&gt;</span>      <span class="c1"># CIDR 表示的 IP 范围</span>
      <span class="l l-Scalar l-Scalar-Plain">except            &lt;[]string&gt;</span>    <span class="c1"># 排除 CIDR 中的某些地址</span>
    <span class="l l-Scalar l-Scalar-Plain">namespaceSelector   &lt;Object&gt;</span>      <span class="c1"># 名称空间选择器</span>
    <span class="l l-Scalar l-Scalar-Plain">podSelector         &lt;Object&gt;</span>      <span class="c1"># POD 选择器，源地址也可以是一组 POD</span>
  <span class="l l-Scalar l-Scalar-Plain">ports                 &lt;[]Object&gt;</span>    <span class="c1"># POD 自己的端口，表示控制自己的端口是否可以被访问，的对象列表</span>
    <span class="l l-Scalar l-Scalar-Plain">port</span>                              <span class="c1"># 数字形式或者是命名的端口</span>
    <span class="l l-Scalar l-Scalar-Plain">protocol</span>                          <span class="c1"># 协议 TCP、UDP</span>
<span class="l l-Scalar l-Scalar-Plain">podSelector             &lt;Object&gt;</span>      <span class="c1"># POD 选择器决定规则应用在哪些 POD 上</span>
<span class="l l-Scalar l-Scalar-Plain">policyTypes             &lt;[]string&gt;</span>    <span class="c1"># 可以是 &quot;Ingress&quot;, &quot;Egress&quot;, 或者 &quot;Ingress,Egress&quot; ，表示放行满足这些规则访问</span>
</pre></div>
</div>
</div>
<div class="section" id="policytypes">
<h3><a class="toc-backref" href="#id330">16.6.3 policyTypes</a><a class="headerlink" href="#policytypes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>首先定义 名称空间</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create namespace dev
kubectl create namespace prod
</pre></div>
</div>
<ul class="simple">
<li><p>在两个命名空间分别创建一个 POD</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod1</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dev</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod1</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">prod</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f pod-a.yaml -n dev
</pre></div>
</div>
<ul class="simple">
<li><p>拒绝所有 dev 空间的报文</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">networking.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NetworkPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">deny-all-ingress</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dev</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">podSelector</span><span class="p">:</span> <span class="p p-Indicator">{}</span>            <span class="c1"># {} 空的选择器表示选择全部</span>
  <span class="nt">policyTypes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>                  <span class="c1"># 指明 Ingress 规则生效，匹配 Ingress 将被放行，如果没定义 Ingress 则不能匹配所有，会拒绝全部</span>
                             <span class="c1"># policyTypes 没有 Egress 表示不控制 Egress ，默认为允许</span>
</pre></div>
</div>
<ul class="simple">
<li><p>在指定命名空间应用规则文件</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f deny-all-ingress.yaml -n dev
</pre></div>
</div>
<ul class="simple">
<li><p>查看规则</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get networkpolicy -n dev
</pre></div>
</div>
<ul class="simple">
<li><p>查看 dev 空间中的 POD
地址并访问，结果是不能访问，因为这个命名空间拒绝外部访问</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods -n dev -o wide
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl <span class="m">10</span>.244.1.2
</pre></div>
</div>
<ul class="simple">
<li><p>查看 prod 空间中的 POD
地址并访问，结果可以访问，因为这个命名空间没有定义规则</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods -n dev -o wide
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl <span class="m">10</span>.244.2.2
</pre></div>
</div>
<ul class="simple">
<li><p>允许指定网段的 POD 访问本 POD 的 80 端口</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">networking.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NetworkPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">allow-80-ingress</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dev</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">podSelector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
  <span class="nt">ingress</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">from</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">ipBlock</span><span class="p">:</span>                   <span class="c1"># 指定源地址为 IP 地址块</span>
        <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.244.0.0/16</span>    <span class="c1"># 掩码形式指出源地址 IP 地址范围</span>
        <span class="nt">except</span><span class="p">:</span>                  <span class="c1"># 排除 cidr 范围内的某个地址</span>
        <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">10.244.1.2/32</span>
    <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>                   <span class="c1"># 入栈且目标端口为 80 的则匹配</span>
      <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
    <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>
      <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
  <span class="nt">policyTypes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>                  <span class="c1"># 指明 Ingress 规则生效，匹配 Ingress 将被放行，如果没定义 Ingress 则不能匹配所有，拒绝全部</span>
                             <span class="c1"># policyTypes 没有 Egress 表示不控制 Egress ，默认为允许</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看规则</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get networkpolicy -n dev
</pre></div>
</div>
<ul class="simple">
<li><p>拒绝出栈的所有请求</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">networking.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NetworkPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">deny-all-egress</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">prod</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">podSelector</span><span class="p">:</span> <span class="p p-Indicator">{}</span>            <span class="c1"># {} 空的选择器表示选择全部</span>
  <span class="nt">policyTypes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Egress</span>                   <span class="c1"># 指明 Egress 规则生效，匹配 Egress 将被放行，如果没定义 Egress 则不能匹配所有，拒绝全部</span>
                             <span class="c1"># policyTypes 没有 Ingress 表示不控制 Egress ，默认为允许</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id89">
<h1><a class="toc-backref" href="#id331">十七 调度策略</a><a class="headerlink" href="#id89" title="Permalink to this headline">¶</a></h1>
<p>Master
主要是运行集群的控制平面组件的，apiserver、scheduler、controlermanager，Master
还依赖与 etcd 这样的存储节点。</p>
<p>kubeadm 部署的集群会将 Master 的控制组件都运行为静态 POD
了，从本质来讲，这些组件就是运行在 Master
节点专为集群提供服务的进程，Master 是不负责运行工作负载的。</p>
<p>node 节点是负责运行工作负载 POD 的相关节点，用户只需要将运行任务提交给
Master 就可以了，用户无需关心运行在哪个 node 节点上，Master 整合了所有
node 为一个虚拟的资源池。</p>
<div class="section" id="id90">
<h2><a class="toc-backref" href="#id332">17.1 POD创建流程</a><a class="headerlink" href="#id90" title="Permalink to this headline">¶</a></h2>
<p>用户创建的任务最终应该运行在哪个 node 节点上，是由 Master 节点上的
scheduler 决定的，而 scheduler
也是允许用户定义它的工作特性的，默认情况下，我们没有定义它，其实是使用的默认的
scheduler 调度器。</p>
<p>当我们使用 kubectl describe pods myapp 查看 POD 信息时候，会有一个
Events 字段中，有关于调度结果的相关信息。</p>
<p>Scheduler 会从众多的 node 节点中挑选出符合 POD
运行要求的节点，然后将选定的 node 节点信息记录在 etcd 中，kubelet 始终
waitch 着 apiserver 上的关于本节点的信息变化，kubelet 就会去 apiserver
获取关于变化信息的配置清单，根据配置清单的定义去创建 POD。</p>
</div>
<div class="section" id="id91">
<h2><a class="toc-backref" href="#id333">17.2 Service创建过程</a><a class="headerlink" href="#id91" title="Permalink to this headline">¶</a></h2>
<p>当用户创建一个 service 的时候，这个请求会提交给 apiserver，apiserver
将清单文件写入 etcd 中，然后每个 node 节点上的 kube-proxy 会 waitch
apiserver 关于 service 资源的相关变动，发生变化时候，每个节点的
kube-proxy 会将 service 创建为 iptables/ipvs 规则。</p>
<p>从通信角度来讲：kubectl、kubelet、kube-proxy 都是 apiserver
的客户端，这些组件与 apiserver 进行交互时候，数据格式为
json，内部的数据序列化方式为 protocolbuff。</p>
</div>
<div class="section" id="id92">
<h2><a class="toc-backref" href="#id334">17.3 资源限制维度</a><a class="headerlink" href="#id92" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>资源需求：运行 POD 需要的最低资源需求</p></li>
<li><p>资源限制：POD 可以占用的最高资源限额</p></li>
</ol>
</div>
<div class="section" id="scheduler">
<h2><a class="toc-backref" href="#id335">17.4 Scheduler 调度过程</a><a class="headerlink" href="#scheduler" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>预选阶段：排除完全不符合运行这个 POD
的节点、例如资源最低要求、资源最高限额、端口是否被占用</p></li>
<li><p>优选阶段：基于一系列的算法函数计算出每个节点的优先级，按照优先级排序，取得分最高的
node</p></li>
<li><p>选中阶段：如果优选阶段产生多个结果，那么随机挑选一个节点</p></li>
</ol>
<ul class="simple">
<li><p>POD 中影响调度的字段，在 kubectl explain pods.spec 中</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nodeName          <span class="c1"># 直接指定 POD 的运行节点</span>
nodeSelector      <span class="c1"># 根据 node 上的标签来对 node 进行预选，这就是节点的亲和性</span>
</pre></div>
</div>
<ul class="simple">
<li><p>其他影响调度的因素</p></li>
</ul>
<p>节点亲和性调度：表现为 nodeSelector 字段</p>
<p>POD 间亲和性：POD 更倾向和某些 POD
运行在一起，例如同一个机房、同一个机器</p>
<p>POD 间反亲和性：POD 和某 POD
更倾向不能运行在一起，这叫反亲和性，例如：监听同一个
nodeport，有机密数据的</p>
<p>Taints（污点）：给某些 node 打上污点，</p>
<p>Tolerations（污点容忍）：一个 POD 能够容忍 node 上的污点，如果运行过程中
node 出现新的污点，那么 POD 可以</p>
<p>驱逐POD：node 给一个限定的时间，让 POD 离开这个节点。</p>
</div>
<div class="section" id="id93">
<h2><a class="toc-backref" href="#id336">17.4 预选因素</a><a class="headerlink" href="#id93" title="Permalink to this headline">¶</a></h2>
<p>下面的预选条件需要满足所有的预选条件才可以通过预选</p>
<ol class="arabic simple">
<li><p>CheckNodeConditionPred</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>检查节点是否正常
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>GeneralPredicates</p></li>
</ol>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 80%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>子策略</p></th>
<th class="head"><p>作用</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>HostName</p></td>
<td><p>检查主机名称是不是 pod.spec.hostname 指定的 NodeName</p></td>
</tr>
<tr class="row-odd"><td><p>PodFitsHostP
orts</p></td>
<td><p>检查 Pod 内每一个容器
pods.spec.containers.ports.hostPort
清单是否已被其它容器占用，如果有所需的 HostPort
不满足需求，那么 Pod 不能调度到这个主机上</p></td>
</tr>
<tr class="row-even"><td><p>MatchNodeSel
ector</p></td>
<td><p>检查 POD 容器上定义了 pods.spec.nodeSelector 查看
node 标签是否能够匹配</p></td>
</tr>
<tr class="row-odd"><td><p>PodFitsResou
rces</p></td>
<td><p>检查 node 是否有足够的资源运行此 POD 的基本要求</p></td>
</tr>
</tbody>
</table>
<ol class="arabic simple" start="3">
<li><p>NoDiskConflict（默认没有启用）</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>检查 pod 定义的存储是否在 node 节点上使用。
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>PodToleratesNodeTaints</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">检查节点的污点</span> <span class="n">nodes</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">taints</span> <span class="n">是否是</span> <span class="n">POD</span> <span class="n">污点容忍清单中</span> <span class="n">pods</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">tolerations</span> <span class="n">的子集</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>PodToleratesNodeNoExecuteTaints</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>检查 pod 是否容忍节点上有 NoExecute 污点。NoExecute 这个污点是啥意思呢。如果一个 pod 上运行在一个没有污点的节点上后，这个节点又给加上污点了，那么 NoExecute 表示这个新加污点的节点会驱逐其上正在运行的 pod；不加 NoExecute 不会驱逐节点上运行的 pod，表示接受既成事实，这是默认策略。
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li><p>CheckNodeLabelPresence（默认没有启用）</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>检查节点上指定标签的存在性，如果节点有pod指定的标签，那么这个节点就被选中。
</pre></div>
</div>
<ol class="arabic simple" start="7">
<li><p>CheckServiceAffinity（默认没有启用）</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>一个 Service 下可以有多个 POD，比如这些 POD 都运行在 1、2、3 机器上，而没有运行在 4、5、6 机器上，那么CheckServiceAffinity 就表示新加入的 POD 都集中运行在 1、2、3 机器上，这样集中好处是一个 Service 下 POD 之间内部通信的效率变高了。
</pre></div>
</div>
<ol class="arabic simple" start="8">
<li><p>MaxEBSVolumeCount</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>确保已挂载的亚马逊 EBS 存储卷不超过设置的最大值，默认39
</pre></div>
</div>
<ol class="arabic simple" start="9">
<li><p>MaxGCEPDVolumeCount</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>确保已挂载的GCE存储卷不超过设置的最大值，默认16
</pre></div>
</div>
<p>10 MaxAzureDiskVolumeCount</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>确保已挂载的Azure存储卷不超过设置的最大值，默认16
</pre></div>
</div>
<ol class="arabic simple" start="11">
<li><p>CheckVolumeBinding</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">检查节点上的</span> <span class="n">PVC</span> <span class="n">是否被别的</span> <span class="n">POD</span> <span class="n">绑定了</span>
</pre></div>
</div>
<ol class="arabic simple" start="12">
<li><p>NoVolumeZoneConflict</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>检查给定的 zone (机房) 限制前提下，检查如果在此主机上部署 POD 是否存在卷冲突
</pre></div>
</div>
<ol class="arabic simple" start="13">
<li><p>CheckNodeMemoryPressure</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">检查</span> <span class="n">node</span> <span class="n">节点上内存是否存在压力</span>
</pre></div>
</div>
<ol class="arabic simple" start="14">
<li><p>CheckNodeDiskPressure</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">检查磁盘</span> <span class="n">IO</span> <span class="n">是否压力过大</span>
</pre></div>
</div>
<ol class="arabic simple" start="15">
<li><p>CheckNodePIDPressure</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">检查</span> <span class="n">node</span> <span class="n">节点上</span> <span class="n">PID</span> <span class="n">资源是否存在压力</span>
</pre></div>
</div>
<ol class="arabic simple" start="16">
<li><p>MatchInterPodAffinity</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">检查</span> <span class="n">Pod</span> <span class="n">是否满足亲和性或者反亲和性</span>
</pre></div>
</div>
</div>
<div class="section" id="id94">
<h2><a class="toc-backref" href="#id337">17.5 优选函数</a><a class="headerlink" href="#id94" title="Permalink to this headline">¶</a></h2>
<p>在每个节点执行优选函数，将结果每个优选函数相加，得分最高的胜出。</p>
<ol class="arabic simple">
<li><p>least_requested.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>选择消耗最小的节点（根据空闲比率评估 cpu(总容量-sum(已使用)*10/总容量)）
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>balanced_resource_allocation.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>均衡资源的使用方式，表示以 cpu 和内存占用率的相近程度作为评估标准，二者占用越接近，得分就越高，得分高的胜出。
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>node_prefer_avoid_pods.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>看节点是否有注解信息 &quot;scheduler.alpha.kubernetes.io/preferAvoidPods&quot; 。没有这个注解信息，说明这个节点是适合运行这个 POD 的。
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>taint_toleration.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>将 pods.spec.tolerations 与 nodes.spec.taints 列表项进行匹配度检查，匹配的条目越多，得分越低。
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>selector_spreading.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>查找当前 POD 对象对应的 service、statefulset、replicatset 等所匹配的标签选择器，在节点上运行的带有这样标签的 POD 越少得分越高，这样的 POD 优选被选出。 这就是说我们要把同一个标签选择器下运行的 POD 散开(spreading)到多个节点上。
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li><p>interpod_affinity_test.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>遍历 POD 对象亲和性的条目，并将那些能够匹配到节点权重相加，值越大的得分越高，得分高的胜出。
</pre></div>
</div>
<ol class="arabic simple" start="7">
<li><p>most_requested.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>表示尽可能的把一个节点的资源先用完，这个和 least_requested 相反，二者不能同时使用。
</pre></div>
</div>
<ol class="arabic simple" start="8">
<li><p>node_label.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>根据节点是否拥有标签，不关心标签是什么，来评估分数。
</pre></div>
</div>
<ol class="arabic simple" start="9">
<li><p>image_locality.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>表示根据满足当前 POD 对象需求的已有镜的体积大小之和来选择节点的。
</pre></div>
</div>
<ol class="arabic simple" start="10">
<li><p>node_affinity.go</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>根据 POD 对象中的 nodeselector，对节点进行匹配度检查，能够成功匹配的数量越多，得分就越高。
</pre></div>
</div>
</div>
<div class="section" id="id95">
<h2><a class="toc-backref" href="#id338">17.6 选择函数</a><a class="headerlink" href="#id95" title="Permalink to this headline">¶</a></h2>
<p>当通过优选的节点有多个，那么从中随机选择一台</p>
</div>
</div>
<div class="section" id="id96">
<h1><a class="toc-backref" href="#id339">十八 高级调度设置</a><a class="headerlink" href="#id96" title="Permalink to this headline">¶</a></h1>
<p>节点选择器：nodeselector、nodeName</p>
<p>节点亲和调度：nodeAffinity</p>
<div class="section" id="id97">
<h2><a class="toc-backref" href="#id340">18.1 节点选择器</a><a class="headerlink" href="#id97" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>使用 nodeselector 来将预选范围缩小，没有被 nodeselector
选中的节点将被预选阶段淘汰</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-schedule-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
  <span class="nt">nodeSelector</span><span class="p">:</span>
    <span class="nt">gpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ok</span>
</pre></div>
</div>
<ul class="simple">
<li><p>此时如果没有任何一个节点有 gpu 这个标签，那么这个 POD
的调度将会被挂起，Pending 状态，直到满足条件</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl label nodes node2 <span class="nv">gpu</span><span class="o">=</span>ok --overwrite
</pre></div>
</div>
<ul class="simple">
<li><p>查看 POD 被调度的节点，POD 已经被调度到 node2 节点了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods -o wide
</pre></div>
</div>
</div>
<div class="section" id="id98">
<h2><a class="toc-backref" href="#id341">18.2 对节点的亲和性</a><a class="headerlink" href="#id98" title="Permalink to this headline">¶</a></h2>
<p>亲和性定义，详见：kubectl explain pods.spec.affinity.nodeAffinity</p>
<ul class="simple">
<li><p>POD 对节点亲和性定义</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nodeAffinity             &lt;Object&gt;                                <span class="c1"># POD 对 node 节点的亲和性</span>
  preferredDuringSchedulingIgnoredDuringExecution  &lt;<span class="o">[]</span>Object&gt;    <span class="c1"># 软亲和性要求，尽量满足亲和性</span>
    preference           &lt;Object&gt;                                <span class="c1"># 亲和的节点对象</span>
      matchExpressions   &lt;<span class="o">[]</span>Object&gt;                              <span class="c1"># 查找表达式</span>
        key              &lt;string&gt;                                <span class="c1"># 标签</span>
        operator         &lt;string&gt;                                <span class="c1"># 操作：比较</span>
        values           &lt;<span class="o">[]</span>string&gt;                              <span class="c1"># 值</span>
      matchFields        &lt;<span class="o">[]</span>Object&gt;                              <span class="c1"># 查找字段</span>
        key              &lt;string&gt;                                <span class="c1"># 标签</span>
        operator         &lt;string&gt;                                <span class="c1"># 操作：比较</span>
        values           &lt;<span class="o">[]</span>string&gt;                              <span class="c1"># 值</span>
    weight               &lt;integer&gt;                               <span class="c1"># 权重 1 - 100</span>
  requiredDuringSchedulingIgnoredDuringExecution   &lt;Object&gt;      <span class="c1"># 硬亲和性要求，不满足则 Pending</span>
    nodeSelectorTerms    &lt;<span class="o">[]</span>Object&gt;                              <span class="c1"># 选择器对象列表</span>
      matchExpressions   &lt;<span class="o">[]</span>Object&gt;                              <span class="c1"># 选择器对象列表</span>
        key              &lt;string&gt;                                <span class="c1"># 标签</span>
        operator         &lt;string&gt;                                <span class="c1"># 操作：比较</span>
        values           &lt;<span class="o">[]</span>string&gt;                              <span class="c1"># 值</span>
      matchFields        &lt;<span class="o">[]</span>Object&gt;                              <span class="c1"># 查找字段</span>
        key              &lt;string&gt;                                <span class="c1"># 标签</span>
        operator         &lt;string&gt;                                <span class="c1"># 操作：比较</span>
        values           &lt;<span class="o">[]</span>string&gt;                              <span class="c1"># 值</span>
</pre></div>
</div>
<ul class="simple">
<li><p>示例配置</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-nodeaffinity1-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
  <span class="nt">affinity</span><span class="p">:</span>
    <span class="nt">nodeAffinity</span><span class="p">:</span>
      <span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>        <span class="c1"># 硬亲和性要求，不满足就 Pending</span>
        <span class="nt">nodeSelectorTerms</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">matchExpressions</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zone</span>
            <span class="nt">operator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">In</span>
            <span class="nt">values</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">foo</span>
            <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">bar</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-nodeaffinity2-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>
  <span class="nt">affinity</span><span class="p">:</span>
    <span class="nt">nodeAffinity</span><span class="p">:</span>
      <span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>     <span class="c1"># 软亲和性要求，不满足也可以对凑</span>
      <span class="p p-Indicator">-</span> <span class="nt">preference</span><span class="p">:</span>
          <span class="nt">matchExpressions</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">zone</span>
            <span class="nt">operator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">In</span>
            <span class="nt">values</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">foo</span>
            <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">bar</span>
        <span class="nt">weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果，kubectl get pods</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME                     READY   STATUS    RESTARTS   AGE
pod-nodeaffinity1-demo   <span class="m">0</span>/1     Pending   <span class="m">0</span>          6m16s  <span class="c1"># 硬亲和性要求，没有就等待</span>
pod-nodeaffinity2-demo   <span class="m">1</span>/1     Running   <span class="m">0</span>          7s     <span class="c1"># 软亲和性要求，没有合适主机也可以凑和</span>
</pre></div>
</div>
</div>
<div class="section" id="id99">
<h2><a class="toc-backref" href="#id342">18.3 对 POD 的亲和性</a><a class="headerlink" href="#id99" title="Permalink to this headline">¶</a></h2>
<p>POD 和 POD 出于高效的通信这种需求，所以需要将 POD 和 POD
组织在同一台机器，同一个机房，例如：LNMT 如果能运行在同一个主机上更好。</p>
<ol class="arabic">
<li><p>想把一组 POD
运行在一起，使用节点亲和性就可以实现，为了达成这个目的，我们需要：把节点标签精心编排，希望在一起运行的
POD，就使用同一组标签选择器来选择节点，这种方式需要管理节点标签和 POD
亲和性才能做到。</p></li>
<li><p>想把一组 POD 运行在一起，使用 POD 亲和性，我们可以设置 POD 对某个 POD
的亲和性，那么比如：LNMT，那么 MySQL 和 Tomcat 可以设置为更加亲和
Ngninx 所在的主机或机柜，所以必须有个前提就是 POD 和 POD
怎么才是最近的，这个标准是什么，也就是什么是同一位置，怎么才能知道
node 和 node 是在一个机柜。</p>
<p>所以可以为同一个机柜的 node 节点打上相同的标签。</p>
</li>
<li><p>MySQL 和 Tomcat 一定不能和 Nginx 运行在一起，这就是反亲和性。</p></li>
</ol>
<ul class="simple">
<li><p>POD 对其他 POD 的亲和性，详见：kubectl explain
pods.spec.affinity.podAffinity</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">podAffinity                &lt;Object&gt;</span>                              <span class="c1"># POD 对其他 POD 的亲和性</span>
  <span class="l l-Scalar l-Scalar-Plain">preferredDuringSchedulingIgnoredDuringExecution  &lt;[]Object&gt;</span>    <span class="c1"># 软性亲和性，尽量满足亲和性</span>
    <span class="l l-Scalar l-Scalar-Plain">podAffinityTerm        &lt;Object&gt;</span>                              <span class="c1"># 亲和的 POD 对象</span>
      <span class="l l-Scalar l-Scalar-Plain">labelSelector        &lt;Object&gt;</span>                              <span class="c1"># 标签选择器对象列表</span>
        <span class="l l-Scalar l-Scalar-Plain">matchExpressions   &lt;[]Object&gt;</span>                            <span class="c1"># 标签选择器对象，选 POD 标签</span>
          <span class="l l-Scalar l-Scalar-Plain">key              &lt;string&gt;</span>                              <span class="c1"># 标签</span>
          <span class="l l-Scalar l-Scalar-Plain">operator         &lt;string&gt;</span>                              <span class="c1"># 操作：比较</span>
          <span class="l l-Scalar l-Scalar-Plain">values           &lt;[]string&gt;</span>                            <span class="c1"># 值</span>
        <span class="l l-Scalar l-Scalar-Plain">matchLabels        &lt;map[string]string&gt;</span>                   <span class="c1"># 集合标签选择器</span>
      <span class="l l-Scalar l-Scalar-Plain">namespaces           &lt;[]string&gt;</span>                            <span class="c1"># 名称空间的列表</span>
      <span class="l l-Scalar l-Scalar-Plain">topologyKey          &lt;string&gt;</span>                              <span class="c1"># 亲和判断条件</span>
    <span class="l l-Scalar l-Scalar-Plain">weight                 &lt;integer&gt;</span>                             <span class="c1"># 权重 1 - 100</span>
  <span class="l l-Scalar l-Scalar-Plain">requiredDuringSchedulingIgnoredDuringExecution   &lt;[]Object&gt;</span>    <span class="c1"># 硬性亲和性，不满足则 Pending</span>
    <span class="l l-Scalar l-Scalar-Plain">labelSelector          &lt;Object&gt;</span>                              <span class="c1"># 标签选择器对象列表</span>
      <span class="l l-Scalar l-Scalar-Plain">matchExpressions   &lt;[]Object&gt;</span>                              <span class="c1"># 标签选择器对象，选 POD 标签</span>
        <span class="l l-Scalar l-Scalar-Plain">key              &lt;string&gt;</span>                                <span class="c1"># 标签</span>
        <span class="l l-Scalar l-Scalar-Plain">operator         &lt;string&gt;</span>                                <span class="c1"># 操作：比较</span>
        <span class="l l-Scalar l-Scalar-Plain">values           &lt;[]string&gt;</span>                              <span class="c1"># 值</span>
      <span class="l l-Scalar l-Scalar-Plain">matchLabels        &lt;map[string]string&gt;</span>                     <span class="c1"># 集合标签选择器</span>
    <span class="l l-Scalar l-Scalar-Plain">namespaces             &lt;[]string&gt;</span>                            <span class="c1"># 名称空间的列表</span>
    <span class="l l-Scalar l-Scalar-Plain">topologyKey            &lt;string&gt;</span>                              <span class="c1"># 亲和判断条件</span>
</pre></div>
</div>
<ul class="simple">
<li><p>示例配置</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod1</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod2</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">db</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">db</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox:latest</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
    <span class="nt">command</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;sh&quot;</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;-c&quot;</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;sleep</span><span class="nv"> </span><span class="s">3600&quot;</span>
  <span class="nt">affinity</span><span class="p">:</span>
    <span class="nt">podAffinity</span><span class="p">:</span>
      <span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>   <span class="c1"># 硬亲和性要求，不满足的 Pending</span>
      <span class="p p-Indicator">-</span> <span class="nt">labelSelector</span><span class="p">:</span>
          <span class="nt">matchExpressions</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app</span>
            <span class="nt">operator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">In</span>
            <span class="nt">values</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">topologyKey</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes.io/hostname</span>             <span class="c1"># 亲和性的依据为同一个主机名则亲和</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果，kubectl get pods -o wide</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME   READY   STATUS    RESTARTS   AGE     IP           NODE    NOMINATED NODE   READINESS GATES
pod1   <span class="m">1</span>/1     Running   <span class="m">0</span>          3m33s   <span class="m">10</span>.244.2.4   node3   &lt;none&gt;           &lt;none&gt;
pod2   <span class="m">1</span>/1     Running   <span class="m">0</span>          3m33s   <span class="m">10</span>.244.2.5   node3   &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
</div>
<div class="section" id="id100">
<h2><a class="toc-backref" href="#id343">18.4 对 POD 的反亲和性</a><a class="headerlink" href="#id100" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>POD 对其他 POD 的反亲和性，详见：kubectl explain
pods.spec.affinity.podAntiAffinity</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">podAntiAffinity              &lt;Object&gt;</span>                            <span class="c1"># POD 对其他 POD 的反亲和性</span>
  <span class="l l-Scalar l-Scalar-Plain">preferredDuringSchedulingIgnoredDuringExecution  &lt;[]Object&gt;</span>    <span class="c1"># 软性反亲和性，尽量满足亲和性</span>
    <span class="l l-Scalar l-Scalar-Plain">podAffinityTerm        &lt;Object&gt;</span>                              <span class="c1"># 反亲和的 POD 对象</span>
      <span class="l l-Scalar l-Scalar-Plain">labelSelector        &lt;Object&gt;</span>                              <span class="c1"># 标签选择器对象列表</span>
        <span class="l l-Scalar l-Scalar-Plain">matchExpressions   &lt;[]Object&gt;</span>                            <span class="c1"># 标签选择器对象，选 POD 标签</span>
          <span class="l l-Scalar l-Scalar-Plain">key              &lt;string&gt;</span>                              <span class="c1"># 标签</span>
          <span class="l l-Scalar l-Scalar-Plain">operator         &lt;string&gt;</span>                              <span class="c1"># 操作：比较</span>
          <span class="l l-Scalar l-Scalar-Plain">values           &lt;[]string&gt;</span>                            <span class="c1"># 值</span>
        <span class="l l-Scalar l-Scalar-Plain">matchLabels        &lt;map[string]string&gt;</span>                   <span class="c1"># 集合标签选择器</span>
      <span class="l l-Scalar l-Scalar-Plain">namespaces           &lt;[]string&gt;</span>                            <span class="c1"># 名称空间的列表</span>
      <span class="l l-Scalar l-Scalar-Plain">topologyKey          &lt;string&gt;</span>                              <span class="c1"># 亲和判断条件</span>
    <span class="l l-Scalar l-Scalar-Plain">weight                 &lt;integer&gt;</span>                             <span class="c1"># 权重 1 - 100</span>
  <span class="l l-Scalar l-Scalar-Plain">requiredDuringSchedulingIgnoredDuringExecution   &lt;[]Object&gt;</span>    <span class="c1"># 硬性反亲和性，不满足则 Pending</span>
    <span class="l l-Scalar l-Scalar-Plain">labelSelector          &lt;Object&gt;</span>                              <span class="c1"># 标签选择器对象列表</span>
      <span class="l l-Scalar l-Scalar-Plain">matchExpressions   &lt;[]Object&gt;</span>                              <span class="c1"># 标签选择器对象，选 POD 标签</span>
        <span class="l l-Scalar l-Scalar-Plain">key              &lt;string&gt;</span>                                <span class="c1"># 标签</span>
        <span class="l l-Scalar l-Scalar-Plain">operator         &lt;string&gt;</span>                                <span class="c1"># 操作：比较</span>
        <span class="l l-Scalar l-Scalar-Plain">values           &lt;[]string&gt;</span>                              <span class="c1"># 值</span>
      <span class="l l-Scalar l-Scalar-Plain">matchLabels        &lt;map[string]string&gt;</span>                     <span class="c1"># 集合标签选择器</span>
    <span class="l l-Scalar l-Scalar-Plain">namespaces             &lt;[]string&gt;</span>                            <span class="c1"># 名称空间的列表</span>
    <span class="l l-Scalar l-Scalar-Plain">topologyKey            &lt;string&gt;</span>                              <span class="c1"># 亲和判断条件</span>
</pre></div>
</div>
<ul class="simple">
<li><p>配置清单</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod3</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v1</span>

<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod4</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">db</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">db</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox:latest</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
    <span class="nt">command</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;sh&quot;</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;-c&quot;</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;sleep</span><span class="nv"> </span><span class="s">3600&quot;</span>
  <span class="nt">affinity</span><span class="p">:</span>
    <span class="nt">podAntiAffinity</span><span class="p">:</span>
      <span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>   <span class="c1"># 硬亲和性要求，不满足的 Pending</span>
      <span class="p p-Indicator">-</span> <span class="nt">labelSelector</span><span class="p">:</span>
          <span class="nt">matchExpressions</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">app</span>
            <span class="nt">operator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">In</span>
            <span class="nt">values</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">topologyKey</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes.io/hostname</span>             <span class="c1"># 反亲和性的依据为同一个主机名</span>
</pre></div>
</div>
</div>
<div class="section" id="id101">
<h2><a class="toc-backref" href="#id344">18.5 node 污点</a><a class="headerlink" href="#id101" title="Permalink to this headline">¶</a></h2>
<p>污点只用在 node
上的键值属性（nodes.spec.taints），它的作用是拒绝不能容忍这些污点的 POD
运行的，因此需要在 POD
上定义容忍度（pods.spec.tolerations），它也是键值数据，是一个列表，表示
POD 可以容忍的污点列表。</p>
<p>一个 POD 能不能运行在一个节点上，就是 pods.spec.tolerations
列表中是否包括了 nodes.spec.taints 中的数据。</p>
<ul class="simple">
<li><p>node 污点清单格式，详见：kubectl explain node.spec.taints</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">taints          &lt;[]Object&gt;</span>     <span class="c1"># 污点对象列表</span>
  <span class="l l-Scalar l-Scalar-Plain">effect        &lt;string&gt;</span>       <span class="c1"># 当 POD 不能容忍这个污点的时候，要采取的行为，也就是排斥不容忍污点的 POD</span>
    <span class="l l-Scalar l-Scalar-Plain">NoSchedule</span>                 <span class="c1"># 影响调度过程，但是已经调度完成 POD 无影响</span>
    <span class="l l-Scalar l-Scalar-Plain">PreferNoSchedule</span>           <span class="c1"># 影响调度过程，尝试驱逐调度已经完成的但不容忍新污点的 POD</span>
    <span class="l l-Scalar l-Scalar-Plain">NoExecute</span>                  <span class="c1"># 新增的污点，影响新的调度过程，且强力驱逐调度已经完成的但不容忍新污点的 POD</span>
  <span class="l l-Scalar l-Scalar-Plain">key           &lt;string&gt;</span>       <span class="c1"># 键</span>
  <span class="l l-Scalar l-Scalar-Plain">timeAdded     &lt;string&gt;</span>       <span class="c1">#</span>
  <span class="l l-Scalar l-Scalar-Plain">value         &lt;string&gt;</span>       <span class="c1"># 值</span>
</pre></div>
</div>
<ul class="simple">
<li><p>给 node 打上污点，键为 node-type 值为 production，污点动作</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl taint node node2 node-type<span class="o">=</span>production:NoSchedule
</pre></div>
</div>
<ul class="simple">
<li><p>删除 node 上的一个污点</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl taint node node2 node-type-
</pre></div>
</div>
<ul class="simple">
<li><p>测试清单</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-deploy</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v2</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果，kubectl get pods -o wide，因为 POD 没有定义容忍 node2
的污点</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">NAME                            READY   STATUS    RESTARTS   AGE   IP            NODE    NOMINATED NODE   READINESS GATES</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-675558bfc5-4x5cf   1/1     Running   0          9s    10.244.2.13   node3   &lt;none&gt;           &lt;none&gt;</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-675558bfc5-58f2s   1/1     Running   0          9s    10.244.2.10   node3   &lt;none&gt;           &lt;none&gt;</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-675558bfc5-gz4kv   1/1     Running   0          9s    10.244.2.12   node3   &lt;none&gt;           &lt;none&gt;</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-675558bfc5-hlxdd   1/1     Running   0          9s    10.244.2.11   node3   &lt;none&gt;           &lt;none&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>此时给 node3 也打上污点，并驱逐原有的 POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl taint node node3 node-type<span class="o">=</span>dev:NoExecute
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果，kubectl get pods -o wide，因为 node3
新增的污点驱逐了不能容忍污点的 POD ，所以 POD 被挂起</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME                            READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES
myapp-deploy-675558bfc5-22wpj   <span class="m">0</span>/1     Pending   <span class="m">0</span>          10s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
myapp-deploy-675558bfc5-lctv5   <span class="m">0</span>/1     Pending   <span class="m">0</span>          14s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
myapp-deploy-675558bfc5-m5qdh   <span class="m">0</span>/1     Pending   <span class="m">0</span>          15s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
myapp-deploy-675558bfc5-z8c4q   <span class="m">0</span>/1     Pending   <span class="m">0</span>          14s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
</div>
<div class="section" id="id102">
<h2><a class="toc-backref" href="#id345">18.6 POD 污点容忍</a><a class="headerlink" href="#id102" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>POD 容忍度，详见：kubectl explain pods.spec.tolerations</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">tolerations            &lt;[]Object&gt;</span>    <span class="c1"># 容忍度对象</span>
  <span class="l l-Scalar l-Scalar-Plain">effect               &lt;string&gt;</span>      <span class="c1"># 能否容忍 node 上的污点驱逐策略，为空表示容忍任何驱逐策略</span>
    <span class="l l-Scalar l-Scalar-Plain">NoSchedule</span>                       <span class="c1"># 能容忍 node 污点的 NoSchedule</span>
    <span class="l l-Scalar l-Scalar-Plain">PreferNoSchedule</span>                 <span class="c1"># 能容忍 node 污点的 PreferNoSchedule</span>
    <span class="l l-Scalar l-Scalar-Plain">NoExecute</span>                        <span class="c1"># 能容忍 node 污点的 NoExecute</span>
  <span class="l l-Scalar l-Scalar-Plain">key                  &lt;string&gt;</span>      <span class="c1"># 污点的键</span>
  <span class="l l-Scalar l-Scalar-Plain">operator             &lt;string&gt;</span>      <span class="c1"># Exists 污点存在不管什么值，Equal 污点的值必须等值</span>
  <span class="l l-Scalar l-Scalar-Plain">tolerationSeconds    &lt;integer&gt;</span>     <span class="c1"># 容忍时间，即如果被驱逐，可以等多久再走，默认 0 秒，NoExecute 使用</span>
  <span class="l l-Scalar l-Scalar-Plain">value                &lt;string&gt;</span>      <span class="c1"># 污点的值</span>
</pre></div>
</div>
<ul class="simple">
<li><p>给 node2 、node3 分别打污点</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl taint node node2 node-type<span class="o">=</span>production:NoSchedule
kubectl taint node node3 node-type<span class="o">=</span>dev:NoExecute
</pre></div>
</div>
<ul class="simple">
<li><p>定义 POD 清单文件，容忍 node 上存在 node-type 值为 dev
的污点、接受被驱逐。</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-deploy</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
      <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
      <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
        <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">canary</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
          <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/myapp:v2</span>
          <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
              <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
      <span class="nt">tolerations</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">node-type</span>
        <span class="nt">operator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Equal</span>
        <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dev</span>
        <span class="nt">effect</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NoExecute</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果，kubectl get pods -o wide，运行在自己容忍的污点的节点上了</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">NAME                           READY   STATUS    RESTARTS   AGE     IP            NODE    NOMINATED NODE   READINESS GATES</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-97578cf74-5v2r6   1/1     Running   0          6m22s   10.244.2.16   node3   &lt;none&gt;           &lt;none&gt;</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-97578cf74-gbfj7   1/1     Running   0          6m22s   10.244.2.14   node3   &lt;none&gt;           &lt;none&gt;</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-97578cf74-l4lbv   1/1     Running   0          6m22s   10.244.2.15   node3   &lt;none&gt;           &lt;none&gt;</span>
<span class="l l-Scalar l-Scalar-Plain">myapp-deploy-97578cf74-zvn8f   1/1     Running   0          6m20s   10.244.2.17   node3   &lt;none&gt;           &lt;none&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>为节点增加新的污点，设置驱离 POD</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl taint node node3 <span class="nv">disk</span><span class="o">=</span>hdd:NoExecute --overwrite
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果，kubectl get pods -o wide，POD 不能容忍新的污点，结果被驱逐</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME                           READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES
myapp-deploy-97578cf74-84bfz   <span class="m">0</span>/1     Pending   <span class="m">0</span>          6s    &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
myapp-deploy-97578cf74-fxk2d   <span class="m">0</span>/1     Pending   <span class="m">0</span>          5s    &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
myapp-deploy-97578cf74-jp99j   <span class="m">0</span>/1     Pending   <span class="m">0</span>          6s    &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
myapp-deploy-97578cf74-vdkbx   <span class="m">0</span>/1     Pending   <span class="m">0</span>          6s    &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="id103">
<h1><a class="toc-backref" href="#id346">十九 容器资源限制</a><a class="headerlink" href="#id103" title="Permalink to this headline">¶</a></h1>
<p>起始值 requests 最低保障</p>
<p>终结值 limits 硬限制</p>
<ul class="simple">
<li><p>CPU</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="n">颗</span> <span class="n">CPU</span> <span class="o">=</span> <span class="mi">1000</span> <span class="n">millicores</span>
<span class="mf">0.5</span> <span class="n">颗</span> <span class="n">CPU</span> <span class="o">=</span> <span class="mi">500</span> <span class="n">m</span>
</pre></div>
</div>
<ul class="simple">
<li><p>内存</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Ei、Pi、Ti、Gi、Mi、Ki
</pre></div>
</div>
<div class="section" id="id104">
<h2><a class="toc-backref" href="#id347">19.1 资源限制</a><a class="headerlink" href="#id104" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>清单格式，详见：kubectl explain pods.spec.containers.resources</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">resources      &lt;Object&gt;</span>               <span class="c1"># 资源限制</span>
  <span class="l l-Scalar l-Scalar-Plain">limits       &lt;map[string]string&gt;</span>    <span class="c1"># 资源最高限制</span>
    <span class="l l-Scalar l-Scalar-Plain">cpu        &lt;string&gt;</span>               <span class="c1"># 单位 m</span>
    <span class="l l-Scalar l-Scalar-Plain">memory     &lt;string&gt;</span>               <span class="c1"># 单位 Gi、Mi</span>
  <span class="l l-Scalar l-Scalar-Plain">requests     &lt;map[string]string&gt;</span>    <span class="c1"># 资源最低要求</span>
    <span class="l l-Scalar l-Scalar-Plain">cpu        &lt;string&gt;</span>               <span class="c1"># 单位 m</span>
    <span class="l l-Scalar l-Scalar-Plain">memory     &lt;string&gt;</span>               <span class="c1"># 单位 Gi、Mi</span>
</pre></div>
</div>
<ul class="simple">
<li><p>清单示例，node 节点的 CPU 为 12 核心，cpu limits 设置为 1000m
也就是允许</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pod-resources-demo</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
    <span class="nt">tier</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">frontend</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ikubernetes/stress-ng</span>
    <span class="nt">command</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;/usr/bin/stress-ng&quot;</span>
    <span class="c1">#- &quot;-m 1&quot;                       # 以单线程压测内存</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;-c</span><span class="nv"> </span><span class="s">1&quot;</span>                        <span class="c1"># 以单线程压测CPU</span>
    <span class="p p-Indicator">-</span> <span class="s">&quot;--metrics-brief&quot;</span>
    <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http</span>
      <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https</span>
      <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>
    <span class="nt">resources</span><span class="p">:</span>
      <span class="nt">requests</span><span class="p">:</span>
        <span class="nt">cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000m</span>                 <span class="c1"># 它决定在预选阶段淘汰哪些主机</span>
        <span class="nt">memory</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">512Mi</span>
      <span class="nt">limits</span><span class="p">:</span>
        <span class="nt">cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000m</span>                 <span class="c1"># 表示限制容器使用 node 节点的一颗 CPU，无论多少进程，它们最多只能占用 node 节点的可 CPU</span>
        <span class="nt">memory</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">512Mi</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">Mem</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">855392K used, 139916K free, 10188K shrd, 796K buff, 350368K cached</span>
<span class="nt">CPU0</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU1</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">100% usr   0% sys   0% nic   0% idle   0% io   0% irq   0% sirq</span>         <span class="c1"># 占满了一颗 CPU</span>
<span class="nt">CPU2</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU3</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU4</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU5</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU6</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU7</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU8</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU9</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU10</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">CPU11</span><span class="p">:</span>   <span class="l l-Scalar l-Scalar-Plain">0% usr   0% sys   0% nic  99% idle   0% io   0% irq   0% sirq</span>
<span class="nt">Load average</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.84 0.50 0.40 3/485 11</span>
  <span class="l l-Scalar l-Scalar-Plain">PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND</span>
    <span class="l l-Scalar l-Scalar-Plain">6     1 root     R     6888   1%   1   8% {stress-ng-cpu} /usr/bin/stress-ng -c 1 --metrics-brief</span>
    <span class="l l-Scalar l-Scalar-Plain">1     0 root     S     6244   1%  10   0% /usr/bin/stress-ng -c 1 --metrics-brief</span>
    <span class="l l-Scalar l-Scalar-Plain">7     0 root     R     1504   0%  11   0% top</span>
</pre></div>
</div>
</div>
<div class="section" id="qos">
<h2><a class="toc-backref" href="#id348">19.2 qos 质量管理</a><a class="headerlink" href="#qos" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>GuranteedW</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>每个容器同时设置了 CPU 和内存的 requests 和 limits，而且
    cpu.limits = cpu.requests
    memory.limits = memory.requests
那么它将优先被调度
</pre></div>
</div>
<ul class="simple">
<li><p>Burstable</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">至少有一个容器设置</span> <span class="n">CPU</span> <span class="n">或内存资源的</span> <span class="n">requests</span> <span class="n">属性</span>

<span class="n">那么它将具有中等优先级</span>
</pre></div>
</div>
<ul class="simple">
<li><p>BestEffort</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>没有任何一个容器设置了 requests 或 limits 属性

那么它将只有最低优先级，当资源不够用的时候，这个容器可能最先被终止，以腾出资源来，为 Burstable 和 Guranteed
</pre></div>
</div>
<ul class="simple">
<li><p>oom 策略</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">最先杀死占用量和需求量的比例大的</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="heapster">
<h1><a class="toc-backref" href="#id349">二十 HeapSter监控（废弃中）</a><a class="headerlink" href="#heapster" title="Permalink to this headline">¶</a></h1>
<p>kubectl top 是 k8s 内置查看 POD 监控信息的命令，它是从 HeapSter
中取得数据，而 HeapSter 是运行在 K8S 集群级别的监控软件。</p>
<p>kubectl 有一个内置插件，叫 cAdvisor 它用来收集 node 节点和节点上的 POD
上的资源使用量，HeapSter 可以收集 cAdvisor
在每个节点上采集的数据，这些数据想要持续存储，那么就必须将数据放在
influx DB 的数据库中，然后可以使用 Grafana 配置 influx DB
为数据源，然后展示。</p>
<ul class="simple">
<li><p>heapster 官方项目</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">kubernetes</span><span class="o">-</span><span class="n">retired</span><span class="o">/</span><span class="n">heapster</span>
</pre></div>
</div>
<div class="section" id="influx-db">
<h2><a class="toc-backref" href="#id350">20.1 安装 influx DB</a><a class="headerlink" href="#influx-db" title="Permalink to this headline">¶</a></h2>
<p>influx DB
是一个时序数据库，它需要一个持久存储来保存数据，所以要注意的是在它的清单文件中应该将官方默认的
emptyDir 修改为具有持久存储能力的存储卷。</p>
<ul class="simple">
<li><p>heapster/deploy/kube-config/influxdb/influxdb.yaml</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>                     <span class="c1"># 此处修改为 apps/v1，由于修改了此处所以还需要修改标签选择器</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring-influxdb</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>                             <span class="c1"># 添加标签</span>
    <span class="nt">matchLables</span><span class="p">:</span>                        <span class="c1"># 添加标签</span>
      <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>                  <span class="c1"># 添加标签</span>
      <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">influxdb</span>                 <span class="c1"># 添加标签</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>
        <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">influxdb</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">influxdb</span>
        <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">k8s.gcr.io/heapster-influxdb-amd64:v1.5.2</span>
        <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/data</span>
          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">influxdb-storage</span>
      <span class="nt">volumes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">influxdb-storage</span>
        <span class="nt">emptyDir</span><span class="p">:</span> <span class="p p-Indicator">{}</span>                    <span class="c1"># 此处应该修改为具有持久存储能力的</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>
    <span class="c1"># For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons)</span>
    <span class="c1"># If you are NOT using this as an addon, you should comment out this line.</span>
    <span class="nt">kubernetes.io/cluster-service</span><span class="p">:</span> <span class="s">&#39;true&#39;</span>
    <span class="nt">kubernetes.io/name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring-influxdb</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring-influxdb</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8086</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8086</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">influxdb</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看 service 和 pod</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get svc -n kube-system
NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>                  AGE
kube-dns               ClusterIP   <span class="m">10</span>.96.0.10       &lt;none&gt;        <span class="m">53</span>/UDP,53/TCP,9153/TCP   9d
kubernetes-dashboard   NodePort    <span class="m">10</span>.109.5.194     &lt;none&gt;        <span class="m">443</span>:30894/TCP            3d14h
monitoring-influxdb    ClusterIP   <span class="m">10</span>.104.173.236   &lt;none&gt;        <span class="m">8086</span>/TCP                 18s

$ kubectl get pod -n kube-system
NAME                                    READY   STATUS    RESTARTS   AGE
.....
monitoring-influxdb-866db5f944-d7rkd    <span class="m">1</span>/1     Running   <span class="m">0</span>          69s
</pre></div>
</div>
</div>
<div class="section" id="id105">
<h2><a class="toc-backref" href="#id351">20.2 安装 HeapSter</a><a class="headerlink" href="#id105" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>首先安装 rbac
的用户，heapster/deploy/kube-config/rbac/heapster-rbac.yaml</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterRoleBinding</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io/v1beta1</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
<span class="nt">roleRef</span><span class="p">:</span>
  <span class="nt">apiGroup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbac.authorization.k8s.io</span>
  <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterRole</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">system:heapster</span>
<span class="nt">subjects</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ServiceAccount</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
</pre></div>
</div>
<ul class="simple">
<li><p>安装 heapster，heapster/deploy/kube-config/influxdb/heapster.yaml</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ServiceAccount</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>                    <span class="c1"># 修改此处的为 apps/v1，修改此处以后还需要添加 selector</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>                           <span class="c1"># 因为修改 api 版本所以需要添加</span>
    <span class="nt">matchLabels</span><span class="p">:</span>                      <span class="c1"># 添加</span>
      <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>                <span class="c1"># 添加</span>
      <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>               <span class="c1"># 添加</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>
        <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">serviceAccountName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
      <span class="nt">containers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
        <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">k8s.gcr.io/heapster-amd64:v1.5.4</span>
        <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
        <span class="nt">command</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/heapster</span>
        <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">--source=kubernetes:https://kubernetes.default</span>
        <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">--sink=influxdb:http://monitoring-influxdb.kube-system.svc:8086</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>
    <span class="nt">kubernetes.io/cluster-service</span><span class="p">:</span> <span class="s">&#39;true&#39;</span>
    <span class="nt">kubernetes.io/name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Heapster</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8082</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heapster</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看结果，kubectl get pods -n kube-system</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NAME</span>                                    <span class="n">READY</span>   <span class="n">STATUS</span>    <span class="n">RESTARTS</span>   <span class="n">AGE</span>
<span class="o">...</span>
<span class="n">heapster</span><span class="o">-</span><span class="mi">5</span><span class="n">d4bf58946</span><span class="o">-</span><span class="mi">6</span><span class="n">dmgf</span>               <span class="mi">1</span><span class="o">/</span><span class="mi">1</span>     <span class="n">Running</span>   <span class="mi">0</span>          <span class="mi">113</span><span class="n">s</span>
<span class="n">monitoring</span><span class="o">-</span><span class="n">influxdb</span><span class="o">-</span><span class="mi">866</span><span class="n">db5f944</span><span class="o">-</span><span class="n">d7rkd</span>    <span class="mi">1</span><span class="o">/</span><span class="mi">1</span>     <span class="n">Running</span>   <span class="mi">0</span>          <span class="mi">23</span><span class="n">m</span>
</pre></div>
</div>
</div>
<div class="section" id="grafana">
<h2><a class="toc-backref" href="#id352">20.3 安装 Grafana</a><a class="headerlink" href="#grafana" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>安装 Grafana 清单：heapster/deploy/kube-config/influxdb/grafana.yaml</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>                <span class="c1"># 修改此处为 apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring-grafana</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">selector</span><span class="p">:</span>                        <span class="c1"># 由于修改了 api 版本，所以增加此处</span>
    <span class="nt">matchLabels</span><span class="p">:</span>                   <span class="c1"># 标签选择器</span>
      <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>             <span class="c1"># 标签选择器</span>
      <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grafana</span>             <span class="c1"># 标签选择器</span>
  <span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
      <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring</span>
        <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grafana</span>
    <span class="nt">spec</span><span class="p">:</span>
      <span class="nt">containers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grafana</span>
        <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">k8s.gcr.io/heapster-grafana-amd64:v5.0.4</span>
        <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3000</span>
          <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
        <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/ssl/certs</span>
          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ca-certificates</span>
          <span class="nt">readOnly</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/var</span>
          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grafana-storage</span>
        <span class="nt">env</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">INFLUXDB_HOST</span>
          <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring-influxdb</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GF_SERVER_HTTP_PORT</span>
          <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;3000&quot;</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GF_AUTH_BASIC_ENABLED</span>
          <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;false&quot;</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GF_AUTH_ANONYMOUS_ENABLED</span>
          <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;true&quot;</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GF_AUTH_ANONYMOUS_ORG_ROLE</span>
          <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Admin</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GF_SERVER_ROOT_URL</span>
          <span class="nt">value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
      <span class="nt">volumes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ca-certificates</span>
        <span class="nt">hostPath</span><span class="p">:</span>
          <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/ssl/certs</span>              <span class="c1"># 注意配置 ssl 证书</span>
      <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grafana-storage</span>
        <span class="nt">emptyDir</span><span class="p">:</span> <span class="p p-Indicator">{}</span>                       <span class="c1"># 注意配置持久存储</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">kubernetes.io/cluster-service</span><span class="p">:</span> <span class="s">&#39;true&#39;</span>
    <span class="nt">kubernetes.io/name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring-grafana</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">monitoring-grafana</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NodePort</span>                         <span class="c1"># 如果需要通过外部访问可以打开，可以关闭 heapster 的此项</span>
  <span class="nt">ports</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3000</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grafana</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id106">
<h1><a class="toc-backref" href="#id353">二十一 新一代监控架构</a><a class="headerlink" href="#id106" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id107">
<h2><a class="toc-backref" href="#id354">21.1 核心指标流水线</a><a class="headerlink" href="#id107" title="Permalink to this headline">¶</a></h2>
<p>由 kubelet、metrics-server 以及由 apiserver 提供的 api 组成；主要
CPU累计使用率、内存实时使用率、POD 资源占用率及容器的磁盘占用率。</p>
<ul class="simple">
<li><p>metrics-server（新一代的资源指标获取方式）</p></li>
</ul>
<p>它是一个 apiserver ，它仅仅用于服务于核心指标服务的，它不是 k8s
的组成部分，仅仅是托管在 k8s 之上 POD。</p>
<p>k8s 的 apiserver 和 metrics-server 的 apiserver
前端应该加一个代理服务器，它就是一个聚合器，把来自多个不同的 apiserver
聚合成一个。它就是 kube-aggregator，经过它聚合后的 api 我么将通过
/apis/metrics.k8s.io/v1/beta1 来获取。</p>
</div>
<div class="section" id="id108">
<h2><a class="toc-backref" href="#id355">21.2监控流水线</a><a class="headerlink" href="#id108" title="Permalink to this headline">¶</a></h2>
<p>用于从系统收集各种指标数据并提供终端用户、存储系统以及
HPA，它包含核心指标和非核心指标，非核心指标不能被 k8s
所理解，k8s-prometheus-adapter 就是转换为 k8s 所理解格式的一个插件</p>
<ul class="simple">
<li><p>prometheus</p></li>
</ul>
<p>CNCF下的第二大项目，收集各种维度的指标，</p>
<p>它收集的信息，来决定是否进行 HPA（自动伸缩） 的一个标准</p>
<p>prometheus
既作为监控系统使用，也作为特殊指标的提供者来使用，但是如果想要作为特殊指标提供给
HPA
这样的机制使用，需要转换格式，而这个转换为特殊指标的一个插件叫：k8s-prometheus-adapter。</p>
</div>
<div class="section" id="metrics-server">
<h2><a class="toc-backref" href="#id356">21.3 安装 metrics-server</a><a class="headerlink" href="#metrics-server" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>官方仓库，这里我使用第一个</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>https://github.com/kubernetes-incubator/metrics-server/tree/master/deploy/1.8%2B      <span class="c1"># 插件官方地址</span>
https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/metrics-server    <span class="c1"># k8s 官方插件示例</span>
</pre></div>
</div>
<ul class="simple">
<li><p>安装部署相关的文件：/tree/master/deploy/，修改
metrics-server-deployment.yaml 文件</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">containers</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">metrics-server</span>
  <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">k8s.gcr.io/metrics-server-amd64:v0.3.1</span>
  <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Always</span>
  <span class="nt">args</span><span class="p">:</span>                                               <span class="c1"># 添加参数</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;--kubelet-preferred-address-types=InternalIP&#39;</span>    <span class="c1"># 不使用主机名，使用 IP</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;--kubelet-insecure-tls&#39;</span>                          <span class="c1"># 不验证客户端证书</span>
  <span class="nt">volumeMounts</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tmp-dir</span>
    <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/tmp</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl apply -f ./
</pre></div>
</div>
<ul class="simple">
<li><p>查看 POD 和 Service 的启动情况</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get pods -n kube-system
$ kubectl get svc -n kube-system
</pre></div>
</div>
<ul class="simple">
<li><p>查看 API 中是否存在，metrics.k8s.io/v1beta1</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl api-versions
</pre></div>
</div>
<ul class="simple">
<li><p>通过测试接口获取监控数据，kubectl proxy –port 8080，kubectl top
也可以正常使用了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl http://127.0.0.1:8080/apis/metrics.k8s.io/v1beta1
$ kubectl top nodes
</pre></div>
</div>
</div>
<div class="section" id="prometheus">
<h2><a class="toc-backref" href="#id357">21.4 安装 prometheus</a><a class="headerlink" href="#prometheus" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>工作原理</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>-   prometheus 通过 pull metrilcs 指令从每个 Jobs/exporters 拉取数据
-   其他的 short-lived jobs 也可以通过向 pushgateway 主动发送数据，由 prometheus 被动接收
-   prometheus 自身实现了一个时间序列数据库，会将得到的数据存储到其中
-   在 k8s 需要使用 service discovery 来发现服务取得需要监控的目标
-   可以使用 apiclient、webui、Grafana、来将 prometheus 中的数据展示出来
-   当需要报警的时候还会推送给 alertmanager 这个组件由这个组件来发送报警
</pre></div>
</div>
<ul class="simple">
<li><p>部署文件</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/prometheus
https://github.com/iKubernetes/k8s-prom
</pre></div>
</div>
</div>
<div class="section" id="hpa">
<h2><a class="toc-backref" href="#id358">21.5 HPA命令行方式</a><a class="headerlink" href="#hpa" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>创建 POD 和 service</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl run myapp --image<span class="o">=</span>ikubernetes/myapp:v1 --replicas<span class="o">=</span><span class="m">1</span> --requests<span class="o">=</span><span class="s1">&#39;cpu=50m&#39;</span>,memory<span class="o">=</span><span class="s1">&#39;256Mi&#39;</span> --limits<span class="o">=</span><span class="s1">&#39;cpu=50m,memory=256Mi&#39;</span> --labels<span class="o">=</span><span class="s1">&#39;app=myapp&#39;</span> --expose --port<span class="o">=</span><span class="m">80</span>
</pre></div>
</div>
<ul class="simple">
<li><p>创建 HPA 控制器</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kubectl</span> <span class="n">autoscale</span> <span class="n">deployment</span> <span class="n">myapp</span> <span class="o">--</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span> <span class="o">--</span><span class="nb">max</span><span class="o">=</span><span class="mi">8</span> <span class="o">--</span><span class="n">cpu</span><span class="o">-</span><span class="n">percent</span><span class="o">=</span><span class="mi">60</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看 HPA 控制器，kubectl get hpa</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
myapp   Deployment/myapp   <span class="m">0</span>%/60%    <span class="m">1</span>         <span class="m">8</span>         <span class="m">1</span>          17s
</pre></div>
</div>
<ul class="simple">
<li><p>开始压力测试</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ab -c <span class="m">100</span> -n <span class="m">5000000</span> http://172.16.100.102:32749/index.html
</pre></div>
</div>
<ul class="simple">
<li><p>测试结果，自动扩容生效</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get hpa -w
NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
myapp   Deployment/myapp   <span class="m">0</span>%/60%    <span class="m">1</span>         <span class="m">8</span>         <span class="m">1</span>          7m35s
myapp   Deployment/myapp   <span class="m">34</span>%/60%   <span class="m">1</span>         <span class="m">8</span>         <span class="m">1</span>          9m58s
myapp   Deployment/myapp   <span class="m">102</span>%/60%   <span class="m">1</span>         <span class="m">8</span>         <span class="m">1</span>          11m
myapp   Deployment/myapp   <span class="m">102</span>%/60%   <span class="m">1</span>         <span class="m">8</span>         <span class="m">2</span>          11m
myapp   Deployment/myapp   <span class="m">96</span>%/60%    <span class="m">1</span>         <span class="m">8</span>         <span class="m">2</span>          12m
myapp   Deployment/myapp   <span class="m">96</span>%/60%    <span class="m">1</span>         <span class="m">8</span>         <span class="m">4</span>          12m
myapp   Deployment/myapp   <span class="m">31</span>%/60%    <span class="m">1</span>         <span class="m">8</span>         <span class="m">4</span>          13m
myapp   Deployment/myapp   <span class="m">26</span>%/60%    <span class="m">1</span>         <span class="m">8</span>         <span class="m">4</span>          14m
myapp   Deployment/myapp   <span class="m">0</span>%/60%     <span class="m">1</span>         <span class="m">8</span>         <span class="m">4</span>          15m
myapp   Deployment/myapp   <span class="m">0</span>%/60%     <span class="m">1</span>         <span class="m">8</span>         <span class="m">4</span>          17m
myapp   Deployment/myapp   <span class="m">0</span>%/60%     <span class="m">1</span>         <span class="m">8</span>         <span class="m">3</span>          18m

$ kubectl get pods
NAME                     READY   STATUS        RESTARTS   AGE
myapp-64bf6764c5-45qwj   <span class="m">0</span>/1     Terminating   <span class="m">0</span>          7m1s
myapp-64bf6764c5-72crv   <span class="m">1</span>/1     Running       <span class="m">0</span>          20m
myapp-64bf6764c5-gmz6c   <span class="m">1</span>/1     Running       <span class="m">0</span>          8m1s
</pre></div>
</div>
</div>
<div class="section" id="id109">
<h2><a class="toc-backref" href="#id359">21.6 HPA清单</a><a class="headerlink" href="#id109" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>清单定义详见：kubectl explain hpa.spec</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">maxReplicas                       &lt;integer&gt;</span>         <span class="c1"># 自动伸缩的 POD 数量上限</span>
<span class="l l-Scalar l-Scalar-Plain">minReplicas                       &lt;integer&gt;</span>         <span class="c1"># 自动伸缩的 POD 数量下限</span>
<span class="l l-Scalar l-Scalar-Plain">scaleTargetRef                    &lt;Object&gt;</span>          <span class="c1"># 其他的伸缩指标</span>
  <span class="l l-Scalar l-Scalar-Plain">apiVersion                      &lt;string&gt;</span>          <span class="c1"># 指标 api 版本</span>
  <span class="l l-Scalar l-Scalar-Plain">kind                            &lt;string&gt;</span>          <span class="c1"># 指标类型</span>
  <span class="l l-Scalar l-Scalar-Plain">name                            &lt;string&gt;</span>          <span class="c1"># 可用指标</span>
<span class="l l-Scalar l-Scalar-Plain">targetCPUUtilizationPercentage    &lt;integer&gt;</span>         <span class="c1"># 根据目标 平均 CPU 利用率阈值评估自动伸缩</span>
</pre></div>
</div>
<ul class="simple">
<li><p>示例清单，它实现了对 myapp 这个 deployment 控制器下的 POD
进行自动扩容</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">autoscaling/v2beta1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">HorizontalPodAutoscaler</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp-hpa-v2</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">scaleTargetRef</span><span class="p">:</span>
    <span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
    <span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">myapp</span>
  <span class="nt">minReplicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">maxReplicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
  <span class="nt">metrics</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Resource</span>
    <span class="nt">resource</span><span class="p">:</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cpu</span>
      <span class="nt">targetAverageUtilization</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">55</span>
  <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Resource</span>
    <span class="nt">resource</span><span class="p">:</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">memory</span>
      <span class="nt">targetAverageValue</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50Mi</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id110">
<h1><a class="toc-backref" href="#id360">二十二 K8S包管理器</a><a class="headerlink" href="#id110" title="Permalink to this headline">¶</a></h1>
<p>Helm 是 Deis 开发的一个用于 Kubernetes 应用的包管理工具，主要用来管理
Charts。有点类似于 Ubuntu 中的 APT 或 CentOS 中的 YUM。</p>
<p>Helm Chart 是用来封装 Kubernetes 原生应用程序的一系列 YAML
文件。可以在你部署应用的时候自定义应用程序的一些
Metadata，以便于应用程序的分发。</p>
<p>对于应用发布者而言，可以通过 Helm
打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。</p>
<p>对于使用者而言，使用 Helm
后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes
上查找、安装、升级、回滚、卸载应用程序。</p>
<div class="section" id="id111">
<h2><a class="toc-backref" href="#id361">22.1 基础概念</a><a class="headerlink" href="#id111" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Helm</p></li>
</ul>
<p>Helm 是一个命令行下的客户端工具。主要用于 Kubernetes 应用程序 Chart
的创建、打包、发布以及创建和管理本地和远程的 Chart 仓库。</p>
<ul class="simple">
<li><p>Tiller</p></li>
</ul>
<p>Tiller 是 Helm 的服务端，部署在 Kubernetes 集群中。Tiller 用于接收 Helm
的请求，并根据 Chart 生成 Kubernetes 的部署文件（Helm 称为
Release），然后提交给 Kubernetes 创建应用。Tiller 还提供了 Release
的升级、删除、回滚等一系列功能。</p>
<ul class="simple">
<li><p>Chart</p></li>
</ul>
<p>Helm 的软件包，采用 TAR 格式。类似于 APT 的 DEB 包或者 YUM 的 RPM
包，其包含了一组定义 Kubernetes 资源相关的 YAML 文件。</p>
<ul class="simple">
<li><p>Repoistory</p></li>
</ul>
<p>Helm 的软件仓库，Repository 本质上是一个 Web
服务器，该服务器保存了一系列的 Chart
软件包以供用户下载，并且提供了一个该 Repository 的 Chart
包的清单文件以供查询，Helm 可以同时管理多个不同的 Repository。</p>
<ul class="simple">
<li><p>Release</p></li>
</ul>
<p>使用 helm install 命令在 Kubernetes 集群中部署的 Chart 称为
Release。Chart 与 Release 的关系类似于面向对象中的类与实例的关系。</p>
</div>
<div class="section" id="helm">
<h2><a class="toc-backref" href="#id362">22.2 Helm 工作原理</a><a class="headerlink" href="#helm" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Chart Install 过程</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. Helm 从指定的目录或者 TAR 文件中解析出 Chart 结构信息。
2. Helm 将指定的 Chart 结构和 Values 信息通过 gRPC 传递给 Tiller。
3. Tiller 根据 Chart 和 Values 生成一个 Release。
4. Tiller 将 Release 发送给 Kubernetes 用于生成 Release。
</pre></div>
</div>
<ul class="simple">
<li><p>Chart Update 过程</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. Helm 从指定的目录或者 TAR 文件中解析出 Chart 结构信息。
2. Helm 将需要更新的 Release 的名称、Chart 结构和 Values 信息传递给 Tiller。
3. Tiller 生成 Release 并更新指定名称的 Release 的 History。
4. Tiller 将 Release 发送给 Kubernetes 用于更新 Release。
</pre></div>
</div>
<ul class="simple">
<li><p>Chart Rollback 过程</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. Helm 将要回滚的 Release 的名称传递给 Tiller。
2. Tiller 根据 Release 的名称查找 History。
3. Tiller 从 History 中获取上一个 Release。
4. Tiller 将上一个 Release 发送给 Kubernetes 用于替换当前 Release。
</pre></div>
</div>
<ul class="simple">
<li><p>Chart 处理依赖说明</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Tiller 在处理 Chart 时，直接将 Chart 以及其依赖的所有 Charts 合并为一个 Release，同时传递给 Kubernetes。
因此 Tiller 并不负责管理依赖之间的启动顺序。Chart 中的应用需要能够自行处理依赖关系。
</pre></div>
</div>
</div>
<div class="section" id="id112">
<h2><a class="toc-backref" href="#id363">22.3 部署 Helm</a><a class="headerlink" href="#id112" title="Permalink to this headline">¶</a></h2>
<p>官方 github 地址：<a class="reference external" href="https://github.com/helm/helm">https://github.com/helm/helm</a></p>
<ul class="simple">
<li><p>下载二进制版本，解压并安装 helm</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ wget https://storage.googleapis.com/kubernetes-helm/helm-v2.13.1-linux-amd64.tar.gz
$ tar xf helm-v2.13.1-linux-amd64.tar.gz
$ mv helm /usr/local/bin/
</pre></div>
</div>
<ul class="simple">
<li><p>初始化 tiller 时候会自动读取 ~/.kube 目录，所以需要确保 config
文件存在并认证成功</p></li>
<li><p>tiller 配置 rbac，新建 rbac-config.yaml，并应用</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>https://github.com/helm/helm/blob/master/docs/rbac.md    <span class="c1"># 在这个页面中找到 rbac-config.yaml</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl apply -f tiller-rbac.yaml
</pre></div>
</div>
<ul class="simple">
<li><p>初始化 tiller 时候会自动读取 ~/.kube 目录，所以需要确保 config
文件存在并认证成功</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ helm init --service-account tiller
</pre></div>
</div>
<ul class="simple">
<li><p>添加 incubator 源</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ helm repo add incubator https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/
$ helm repo update
</pre></div>
</div>
<ul class="simple">
<li><p>安装完成，查看版本</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ helm version
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Client: <span class="p">&amp;</span>version.Version<span class="o">{</span>SemVer:<span class="s2">&quot;v2.13.1&quot;</span>, GitCommit:<span class="s2">&quot;618447cbf203d147601b4b9bd7f8c37a5d39fbb4&quot;</span>, GitTreeState:<span class="s2">&quot;clean&quot;</span><span class="o">}</span>
Server: <span class="p">&amp;</span>version.Version<span class="o">{</span>SemVer:<span class="s2">&quot;v2.9.1&quot;</span>, GitCommit:<span class="s2">&quot;20adb27c7c5868466912eebdf6664e7390ebe710&quot;</span>, GitTreeState:<span class="s2">&quot;clean&quot;</span><span class="o">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>helm 官方可用的 chart 仓库</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>http://hub.kubeapps.com/
</pre></div>
</div>
<ul class="simple">
<li><p>命令基本使用</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>completion  <span class="c1"># 为指定的shell生成自动完成脚本（bash或zsh）</span>
create      <span class="c1"># 创建一个具有给定名称的新 chart</span>
delete      <span class="c1"># 从 Kubernetes 删除指定名称的 release</span>
dependency  <span class="c1"># 管理 chart 的依赖关系</span>
fetch       <span class="c1"># 从存储库下载 chart 并（可选）将其解压缩到本地目录中</span>
get         <span class="c1"># 下载一个命名 release</span>
<span class="nb">help</span>        <span class="c1"># 列出所有帮助信息</span>
<span class="nb">history</span>     <span class="c1"># 获取 release 历史</span>
home        <span class="c1"># 显示 HELM_HOME 的位置</span>
init        <span class="c1"># 在客户端和服务器上初始化Helm</span>
inspect     <span class="c1"># 检查 chart 详细信息</span>
install     <span class="c1"># 安装 chart 存档</span>
lint        <span class="c1"># 对 chart 进行语法检查</span>
list        <span class="c1"># releases 列表</span>
package     <span class="c1"># 将 chart 目录打包成 chart 档案</span>
plugin      <span class="c1"># 添加列表或删除 helm 插件</span>
repo        <span class="c1"># 添加列表删除更新和索引 chart 存储库</span>
reset       <span class="c1"># 从集群中卸载 Tiller</span>
rollback    <span class="c1"># 将版本回滚到以前的版本</span>
search      <span class="c1"># 在 chart 存储库中搜索关键字</span>
serve       <span class="c1"># 启动本地http网络服务器</span>
status      <span class="c1"># 显示指定 release 的状态</span>
template    <span class="c1"># 本地渲染模板</span>
<span class="nb">test</span>        <span class="c1"># 测试一个 release</span>
upgrade     <span class="c1"># 升级一个 release</span>
verify      <span class="c1"># 验证给定路径上的 chart 是否已签名且有效</span>
version     <span class="c1"># 打印客户端/服务器版本信息</span>
dep         <span class="c1"># 分析 Chart 并下载依赖</span>
</pre></div>
</div>
<ul class="simple">
<li><p>指定 values.yaml 部署一个 chart</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install --name els1 -f values.yaml stable/elasticsearch
</pre></div>
</div>
<ul class="simple">
<li><p>升级一个 chart</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm upgrade --set <span class="nv">mysqlRootPassword</span><span class="o">=</span>passwd db-mysql stable/mysql
</pre></div>
</div>
<ul class="simple">
<li><p>回滚一个 chart</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm rollback db-mysql <span class="m">1</span>
</pre></div>
</div>
<ul class="simple">
<li><p>删除一个 release</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm delete --purge db-mysql
</pre></div>
</div>
<ul class="simple">
<li><p>只对模板进行渲染然后输出，不进行安装</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install/upgrade xxx --dry-run --debug
</pre></div>
</div>
</div>
<div class="section" id="chart">
<h2><a class="toc-backref" href="#id364">22.4 Chart文件组织</a><a class="headerlink" href="#chart" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>myapp/                               <span class="c1"># Chart 目录</span>
├── charts                           <span class="c1"># 这个 charts 依赖的其他 charts，始终被安装</span>
├── Chart.yaml                       <span class="c1"># 描述这个 Chart 的相关信息、包括名字、描述信息、版本等</span>
├── templates                        <span class="c1"># 模板目录</span>
│   ├── deployment.yaml              <span class="c1"># deployment 控制器的 Go 模板文件</span>
│   ├── _helpers.tpl                 <span class="c1"># 以 _ 开头的文件不会部署到 k8s 上，可用于定制通用信息</span>
│   ├── ingress.yaml                 <span class="c1"># ingress 的模板文件</span>
│   ├── NOTES.txt                    <span class="c1"># Chart 部署到集群后的一些信息，例如：如何使用、列出缺省值</span>
│   ├── service.yaml                 <span class="c1"># service 的 Go 模板文件</span>
│   └── tests
│       └── test-connection.yaml
└── values.yaml                      <span class="c1"># 模板的值文件，这些值会在安装时应用到 GO 模板生成部署文件</span>
</pre></div>
</div>
</div>
<div class="section" id="helm-ceph-efk">
<h2><a class="toc-backref" href="#id365">22.5 使用 Helm + Ceph 部署 EFK</a><a class="headerlink" href="#helm-ceph-efk" title="Permalink to this headline">¶</a></h2>
<p>本文使用 K8S 集群上运行 EFK，使用 Ceph 集群作为 ElasticSearch
集群的持久存储。</p>
<p>用到知识有：Storage Class、PVC、Helm，另外，很多服务镜像需要翻墙。</p>
<p>helm install 阻塞过程会下载镜像可能会比较慢。</p>
<p>helm
里面有很多可以定制的项目，这里我就不定制了，反正我的资源也够用，懒得调了。</p>
</div>
<div class="section" id="storage-class">
<h2><a class="toc-backref" href="#id366">22.6 Storage Class</a><a class="headerlink" href="#storage-class" title="Permalink to this headline">¶</a></h2>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Secret</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-admin-secret</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">type</span><span class="p">:</span> <span class="s">&quot;kubernetes.io/rbd&quot;</span>
<span class="nt">data</span><span class="p">:</span>
  <span class="c1"># ceph auth get-key client.admin | base64</span>
  <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">QVFER3U5TmMQNXQ4SlJBAAhHMGltdXZlNFZkUXAvN2tTZ1BENGc9PQ==</span>


<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Secret</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-secret</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">type</span><span class="p">:</span> <span class="s">&quot;kubernetes.io/rbd&quot;</span>
<span class="nt">data</span><span class="p">:</span>
  <span class="c1"># ceph auth get-key client.kube | base64</span>
  <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">QVFCcUM5VmNWVDdQCCCCWR1NUxFNfVKeTAiazdUWVhOa3N2UWc9PQ==</span>


<span class="nn">---</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">StorageClass</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">storage.k8s.io/v1</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-rbd</span>
<span class="nt">provisioner</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph.com/rbd</span>
<span class="nt">reclaimPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Retain</span>
<span class="nt">parameters</span><span class="p">:</span>
  <span class="nt">monitors</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.16.100.9:6789</span>
  <span class="nt">pool</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube</span>
  <span class="nt">adminId</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">admin</span>
  <span class="nt">adminSecretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-admin-secret</span>
  <span class="nt">adminSecretNamespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
  <span class="nt">userId</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube</span>
  <span class="nt">userSecretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph-secret</span>
  <span class="nt">userSecretNamespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
  <span class="nt">fsType</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ext4</span>
  <span class="nt">imageFormat</span><span class="p">:</span> <span class="s">&quot;2&quot;</span>
  <span class="nt">imageFeatures</span><span class="p">:</span> <span class="s">&quot;layering&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="helm-elasticsearch">
<h2><a class="toc-backref" href="#id367">22.7 Helm Elasticsearch</a><a class="headerlink" href="#helm-elasticsearch" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>下载 elasticsearch 的 StatfullSet 的 chart</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm fetch stable/elasticsearch
</pre></div>
</div>
<ul class="simple">
<li><p>编辑 values.yaml，修改 storageClass 指向上面创建的 storageClass</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">storageClass</span><span class="p">:</span> <span class="s">&quot;ceph-rbd&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用 helm 指定 values.yaml 部署 elasticsearch</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install --name els1 -f values.yaml stable/elasticsearch
</pre></div>
</div>
<ul class="simple">
<li><p>安装后查看，调试直到全部处于 READY 状态</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get pods
NAME                                         READY   STATUS    RESTARTS   AGE
els1-elasticsearch-client-55696f5bdd-qczbf   <span class="m">1</span>/1     Running   <span class="m">1</span>          78m
els1-elasticsearch-client-55696f5bdd-tdwdc   <span class="m">1</span>/1     Running   <span class="m">1</span>          78m
els1-elasticsearch-data-0                    <span class="m">1</span>/1     Running   <span class="m">1</span>          78m
els1-elasticsearch-data-1                    <span class="m">1</span>/1     Running   <span class="m">1</span>          56m
els1-elasticsearch-master-0                  <span class="m">1</span>/1     Running   <span class="m">1</span>          78m
els1-elasticsearch-master-1                  <span class="m">1</span>/1     Running   <span class="m">1</span>          53m
els1-elasticsearch-master-2                  <span class="m">1</span>/1     Running   <span class="m">1</span>          52m
rbd-provisioner-9b8ffbcc-nxdjd               <span class="m">1</span>/1     Running   <span class="m">2</span>          81m
</pre></div>
</div>
<ul class="simple">
<li><p>也可以使用 helm 命令查看</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ helm status els1

LAST DEPLOYED: Sun May <span class="m">12</span> <span class="m">16</span>:28:56 <span class="m">2019</span>
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
<span class="o">==</span>&gt; v1/ConfigMap
NAME                     DATA  AGE
els1-elasticsearch       <span class="m">4</span>     88m
els1-elasticsearch-test  <span class="m">1</span>     <span class="nv">88m</span>

<span class="o">==</span>&gt; v1/Pod<span class="o">(</span>related<span class="o">)</span>
NAME                                        READY  STATUS   RESTARTS  AGE
els1-elasticsearch-client-55696f5bdd-qczbf  <span class="m">1</span>/1    Running  <span class="m">1</span>         88m
els1-elasticsearch-client-55696f5bdd-tdwdc  <span class="m">1</span>/1    Running  <span class="m">1</span>         88m
els1-elasticsearch-data-0                   <span class="m">1</span>/1    Running  <span class="m">1</span>         88m
els1-elasticsearch-data-1                   <span class="m">1</span>/1    Running  <span class="m">1</span>         66m
els1-elasticsearch-master-0                 <span class="m">1</span>/1    Running  <span class="m">1</span>         88m
els1-elasticsearch-master-1                 <span class="m">1</span>/1    Running  <span class="m">1</span>         63m
els1-elasticsearch-master-2                 <span class="m">1</span>/1    Running  <span class="m">1</span>         <span class="nv">62m</span>

<span class="o">==</span>&gt; v1/Service
NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP  PORT<span class="o">(</span>S<span class="o">)</span>   AGE
els1-elasticsearch-client     ClusterIP  <span class="m">10</span>.98.197.185  &lt;none&gt;       <span class="m">9200</span>/TCP  88m
els1-elasticsearch-discovery  ClusterIP  None           &lt;none&gt;       <span class="m">9300</span>/TCP  <span class="nv">88m</span>

<span class="o">==</span>&gt; v1/ServiceAccount
NAME                       SECRETS  AGE
els1-elasticsearch-client  <span class="m">1</span>        88m
els1-elasticsearch-data    <span class="m">1</span>        88m
els1-elasticsearch-master  <span class="m">1</span>        <span class="nv">88m</span>

<span class="o">==</span>&gt; v1beta1/Deployment
NAME                       READY  UP-TO-DATE  AVAILABLE  AGE
els1-elasticsearch-client  <span class="m">2</span>/2    <span class="m">2</span>           <span class="m">2</span>          <span class="nv">88m</span>

<span class="o">==</span>&gt; v1beta1/StatefulSet
NAME                       READY  AGE
els1-elasticsearch-data    <span class="m">2</span>/2    88m
els1-elasticsearch-master  <span class="m">3</span>/3    88m


NOTES:
The elasticsearch cluster has been installed.

Elasticsearch can be accessed:

  * Within your cluster, at the following DNS name at port <span class="m">9200</span>:

    els1-elasticsearch-client.default.svc

  * From outside the cluster, run these commands in the same shell:

    <span class="nb">export</span> <span class="nv">POD_NAME</span><span class="o">=</span><span class="k">$(</span>kubectl get pods --namespace default -l <span class="s2">&quot;app=elasticsearch,component=client,release=els1&quot;</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">&quot;{.items[0].metadata.name}&quot;</span><span class="k">)</span>
    <span class="nb">echo</span> <span class="s2">&quot;Visit http://127.0.0.1:9200 to use Elasticsearch&quot;</span>
    kubectl port-forward --namespace default <span class="nv">$POD_NAME</span> <span class="m">9200</span>:9200
</pre></div>
</div>
<ul class="simple">
<li><p>启动一个临时的容器，解析集群地址，测试集群信息，查看集群节点</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl run cirros1 --rm -it --image<span class="o">=</span>cirros -- /bin/sh

/ <span class="c1"># nslookup els1-elasticsearch-client.default.svc</span>
Server:    <span class="m">10</span>.96.0.10
Address <span class="m">1</span>: <span class="m">10</span>.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      els1-elasticsearch-client.default.svc
Address <span class="m">1</span>: <span class="m">10</span>.98.197.185 els1-elasticsearch-client.default.svc.cluster.local
/ <span class="c1"># curl els1-elasticsearch-client.default.svc.cluster.local:9200/_cat/nodes</span>
<span class="m">10</span>.244.2.28  <span class="m">7</span> <span class="m">96</span> <span class="m">2</span> <span class="m">0</span>.85 <span class="m">0</span>.26 <span class="m">0</span>.16 di - els1-elasticsearch-data-0
<span class="m">10</span>.244.1.37  <span class="m">7</span> <span class="m">83</span> <span class="m">1</span> <span class="m">0</span>.04 <span class="m">0</span>.06 <span class="m">0</span>.11 di - els1-elasticsearch-data-1
<span class="m">10</span>.244.2.25 <span class="m">19</span> <span class="m">96</span> <span class="m">2</span> <span class="m">0</span>.85 <span class="m">0</span>.26 <span class="m">0</span>.16 i  - els1-elasticsearch-client-55696f5bdd-tdwdc
<span class="m">10</span>.244.2.27 <span class="m">28</span> <span class="m">96</span> <span class="m">2</span> <span class="m">0</span>.85 <span class="m">0</span>.26 <span class="m">0</span>.16 mi * els1-elasticsearch-master-2
<span class="m">10</span>.244.1.39 <span class="m">19</span> <span class="m">83</span> <span class="m">1</span> <span class="m">0</span>.04 <span class="m">0</span>.06 <span class="m">0</span>.11 i  - els1-elasticsearch-client-55696f5bdd-qczbf
<span class="m">10</span>.244.2.29 <span class="m">21</span> <span class="m">96</span> <span class="m">2</span> <span class="m">0</span>.85 <span class="m">0</span>.26 <span class="m">0</span>.16 mi - els1-elasticsearch-master-1
<span class="m">10</span>.244.1.38 <span class="m">23</span> <span class="m">83</span> <span class="m">1</span> <span class="m">0</span>.04 <span class="m">0</span>.06 <span class="m">0</span>.11 mi - els1-elasticsearch-master-0
</pre></div>
</div>
</div>
<div class="section" id="helm-fluentd-elasticsearch">
<h2><a class="toc-backref" href="#id368">22.8 Helm fluentd-elasticsearch</a><a class="headerlink" href="#helm-fluentd-elasticsearch" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>安装 kiwigrid 源</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm repo add kiwigrid https://kiwigrid.github.io
</pre></div>
</div>
<ul class="simple">
<li><p>下载 fluentd-elasticsearch</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm fetch kiwigrid/fluentd-elasticsearch
</pre></div>
</div>
<ul class="simple">
<li><p>获取集群地址</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>els1-elasticsearch-client.default.svc.cluster.local:9200
</pre></div>
</div>
<ul class="simple">
<li><p>编辑修改 values.yaml，指定 elasticsearch 集群的位置</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>elasticsearch:
  host: <span class="s1">&#39;els1-elasticsearch-client.default.svc.cluster.local&#39;</span>
  port: <span class="m">9200</span>
</pre></div>
</div>
<ul class="simple">
<li><p>修改对污点的容忍程度，使其容忍 Master 节点的污点，也运行在 Master
节点上收集信息</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">tolerations</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">node-role.kubernetes.io/master</span>
    <span class="nt">operator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Exists</span>
    <span class="nt">effect</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NoSchedule</span>
</pre></div>
</div>
<ul class="simple">
<li><p>如果使用 prometheus 监控应该打开 prometheusRole 规则</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">podAnnotations</span><span class="p">:</span>
  <span class="nt">prometheus.io/scrape</span><span class="p">:</span> <span class="s">&quot;true&quot;</span>
  <span class="nt">prometheus.io/port</span><span class="p">:</span> <span class="s">&quot;24231&quot;</span>

<span class="nt">service</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ClusterIP</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;monitor-agent&quot;</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">24231</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用 helm 指定 values.yaml 部署 fluentd-elasticsearch</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install --name flu1 -f values.yaml kiwigrid/fluentd-elasticsearch
</pre></div>
</div>
<ul class="simple">
<li><p>查看状态 flu1 这个 helm 服务的运行状态</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master fluentd-elasticsearch<span class="o">]</span><span class="c1"># helm status flu1</span>
LAST DEPLOYED: Sun May <span class="m">12</span> <span class="m">18</span>:13:12 <span class="m">2019</span>
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
<span class="o">==</span>&gt; v1/ClusterRole
NAME                        AGE
flu1-fluentd-elasticsearch  <span class="nv">17m</span>

<span class="o">==</span>&gt; v1/ClusterRoleBinding
NAME                        AGE
flu1-fluentd-elasticsearch  <span class="nv">17m</span>

<span class="o">==</span>&gt; v1/ConfigMap
NAME                        DATA  AGE
flu1-fluentd-elasticsearch  <span class="m">6</span>     <span class="nv">17m</span>

<span class="o">==</span>&gt; v1/DaemonSet
NAME                        DESIRED  CURRENT  READY  UP-TO-DATE  AVAILABLE  NODE SELECTOR  AGE
flu1-fluentd-elasticsearch  <span class="m">3</span>        <span class="m">3</span>        <span class="m">3</span>      <span class="m">3</span>           <span class="m">3</span>          &lt;none&gt;         <span class="nv">17m</span>

<span class="o">==</span>&gt; v1/Pod<span class="o">(</span>related<span class="o">)</span>
NAME                              READY  STATUS   RESTARTS  AGE
flu1-fluentd-elasticsearch-p49fc  <span class="m">1</span>/1    Running  <span class="m">1</span>         17m
flu1-fluentd-elasticsearch-q5b9k  <span class="m">1</span>/1    Running  <span class="m">0</span>         17m
flu1-fluentd-elasticsearch-swfvt  <span class="m">1</span>/1    Running  <span class="m">0</span>         <span class="nv">17m</span>

<span class="o">==</span>&gt; v1/Service
NAME                        TYPE       CLUSTER-IP      EXTERNAL-IP  PORT<span class="o">(</span>S<span class="o">)</span>    AGE
flu1-fluentd-elasticsearch  ClusterIP  <span class="m">10</span>.106.106.209  &lt;none&gt;       <span class="m">24231</span>/TCP  <span class="nv">17m</span>

<span class="o">==</span>&gt; v1/ServiceAccount
NAME                        SECRETS  AGE
flu1-fluentd-elasticsearch  <span class="m">1</span>        17m


NOTES:
<span class="m">1</span>. To verify that Fluentd has started, run:

  kubectl --namespace<span class="o">=</span>default get pods -l <span class="s2">&quot;app.kubernetes.io/name=fluentd-elasticsearch,app.kubernetes.io/instance=flu1&quot;</span>

THIS APPLICATION CAPTURES ALL CONSOLE OUTPUT AND FORWARDS IT TO elasticsearch . Anything that might be identifying,
including things like IP addresses, container images, and object names will NOT be anonymized.
<span class="m">2</span>. Get the application URL by running these commands:
  <span class="nb">export</span> <span class="nv">POD_NAME</span><span class="o">=</span><span class="k">$(</span>kubectl get pods --namespace default -l <span class="s2">&quot;app.kubernetes.io/name=fluentd-elasticsearch,app.kubernetes.io/instance=flu1&quot;</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">&quot;{.items[0].metadata.name}&quot;</span><span class="k">)</span>
  <span class="nb">echo</span> <span class="s2">&quot;Visit http://127.0.0.1:8080 to use your application&quot;</span>
  kubectl port-forward <span class="nv">$POD_NAME</span> <span class="m">8080</span>:80
</pre></div>
</div>
<ul class="simple">
<li><p>是否生成了索引，直接使用访问 elasticsearch 的 RESTfull API 接口。</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl run cirros1 --rm -it --image<span class="o">=</span>cirros -- /bin/sh
/ <span class="c1"># curl els1-elasticsearch-client.default.svc.cluster.local:9200/_cat/indices</span>
green open logstash-2019.05.10 a2b-GyKsSLOZPqGKbCpyJw <span class="m">5</span> <span class="m">1</span>   <span class="m">158</span> <span class="m">0</span> <span class="m">84</span>.2kb   460b
green open logstash-2019.05.09 CwYylNhdRf-A5UELhrzHow <span class="m">5</span> <span class="m">1</span> <span class="m">71418</span> <span class="m">0</span> <span class="m">34</span>.3mb <span class="m">17</span>.4mb
green open logstash-2019.05.12 5qRFpV46RGG_bWC4xbsyVA <span class="m">5</span> <span class="m">1</span> <span class="m">34496</span> <span class="m">0</span> <span class="m">26</span>.1mb <span class="m">13</span>.2mb
</pre></div>
</div>
</div>
<div class="section" id="helm-kibana">
<h2><a class="toc-backref" href="#id369">22.9 Helm kibana</a><a class="headerlink" href="#helm-kibana" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>下载 stable/kibana</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm fetch stable/kibana
</pre></div>
</div>
<ul class="simple">
<li><p>编辑 values.yaml，修改 elasticsearch 指向 elasticsearch 集群的地址</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>elasticsearch.hosts: http://els1-elasticsearch-client.default.svc.cluster.local:920
</pre></div>
</div>
<ul class="simple">
<li><p>修改 service 的工作模式，使得可以从集群外部访问</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">service</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NodePort</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用 helm 指定 values.yaml 部署 kibana</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install --name kib1 -f values.yaml stable/kibana
</pre></div>
</div>
<ul class="simple">
<li><p>获取 service 端口</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl get svc
NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>         AGE
els1-elasticsearch-client      ClusterIP   <span class="m">10</span>.98.197.185   &lt;none&gt;        <span class="m">9200</span>/TCP        4h51m
els1-elasticsearch-discovery   ClusterIP   None            &lt;none&gt;        <span class="m">9300</span>/TCP        4h51m
flu1-fluentd-elasticsearch     ClusterIP   <span class="m">10</span>.101.97.11    &lt;none&gt;        <span class="m">24231</span>/TCP       157m
kib1-kibana                    NodePort    <span class="m">10</span>.103.7.215    &lt;none&gt;        <span class="m">443</span>:31537/TCP   6m50s
kubernetes                     ClusterIP   <span class="m">10</span>.96.0.1       &lt;none&gt;        <span class="m">443</span>/TCP         3d4h
</pre></div>
</div>
<ul class="simple">
<li><p>由于 service 工作在 NodePort 模式下，所以可以在集群外部访问了</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">172</span>.16.100.6:31537
</pre></div>
</div>
</div>
</div>
<div class="section" id="id113">
<h1><a class="toc-backref" href="#id370">二十三 ETCD详解</a><a class="headerlink" href="#id113" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id114">
<h2><a class="toc-backref" href="#id371">23.1 ETCD概述</a><a class="headerlink" href="#id114" title="Permalink to this headline">¶</a></h2>
<p>Etcd 是
作为K8S必不可少的键值元存储系统，需要进行系统的学习来更好的了解K8S，</p>
<div class="section" id="id115">
<h3><a class="toc-backref" href="#id372">23.1.1 ETCD简介</a><a class="headerlink" href="#id115" title="Permalink to this headline">¶</a></h3>
<p>etcd是CoreOS团队于2013年6月发起的开源项目，它的目标是构建一个高可用的分布式键值(key-value)数据库。etcd内部采用<code class="docutils literal notranslate"><span class="pre">raft</span></code>协议作为一致性算法，etcd基于Go语言实现。</p>
</div>
<div class="section" id="id116">
<h3><a class="toc-backref" href="#id373">23.1.2 发展历史</a><a class="headerlink" href="#id116" title="Permalink to this headline">¶</a></h3>
<p><img alt="image1" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315174937.png" /></p>
</div>
<div class="section" id="id117">
<h3><a class="toc-backref" href="#id374">23.1.3 ETCD特点</a><a class="headerlink" href="#id117" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>简单：安装配置简单，而且提供了HTTP API进行交互，使用也很简单</p></li>
<li><p>安全：支持SSL证书验证</p></li>
<li><p>快速：根据官方提供的benchmark数据，单实例支持每秒2k+读操作</p></li>
<li><p>可靠：采用raft算法，实现分布式系统数据的可用性和一致性</p></li>
</ul>
</div>
<div class="section" id="id118">
<h3><a class="toc-backref" href="#id375">23.1.4 概念术语</a><a class="headerlink" href="#id118" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Raft：etcd所采用的保证分布式系统强一致性的算法。</p></li>
<li><p>Node：一个Raft状态机实例。</p></li>
<li><p>Member：
一个etcd实例。它管理着一个Node，并且可以为客户端请求提供服务。</p></li>
<li><p>Cluster：由多个Member构成可以协同工作的etcd集群。</p></li>
<li><p>Peer：对同一个etcd集群中另外一个Member的称呼。</p></li>
<li><p>Client： 向etcd集群发送HTTP请求的客户端。</p></li>
<li><p>WAL：预写式日志，etcd用于持久化存储的日志格式。</p></li>
<li><p>snapshot：etcd防止WAL文件过多而设置的快照，存储etcd数据状态。</p></li>
<li><p>Proxy：etcd的一种模式，为etcd集群提供反向代理服务。</p></li>
<li><p>Leader：Raft算法中通过竞选而产生的处理所有数据提交的节点。</p></li>
<li><p>Follower：竞选失败的节点作为Raft中的从属节点，为算法提供强一致性保证。</p></li>
<li><p>Candidate：当Follower超过一定时间接收不到Leader的心跳时转变为Candidate开始竞选。</p></li>
<li><p>Term：某个节点成为Leader到下一次竞选时间，称为一个Term。</p></li>
<li><p>Index：数据项编号。Raft中通过Term和Index来定位数据。</p></li>
</ul>
</div>
<div class="section" id="id119">
<h3><a class="toc-backref" href="#id376">23.1.5 相关原理</a><a class="headerlink" href="#id119" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id120">
<h4>23.1.5.1 数据读写顺序<a class="headerlink" href="#id120" title="Permalink to this headline">¶</a></h4>
<p>为了保证数据的强一致性，etcd集群中所有的数据流向都是一个方向，从 Leader
（主节点）流向 Follower，也就是所有 Follower 的数据必须与 Leader
保持一致，如果不一致会被覆盖。</p>
<p>用户对于etcd集群所有节点进行读写</p>
<ul class="simple">
<li><p>读取：由于集群所有节点数据是强一致性的，读取可以从集群中随便哪个节点进行读取数据</p></li>
<li><p>写入：etcd集群有leader，如果写入往leader写入，可以直接写入，然后然后Leader节点会把写入分发给所有Follower，如果往follower写入，然后Leader节点会把写入分发给所有Follower</p></li>
</ul>
</div>
<div class="section" id="leader">
<h4>23.1.5.2 leader选举<a class="headerlink" href="#leader" title="Permalink to this headline">¶</a></h4>
<p>假设三个节点的集群，三个节点上均运行Timer（每个Timer持续时间是随机的），Raft算法使用随机Timer来初始化Leader选举流程，第一个节点率先完成了Timer，随后它就会向其他两个节点发送成为Leader的请求，其他节点接收到请求后会以投票回应然后第一个节点被选举为Leader。</p>
<p>成为Leader后，该节点会以固定时间间隔向其他节点发送通知，确保自己仍是Leader。有些情况下当Follower们收不到Leader的通知后，比如说Leader节点宕机或者失去了连接，其他节点会重复之前选举过程选举出新的Leader。</p>
</div>
<div class="section" id="id121">
<h4>23.1.5.3 判断数据是否写入<a class="headerlink" href="#id121" title="Permalink to this headline">¶</a></h4>
<p>etcd认为写入请求被Leader节点处理并分发给了多数节点后，就是一个成功的写入。那么多少节点如何判定呢，假设总结点数是N，那么多数节点
<code class="docutils literal notranslate"><span class="pre">Quorum=N/2+1</span></code>。关于如何确定etcd集群应该有多少个节点的问题，上图的左侧的图表给出了集群中节点总数(Instances)对应的Quorum数量，用Instances减去Quorom就是集群中容错节点（允许出故障的节点）的数量。</p>
<p>所以在集群中推荐的最少节点数量是3个，因为1和2个节点的容错节点数都是0，一旦有一个节点宕掉整个集群就不能正常工作了。</p>
</div>
</div>
</div>
<div class="section" id="id122">
<h2><a class="toc-backref" href="#id377">23.2 ETCD架构及解析</a><a class="headerlink" href="#id122" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id123">
<h3><a class="toc-backref" href="#id378">23.2.1 架构图</a><a class="headerlink" href="#id123" title="Permalink to this headline">¶</a></h3>
<p><img alt="image2" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175005.png" /></p>
</div>
<div class="section" id="id124">
<h3><a class="toc-backref" href="#id379">23.2.2 架构解析</a><a class="headerlink" href="#id124" title="Permalink to this headline">¶</a></h3>
<p>从 etcd 的架构图中我们可以看到，etcd 主要分为四个部分。</p>
<ul class="simple">
<li><p>HTTP Server：用于处理用户发送的 API 请求以及其它 etcd
节点的同步与心跳信息请求。</p></li>
<li><p>Store：用于处理 etcd
支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等等，是
etcd 对用户提供的大多数 API 功能的具体实现。</p></li>
<li><p>Raft：Raft 强一致性算法的具体实现，是 etcd 的核心。</p></li>
<li><p>WAL：Write Ahead Log（预写式日志），是 etcd
的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd
就通过 WAL 进行持久化存储。WAL 中，所有的数据提交前都会事先记录日志。</p>
<ul>
<li><p>Snapshot 是为了防止数据过多而进行的状态快照；</p></li>
<li><p>Entry 表示存储的具体日志内容。</p></li>
</ul>
</li>
</ul>
<p>通常，一个用户的请求发送过来，会经由 HTTP Server 转发给 Store
进行具体的事务处理，如果涉及到节点的修改，则交给 Raft
模块进行状态的变更、日志的记录，然后再同步给别的 etcd
节点以确认数据提交，最后进行数据的提交，再次同步。</p>
</div>
</div>
<div class="section" id="id125">
<h2><a class="toc-backref" href="#id380">23.3 应用场景</a><a class="headerlink" href="#id125" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id126">
<h3><a class="toc-backref" href="#id381">23.3.1 服务注册发现</a><a class="headerlink" href="#id126" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>前后端业务注册发现</p></li>
</ul>
<p><img alt="image3" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175135.png" /></p>
<p>中间价已经后端服务在etcd中注册，前端和中间价可以很轻松的从etcd中发现相关服务器然后服务器之间根据调用关系相关绑定调用</p>
<ul class="simple">
<li><p>多组后端服务器注册发现</p></li>
</ul>
<div class="figure align-default" id="id163">
<img alt="image-20200315175200809" src="Users/xuel/Library/Application%20Support/typora-user-images/image-20200315175200809.png" />
<p class="caption"><span class="caption-text">image-20200315175200809</span><a class="headerlink" href="#id163" title="Permalink to this image">¶</a></p>
</div>
<p>后端多个无状态相同副本的app可以同事注册到etcd中，前端可以通过haproxy从etcd中获取到后端的ip和端口组，然后进行请求转发，可以用来故障转移屏蔽后端端口已经后端多组app实例。</p>
</div>
<div class="section" id="id127">
<h3><a class="toc-backref" href="#id382">23.3.2 消息发布与订阅</a><a class="headerlink" href="#id127" title="Permalink to this headline">¶</a></h3>
<p><img alt="image4" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175211.png" /></p>
<p>etcd可以充当消息中间件，生产者可以往etcd中注册topic并发送消息，消费者从etcd中订阅topic，来获取生产者发送至etcd中的消息。</p>
</div>
<div class="section" id="id128">
<h3><a class="toc-backref" href="#id383">23.3.3 负载均衡</a><a class="headerlink" href="#id128" title="Permalink to this headline">¶</a></h3>
<p><img alt="image5" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175304.png" /></p>
<p>后端多组相同的服务提供者可以经自己服务注册到etcd中，etcd并且会与注册的服务进行监控检查，服务请求这首先从etcd中获取到可用的服务提供者真正的ip:port，然后对此多组服务发送请求，etcd在其中充当了负载均衡的功能</p>
</div>
<div class="section" id="id129">
<h3><a class="toc-backref" href="#id384">23.3.4 分布式通知与协调</a><a class="headerlink" href="#id129" title="Permalink to this headline">¶</a></h3>
<p><img alt="image6" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175330.png" /></p>
<ul class="simple">
<li><p>当etcd watch服务发现丢失，会通知服务检查</p></li>
<li><p>控制器向etcd发送启动服务，etcd通知服务进行相应操作</p></li>
<li><p>当服务完成work会讲状态更新至etcd，etcd对应会通知用户</p></li>
</ul>
</div>
<div class="section" id="id130">
<h3><a class="toc-backref" href="#id385">23.3.5 分布式锁</a><a class="headerlink" href="#id130" title="Permalink to this headline">¶</a></h3>
<p><img alt="image7" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175402.png" /></p>
<p>当有多个竞争者node节点，etcd作为总控，在分布式集群中与一个节点成功分配lock</p>
</div>
<div class="section" id="id131">
<h3><a class="toc-backref" href="#id386">23.3.6 分布式队列</a><a class="headerlink" href="#id131" title="Permalink to this headline">¶</a></h3>
<p><img alt="image8" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175420.png" /></p>
<p>有对个node，etcd根据每个node来创建对应node的队列，根据不同的队列可以在etcd中找到对应的competitor</p>
</div>
<div class="section" id="id132">
<h3><a class="toc-backref" href="#id387">23.3.7 集群及爱你与Leader选举</a><a class="headerlink" href="#id132" title="Permalink to this headline">¶</a></h3>
<div class="figure align-default" id="id164">
<img alt="image-20200315175441952" src="Users/xuel/Library/Application%20Support/typora-user-images/image-20200315175441952.png" />
<p class="caption"><span class="caption-text">image-20200315175441952</span><a class="headerlink" href="#id164" title="Permalink to this image">¶</a></p>
</div>
<p>etcd可以根据raft算法在多个node节点来选举出leader</p>
</div>
</div>
<div class="section" id="id133">
<h2><a class="toc-backref" href="#id388">23.4 安装部署</a><a class="headerlink" href="#id133" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id134">
<h3><a class="toc-backref" href="#id389">23.4.1 单机安装</a><a class="headerlink" href="#id134" title="Permalink to this headline">¶</a></h3>
<p>可以使用二进制或源码下载安装，但是危害需要自己写配置文件，如何要启动需要自己写服务启动文件，推荐使用yum安装方式</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hostnamectl set-hostname etcd-1
wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
rpm -ivh epel-release-latest-7.noarch.rpm
<span class="c1"># yum 仓库中的etcd版本为3.3.11，如果需要最新版本的etcd可以进行二进制安装</span>
yum -y install etcd
systemctl <span class="nb">enable</span> etcd
</pre></div>
</div>
<p>可以查看yum安装的etcd的有效配置文件，根据自己的需求来修改数据存储目录，已经监听端口url/etcd的名称等</p>
<ul class="simple">
<li><p>etcd 默认将数据存放到当前路径的 <code class="docutils literal notranslate"><span class="pre">default.etcd/</span></code> 目录下</p></li>
<li><p>在 <code class="docutils literal notranslate"><span class="pre">http://localhost:2380</span></code> 和集群中其他节点通信</p></li>
<li><p>在 <code class="docutils literal notranslate"><span class="pre">http://localhost:2379</span></code> 提供 HTTP API 服务，供客户端交互</p></li>
<li><p>该节点的名称默认为 <code class="docutils literal notranslate"><span class="pre">default</span></code></p>
<ul>
<li><p>heartbeat 为 100ms，后面会说明这个配置的作用</p></li>
</ul>
</li>
<li><p>election 为 1000ms，后面会说明这个配置的作用</p></li>
<li><p>snapshot count 为 10000，后面会说明这个配置的作用</p></li>
<li><p>集群和每个节点都会生成一个 uuid</p></li>
<li><p>启动的时候，会运行 raft，选举出 leader</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@VM_0_8_centos tmp<span class="o">]</span><span class="c1"># grep -Ev &quot;^#|^$&quot; /etc/etcd/etcd.conf</span>
<span class="nv">ETCD_DATA_DIR</span><span class="o">=</span><span class="s2">&quot;/var/lib/etcd/default.etcd&quot;</span>
<span class="nv">ETCD_LISTEN_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://localhost:2379&quot;</span>
<span class="nv">ETCD_NAME</span><span class="o">=</span><span class="s2">&quot;default&quot;</span>
<span class="nv">ETCD_ADVERTISE_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://localhost:2379&quot;</span>
<span class="o">[</span>root@VM_0_8_centos tmp<span class="o">]</span><span class="c1"># systemctl status etcd</span>
</pre></div>
</div>
</div>
<div class="section" id="id135">
<h3><a class="toc-backref" href="#id390">23.4.2 集群部署</a><a class="headerlink" href="#id135" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id136">
<h4>23.4.2.1 主机信息<a class="headerlink" href="#id136" title="Permalink to this headline">¶</a></h4>
<p><img alt="image9" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175452.png" /></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 24%" />
<col style="width: 26%" />
<col style="width: 29%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>主机名称</p></th>
<th class="head"><p>系统</p></th>
<th class="head"><p>IP地址</p></th>
<th class="head"><p>部署组件</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>etcd-0-8</p></td>
<td><p>CentOS 7.3</p></td>
<td><p>172.16.0.8</p></td>
<td><p>etcd</p></td>
</tr>
<tr class="row-odd"><td><p>etcd-0-17</p></td>
<td><p>CentOS 7.3</p></td>
<td><p>172.16.0.17</p></td>
<td><p>etcd</p></td>
</tr>
<tr class="row-even"><td><p>etcd-0-14</p></td>
<td><p>CentOS 7.3</p></td>
<td><p>172.16.0.14</p></td>
<td><p>etcd</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="hosts">
<h4>23.4.2.2 HOSTS配置<a class="headerlink" href="#hosts" title="Permalink to this headline">¶</a></h4>
<p>在此示例用三个节点来部署etcd集群，各节点修改hosts</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>cat &gt;&gt; /etc/hosts <span class="s">&lt;&lt; EOF</span>
<span class="s">172.16.0.8 etcd-0-8</span>
<span class="s">172.16.0.14 etcd-0-14</span>
<span class="s">172.16.0.17 etcd-0-17</span>
<span class="s">EOF</span>
</pre></div>
</div>
</div>
<div class="section" id="id137">
<h4>23.4.2.3 ETCD安装<a class="headerlink" href="#id137" title="Permalink to this headline">¶</a></h4>
<p>三个节点均安装etcd</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
rpm -ivh epel-release-latest-7.noarch.rpm
yum -y install etcd
systemctl <span class="nb">enable</span> etcd
mkdir -p /data/app/etcd/
chown etcd:etcd /data/app/etcd/
</pre></div>
</div>
</div>
<div class="section" id="id138">
<h4>23.4.2.4 ETCD配置<a class="headerlink" href="#id138" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>etcd默认配置文件</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@etcd-0-8 app<span class="o">]</span><span class="c1"># cat /etc/etcd/etcd.conf</span>
<span class="c1">#[Member]</span>
<span class="c1">#ETCD_CORS=&quot;&quot;</span>
<span class="nv">ETCD_DATA_DIR</span><span class="o">=</span><span class="s2">&quot;/data/app/etcd/&quot;</span>                                                                                     <span class="c1"># etcd数据存储目录，建议存储在数据盘</span>
<span class="c1">#ETCD_WAL_DIR=&quot;&quot;</span>
<span class="nv">ETCD_LISTEN_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.8:2380&quot;</span>                                                      <span class="c1"># 与同伴的通讯地址，和其他节点同伴的通讯地址</span>
<span class="nv">ETCD_LISTEN_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.8:2379&quot;</span>      <span class="c1"># 对外提供服务的地址</span>
<span class="c1">#ETCD_MAX_SNAPSHOTS=&quot;5&quot;                                                                                                     # etcd最大快照保存数</span>
<span class="c1">#ETCD_MAX_WALS=&quot;5&quot;                                                                                                              # etcd 最大wals</span>
<span class="nv">ETCD_NAME</span><span class="o">=</span><span class="s2">&quot;etcd-0-8&quot;</span>                                                                                                            <span class="c1"># etcd节点名称，集群内需要唯一</span>
<span class="c1">#ETCD_SNAPSHOT_COUNT=&quot;100000&quot;                                                         # 指定有多少事务（transaction）被提交时，触发截取快照保存到磁盘</span>
<span class="c1">#ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;                                                          # leader 多久发送一次心跳到 followers。默认值是 100ms</span>
<span class="c1">#ETCD_ELECTION_TIMEOUT=&quot;1000&quot;                                     # 重新投票的超时时间，如果 follow 在该时间间隔没有收到心跳包，会触发重新投票，默认为 1000 ms</span>
<span class="c1">#ETCD_QUOTA_BACKEND_BYTES=&quot;0&quot;</span>
<span class="c1">#ETCD_MAX_REQUEST_BYTES=&quot;1572864&quot;</span>
<span class="c1">#ETCD_GRPC_KEEPALIVE_MIN_TIME=&quot;5s&quot;</span>
<span class="c1">#ETCD_GRPC_KEEPALIVE_INTERVAL=&quot;2h0m0s&quot;</span>
<span class="c1">#ETCD_GRPC_KEEPALIVE_TIMEOUT=&quot;20s&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Clustering]</span>
<span class="nv">ETCD_INITIAL_ADVERTISE_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.8:2380&quot;</span>                                      <span class="c1"># 该节点同伴监听地址，这个值会告诉集群中其他节点</span>
<span class="nv">ETCD_ADVERTISE_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.8:2379&quot;</span>    <span class="c1"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span>
<span class="c1">#ETCD_DISCOVERY=&quot;&quot;</span>
<span class="c1">#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;</span>
<span class="c1">#ETCD_DISCOVERY_PROXY=&quot;&quot;</span>
<span class="c1">#ETCD_DISCOVERY_SRV=&quot;&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER</span><span class="o">=</span><span class="s2">&quot;etcd-0-8=http://172.16.0.8:2380,etcd-0-17=http://172.16.0.17:2380,etcd-0-14=http://172.16.0.14:2380&quot;</span>                                                  <span class="c1"># 集群中所有节点的信</span>
<span class="nv">ETCD_INITIAL_CLUSTER_TOKEN</span><span class="o">=</span><span class="s2">&quot;etcd-token&quot;</span>                          <span class="c1"># 创建集群的 token，这个值每个集群保持唯一。这样的话，如果你要重新创建集群，即使配置和之前一样，也会再次生成新的集群和节点 uuid；否则会导致多个集群之间的冲突，造成未知的错误</span>
<span class="nv">ETCD_INITIAL_CLUSTER_STATE</span><span class="o">=</span><span class="s2">&quot;new&quot;</span>
<span class="c1">#ETCD_STRICT_RECONFIG_CHECK=&quot;true&quot;                                   # 新建集群的时候，这个值为 new；假如已经存在的集群，这个值为 existing</span>
<span class="c1">#ETCD_ENABLE_V2=&quot;true&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Proxy]</span>
<span class="c1">#ETCD_PROXY=&quot;off&quot;</span>
<span class="c1">#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;</span>
<span class="c1">#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;</span>
<span class="c1">#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;</span>
<span class="c1">#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;</span>
<span class="c1">#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Security]</span>
<span class="c1">#ETCD_CERT_FILE=&quot;&quot;</span>
<span class="c1">#ETCD_KEY_FILE=&quot;&quot;</span>
<span class="c1">#ETCD_CLIENT_CERT_AUTH=&quot;false&quot;</span>
<span class="c1">#ETCD_TRUSTED_CA_FILE=&quot;&quot;</span>
<span class="c1">#ETCD_AUTO_TLS=&quot;false&quot;</span>
<span class="c1">#ETCD_PEER_CERT_FILE=&quot;&quot;</span>
<span class="c1">#ETCD_PEER_KEY_FILE=&quot;&quot;</span>
<span class="c1">#ETCD_PEER_CLIENT_CERT_AUTH=&quot;false&quot;</span>
<span class="c1">#ETCD_PEER_TRUSTED_CA_FILE=&quot;&quot;</span>
<span class="c1">#ETCD_PEER_AUTO_TLS=&quot;false&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Logging]</span>
<span class="c1">#ETCD_DEBUG=&quot;false&quot;</span>
<span class="c1">#ETCD_LOG_PACKAGE_LEVELS=&quot;&quot;</span>
<span class="c1">#ETCD_LOG_OUTPUT=&quot;default&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Unsafe]</span>
<span class="c1">#ETCD_FORCE_NEW_CLUSTER=&quot;false&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Version]</span>
<span class="c1">#ETCD_VERSION=&quot;false&quot;</span>
<span class="c1">#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Profiling]</span>
<span class="c1">#ETCD_ENABLE_PPROF=&quot;false&quot;</span>
<span class="c1">#ETCD_METRICS=&quot;basic&quot;</span>
<span class="c1">#</span>
<span class="c1">#[Auth]</span>
<span class="c1">#ETCD_AUTH_TOKEN=&quot;simple&quot;</span>
</pre></div>
</div>
<p>etcd-0-8配置：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@etcd-server ~<span class="o">]</span><span class="c1"># hostnamectl set-hostname etcd-0-8</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># egrep &quot;^#|^$&quot; /etc/etcd/etcd.conf -v</span>
<span class="nv">ETCD_DATA_DIR</span><span class="o">=</span><span class="s2">&quot;/data/app/etcd/&quot;</span>
<span class="nv">ETCD_LISTEN_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.8:2380&quot;</span>
<span class="nv">ETCD_LISTEN_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.8:2379&quot;</span>
<span class="nv">ETCD_NAME</span><span class="o">=</span><span class="s2">&quot;etcd-0-8&quot;</span>
<span class="nv">ETCD_INITIAL_ADVERTISE_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.8:2380&quot;</span>
<span class="nv">ETCD_ADVERTISE_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.8:2379&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER</span><span class="o">=</span><span class="s2">&quot;etcd-0-8=http://172.16.0.8:2380,etcd-0-17=http://172.16.0.17:2380,etcd-0-14=http://172.16.0.14:2380&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER_TOKEN</span><span class="o">=</span><span class="s2">&quot;etcd-token&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER_STATE</span><span class="o">=</span><span class="s2">&quot;new&quot;</span>
</pre></div>
</div>
<p>etcd-0-14配置：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@etcd-server ~<span class="o">]</span><span class="c1"># hostnamectl set-hostname etcd-0-14</span>
<span class="o">[</span>root@etcd-server ~<span class="o">]</span><span class="c1"># mkdir -p /data/app/etcd/</span>
<span class="o">[</span>root@etcd-0.14 ~<span class="o">]</span><span class="c1"># egrep &quot;^#|^$&quot; /etc/etcd/etcd.conf -v</span>
<span class="nv">ETCD_DATA_DIR</span><span class="o">=</span><span class="s2">&quot;/data/app/etcd/&quot;</span>
<span class="nv">ETCD_LISTEN_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.14:2380&quot;</span>
<span class="nv">ETCD_LISTEN_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.14:2379&quot;</span>
<span class="nv">ETCD_NAME</span><span class="o">=</span><span class="s2">&quot;etcd-0-14&quot;</span>
<span class="nv">ETCD_INITIAL_ADVERTISE_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.14:2380&quot;</span>
<span class="nv">ETCD_ADVERTISE_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.14:2379&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER</span><span class="o">=</span><span class="s2">&quot;etcd-0-8=http://172.16.0.8:2380,etcd-0-17=http://172.16.0.17:2380,etcd-0-14=http://172.16.0.14:2380&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER_TOKEN</span><span class="o">=</span><span class="s2">&quot;etcd-token&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER_STATE</span><span class="o">=</span><span class="s2">&quot;new&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>etcd-0-7配置:</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@etcd-server ~<span class="o">]</span><span class="c1"># hostnamectl set-hostname etcd-0-17</span>
<span class="o">[</span>root@etcd-server ~<span class="o">]</span><span class="c1"># mkdir -p /data/app/etcd/</span>
<span class="o">[</span>root@etcd-0-17 ~<span class="o">]</span><span class="c1"># egrep &quot;^#|^$&quot; /etc/etcd/etcd.conf -v</span>
<span class="nv">ETCD_DATA_DIR</span><span class="o">=</span><span class="s2">&quot;/data/app/etcd/&quot;</span>
<span class="nv">ETCD_LISTEN_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.17:2380&quot;</span>
<span class="nv">ETCD_LISTEN_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.17:2379&quot;</span>
<span class="nv">ETCD_NAME</span><span class="o">=</span><span class="s2">&quot;etcd-0-17&quot;</span>
<span class="nv">ETCD_INITIAL_ADVERTISE_PEER_URLS</span><span class="o">=</span><span class="s2">&quot;http://172.16.0.17:2380&quot;</span>
<span class="nv">ETCD_ADVERTISE_CLIENT_URLS</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:2379,http://172.16.0.17:2379&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER</span><span class="o">=</span><span class="s2">&quot;etcd-0-8=http://172.16.0.8:2380,etcd-0-17=http://172.16.0.17:2380,etcd-0-14=http://172.16.0.14:2380&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER_TOKEN</span><span class="o">=</span><span class="s2">&quot;etcd-token&quot;</span>
<span class="nv">ETCD_INITIAL_CLUSTER_STATE</span><span class="o">=</span><span class="s2">&quot;new&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>配置完成后启动服务</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>systemctl start etcd
</pre></div>
</div>
</div>
<div class="section" id="id139">
<h4>23.4.2.5 查看集群状态<a class="headerlink" href="#id139" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>查看etcd状态</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@etcd-0-8 default.etcd<span class="o">]</span><span class="c1"># systemctl status etcd</span>
● etcd.service - Etcd Server
   Loaded: loaded <span class="o">(</span>/usr/lib/systemd/system/etcd.service<span class="p">;</span> enabled<span class="p">;</span> vendor preset: disabled<span class="o">)</span>
   Active: active <span class="o">(</span>running<span class="o">)</span> since 二 <span class="m">2019</span>-12-03 <span class="m">15</span>:55:28 CST<span class="p">;</span> 8s ago
 Main PID: <span class="m">24510</span> <span class="o">(</span>etcd<span class="o">)</span>
   CGroup: /system.slice/etcd.service
           └─24510 /usr/bin/etcd --name<span class="o">=</span>etcd-0-8 --data-dir<span class="o">=</span>/data/app/etcd/ --listen-client-urls<span class="o">=</span>http://172.16.0.8:2379

12月 <span class="m">03</span> <span class="m">15</span>:55:28 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: <span class="nb">set</span> the initial cluster version to <span class="m">3</span>.0
12月 <span class="m">03</span> <span class="m">15</span>:55:28 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: enabled capabilities <span class="k">for</span> version <span class="m">3</span>.0
12月 <span class="m">03</span> <span class="m">15</span>:55:30 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: peer 56e0b6dad4c53d42 became active
12月 <span class="m">03</span> <span class="m">15</span>:55:30 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: established a TCP streaming connection with peer 56e0b6dad4c53d42 <span class="o">(</span>stream Message reader<span class="o">)</span>
12月 <span class="m">03</span> <span class="m">15</span>:55:30 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: established a TCP streaming connection with peer 56e0b6dad4c53d42 <span class="o">(</span>stream Message writer<span class="o">)</span>
12月 <span class="m">03</span> <span class="m">15</span>:55:30 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: established a TCP streaming connection with peer 56e0b6dad4c53d42 <span class="o">(</span>stream MsgApp v2 reader<span class="o">)</span>
12月 <span class="m">03</span> <span class="m">15</span>:55:30 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: established a TCP streaming connection with peer 56e0b6dad4c53d42 <span class="o">(</span>stream MsgApp v2 writer<span class="o">)</span>
12月 <span class="m">03</span> <span class="m">15</span>:55:32 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: updating the cluster version from <span class="m">3</span>.0 to <span class="m">3</span>.3
12月 <span class="m">03</span> <span class="m">15</span>:55:32 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: updated the cluster version from <span class="m">3</span>.0 to <span class="m">3</span>.3
12月 <span class="m">03</span> <span class="m">15</span>:55:32 etcd-0-8 etcd<span class="o">[</span><span class="m">24510</span><span class="o">]</span>: enabled capabilities <span class="k">for</span> version <span class="m">3</span>.3
</pre></div>
</div>
<ul class="simple">
<li><p>查看端口监听(如果未在本地监听环回地址，那么在本地使用etcdctl不能正常连入进去)</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@etcd-0-8 default.etcd<span class="o">]</span><span class="c1"># netstat -lntup |grep etcd</span>
tcp        <span class="m">0</span>      <span class="m">0</span> <span class="m">172</span>.16.0.8:2379         <span class="m">0</span>.0.0.0:*               LISTEN      <span class="m">25167</span>/etcd
tcp        <span class="m">0</span>      <span class="m">0</span> <span class="m">127</span>.0.0.1:2379          <span class="m">0</span>.0.0.0:*               LISTEN      <span class="m">25167</span>/etcd
tcp        <span class="m">0</span>      <span class="m">0</span> <span class="m">172</span>.16.0.8:2380         <span class="m">0</span>.0.0.0:*               LISTEN      <span class="m">25167</span>/etcd
</pre></div>
</div>
<ul class="simple">
<li><p>查看集群状态(可以看到etcd-0-17)</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@etcd-0-8 default.etcd<span class="o">]</span><span class="c1"># etcdctl member list</span>
2d2e457c6a1a76cb: <span class="nv">name</span><span class="o">=</span>etcd-0-8 <span class="nv">peerURLs</span><span class="o">=</span>http://172.16.0.8:2380 <span class="nv">clientURLs</span><span class="o">=</span>http://127.0.0.1:2379,http://172.16.0.8:2379 <span class="nv">isLeader</span><span class="o">=</span><span class="nb">false</span>
56e0b6dad4c53d42: <span class="nv">name</span><span class="o">=</span>etcd-0-14 <span class="nv">peerURLs</span><span class="o">=</span>http://172.16.0.14:2380 <span class="nv">clientURLs</span><span class="o">=</span>http://127.0.0.1:2379,http://172.16.0.14:2379 <span class="nv">isLeader</span><span class="o">=</span><span class="nb">true</span>
d2d2e9fc758e6790: <span class="nv">name</span><span class="o">=</span>etcd-0-17 <span class="nv">peerURLs</span><span class="o">=</span>http://172.16.0.17:2380 <span class="nv">clientURLs</span><span class="o">=</span>http://127.0.0.1:2379,http://172.16.0.17:2379 <span class="nv">isLeader</span><span class="o">=</span><span class="nb">false</span>

<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl cluster-health</span>
member 2d2e457c6a1a76cb is healthy: got healthy result from http://127.0.0.1:2379
member 56e0b6dad4c53d42 is healthy: got healthy result from http://127.0.0.1:2379
member d2d2e9fc758e6790 is healthy: got healthy result from http://127.0.0.1:2379
cluster is healthy
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id140">
<h2><a class="toc-backref" href="#id391">23.5 简单使用</a><a class="headerlink" href="#id140" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id141">
<h3><a class="toc-backref" href="#id392">23.5.1 增加</a><a class="headerlink" href="#id141" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>set</p></li>
</ul>
<p>指定某个键的值。例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl set /testdir/testkey &quot;Hello world&quot;
Hello world
</pre></div>
</div>
<p>支持的选项包括：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--ttl &#39;0&#39; 该键值的超时时间(单位为秒)，不配置(默认为0)则永不超时
--swap-with-value value 若该键现在的值是value，则进行设置操作
--swap-with-index &#39;0&#39;   若该键现在的索引值是指定索引，则进行设置操作
</pre></div>
</div>
<ul class="simple">
<li><p>mk</p></li>
</ul>
<p>如果给定的键不存在，则创建一个新的键值。例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl mk /testdir/testkey &quot;Hello world&quot;
Hello world
</pre></div>
</div>
<p>当键存在的时候，执行该命令会报错，例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl mk /testdir/testkey &quot;Hello world&quot;
Error:  105: Key already exists (/testdir/testkey) [8]
</pre></div>
</div>
<p>支持的选项为:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--ttl &#39;0&#39;  超时时间(单位为秒），不配置(默认为 0)。则永不超时
</pre></div>
</div>
<ul class="simple">
<li><p>mkdir</p></li>
</ul>
<p>如果给定的键目录不存在，则创建一个新的键目录。例如：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl mkdir testdir2
</pre></div>
</div>
<p>当键目录存在的时候，执行该命令会报错，例如：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl mkdir testdir2
Error:  105: Key already exists (/testdir2) [9]
</pre></div>
</div>
<p>支持的选项为：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--ttl &#39;0&#39; 超时时间(单位为秒)，不配置(默认为0)则永不超时。
</pre></div>
</div>
<ul class="simple">
<li><p>setdir</p></li>
</ul>
<p>创建一个键目录。如果目录不存在就创建，如果目录存在更新目录TTL。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl setdir testdir3
</pre></div>
</div>
<p>支持的选项为:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--ttl &#39;0&#39; 超时时间(单位为秒)，不配置(默认为0)则永不超时。
</pre></div>
</div>
</div>
<div class="section" id="id142">
<h3><a class="toc-backref" href="#id393">23.5.2 删除</a><a class="headerlink" href="#id142" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>rm</p></li>
</ul>
<p>删除某个键值。例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl rm /testdir/testkey
PrevNode.Value: Hello
</pre></div>
</div>
<p>当键不存在时，则会报错。例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl rm /testdir/testkey
Error:  100: Key not found (/testdir/testkey) [7]
</pre></div>
</div>
<p>支持的选项为：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="nb">dir</span> <span class="n">如果键是个空目录或者键值对则删除</span>
<span class="o">--</span><span class="n">recursive</span> <span class="n">删除目录和所有子键</span>
<span class="o">--</span><span class="k">with</span><span class="o">-</span><span class="n">value</span>  <span class="n">检查现有的值是否匹配</span>
<span class="o">--</span><span class="k">with</span><span class="o">-</span><span class="n">index</span> <span class="s1">&#39;0&#39;</span><span class="n">检查现有的index是否匹配</span>
</pre></div>
</div>
<ul class="simple">
<li><p>rmdir</p></li>
</ul>
<p>删除一个空目录，或者键值对。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl setdir dir1
$ etcdctl rmdir dir1
</pre></div>
</div>
<p>若目录不空，会报错:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl set /dir/testkey hi
hi
$ etcdctl rmdir /dir
Error:  108: Directory not empty (/dir) [17]
</pre></div>
</div>
</div>
<div class="section" id="id143">
<h3><a class="toc-backref" href="#id394">23.5.3 更新</a><a class="headerlink" href="#id143" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>update</p></li>
</ul>
<p>当键存在时，更新值内容。例如：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl update /testdir/testkey &quot;Hello&quot;
Hello
</pre></div>
</div>
<p>当键不存在时，则会报错。例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl update /testdir/testkey2 &quot;Hello&quot;
Error:  100: Key not found (/testdir/testkey2) [6]
</pre></div>
</div>
<p>支持的选项为:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--ttl &#39;0&#39; 超时时间(单位为秒)，不配置(默认为 0)则永不超时。
</pre></div>
</div>
<ul class="simple">
<li><p>updatedir</p></li>
</ul>
<p>更新一个已经存在的目录。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl updatedir testdir2
</pre></div>
</div>
<p>支持的选项为:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--ttl &#39;0&#39; 超时时间(单位为秒)，不配置(默认为0)则永不超时。
</pre></div>
</div>
</div>
<div class="section" id="id144">
<h3><a class="toc-backref" href="#id395">23.5.4 查询</a><a class="headerlink" href="#id144" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>get</p></li>
</ul>
<p>获取指定键的值。例如：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl get /testdir/testkey
Hello world
</pre></div>
</div>
<p>当键不存在时，则会报错。例如：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl get /testdir/testkey2
Error:  100: Key not found (/testdir/testkey2) [5]
</pre></div>
</div>
<p>支持的选项为:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--sort 对结果进行排序
--consistent 将请求发给主节点，保证获取内容的一致性。
</pre></div>
</div>
<ul class="simple">
<li><p>ls</p></li>
</ul>
<p>列出目录(默认为根目录)下的键或者子目录，默认不显示子目录中内容。</p>
<p>例如：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl ls
/testdir
/testdir2
/dir

$ etcdctl ls dir
/dir/testkey
</pre></div>
</div>
<p>支持的选项包括:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--sort 将输出结果排序
--recursive 如果目录下有子目录，则递归输出其中的内容
-p 对于输出为目录，在最后添加/进行区分
</pre></div>
</div>
</div>
<div class="section" id="watch">
<h3><a class="toc-backref" href="#id396">23.5.5 watch</a><a class="headerlink" href="#watch" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>watch</p></li>
</ul>
<p>监测一个键值的变化，一旦键值发生更新，就会输出最新的值并退出。</p>
<p>例如:用户更新testkey键值为Hello watch。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl get /testdir/testkey
Hello world
$ etcdctl set /testdir/testkey &quot;Hello watch&quot;
Hello watch
$ etcdctl watch testdir/testkey
Hello watch
</pre></div>
</div>
<p>支持的选项包括:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">forever</span>  <span class="n">一直监测直到用户按CTRL</span><span class="o">+</span><span class="n">C退出</span>
<span class="o">--</span><span class="n">after</span><span class="o">-</span><span class="n">index</span> <span class="s1">&#39;0&#39;</span> <span class="n">在指定index之前一直监测</span>
<span class="o">--</span><span class="n">recursive</span> <span class="n">返回所有的键值和子键值</span>
</pre></div>
</div>
<ul class="simple">
<li><p>exec-watch</p></li>
</ul>
<p>监测一个键值的变化，一旦键值发生更新，就执行给定命令。</p>
<p>例如：用户更新testkey键值。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl exec-watch testdir/testkey -- sh -c &#39;ls&#39;
config  Documentation  etcd  etcdctl  README-etcdctl.md  README.md  READMEv2-etcdctl.md
</pre></div>
</div>
<p>支持的选项包括:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">after</span><span class="o">-</span><span class="n">index</span> <span class="s1">&#39;0&#39;</span> <span class="n">在指定</span> <span class="n">index</span> <span class="n">之前一直监测</span>
<span class="o">--</span><span class="n">recursive</span> <span class="n">返回所有的键值和子键值</span>
</pre></div>
</div>
</div>
<div class="section" id="id145">
<h3><a class="toc-backref" href="#id397">23.5.6 备份</a><a class="headerlink" href="#id145" title="Permalink to this headline">¶</a></h3>
<p>备份etcd的数据。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl backup --data-dir /var/lib/etcd  --backup-dir /home/etcd_backup
</pre></div>
</div>
<p>支持的选项包括:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">data</span><span class="o">-</span><span class="nb">dir</span>  <span class="n">etcd的数据目录</span>
<span class="o">--</span><span class="n">backup</span><span class="o">-</span><span class="nb">dir</span> <span class="n">备份到指定路径</span>
</pre></div>
</div>
</div>
<div class="section" id="member">
<h3><a class="toc-backref" href="#id398">23.5.7 member</a><a class="headerlink" href="#member" title="Permalink to this headline">¶</a></h3>
<p>通过<code class="docutils literal notranslate"><span class="pre">list</span></code>、<code class="docutils literal notranslate"><span class="pre">add</span></code>、<code class="docutils literal notranslate"><span class="pre">remove</span></code>命令列出、添加、删除etcd实例到etcd集群中。</p>
<p>查看集群中存在的节点</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl member list
8e9e05c52164694d: name=dev-master-01 peerURLs=http://localhost:2380 clientURLs=http://localhost:2379 isLeader=true
</pre></div>
</div>
<p>删除集群中存在的节点</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl member remove 8e9e05c52164694d
Removed member 8e9e05c52164694d from cluster
</pre></div>
</div>
<p>向集群中新加节点</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ etcdctl member add etcd3 http://192.168.1.100:2380
Added member named etcd3 with ID 8e9e05c52164694d to cluster
</pre></div>
</div>
</div>
</div>
<div class="section" id="id146">
<h2><a class="toc-backref" href="#id399">23.6 示例</a><a class="headerlink" href="#id146" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 设置一个key值</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl set /msg &quot;hello k8s&quot;</span>
hello k8s

<span class="c1"># 获取key的值</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /msg</span>
hello k8s

<span class="c1"># 获取key值的详细信息</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl -o extended get /msg</span>
Key: /msg
Created-Index: <span class="m">12</span>
Modified-Index: <span class="m">12</span>
TTL: <span class="m">0</span>
Index: <span class="m">12</span>

hello k8s

<span class="c1"># 获取不存在的key回报错</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /xxzx</span>
Error:  <span class="m">100</span>: Key not found <span class="o">(</span>/xxzx<span class="o">)</span> <span class="o">[</span><span class="m">12</span><span class="o">]</span>

<span class="c1"># 设置key的ttl，过期后会被自动删除</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl set /testkey &quot;tmp key test&quot; --ttl 5</span>
tmp key <span class="nb">test</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /testkey</span>
Error:  <span class="m">100</span>: Key not found <span class="o">(</span>/testkey<span class="o">)</span> <span class="o">[</span><span class="m">14</span><span class="o">]</span>

<span class="c1"># key 替换操作</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /msg</span>
hello k8s
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl set --swap-with-value &quot;hello k8s&quot; /msg &quot;goodbye&quot;</span>
goodbye
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /msg</span>
goodbye

<span class="c1"># mk 仅当key不存在时创建(set对同一个key会覆盖)</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /msg</span>
goodbye
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl mk /msg &quot;mktest&quot;</span>
Error:  <span class="m">105</span>: Key already exists <span class="o">(</span>/msg<span class="o">)</span> <span class="o">[</span><span class="m">18</span><span class="o">]</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl mk /msg1 &quot;mktest&quot;</span>
mktest

<span class="c1"># 创建自排序的key</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl mk --in-order /queue s1</span>
s1
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl mk --in-order /queue s2</span>
s2
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl ls --sort /queue</span>
/queue/00000000000000000021
/queue/00000000000000000022
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /queue/00000000000000000021</span>
s1

<span class="c1"># 更新key值</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl update /msg1 &quot;update test&quot;</span>
update <span class="nb">test</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /msg1</span>
update <span class="nb">test</span>

<span class="c1"># 更新key的ttl及值</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl update --ttl 5 /msg &quot;aaa&quot;</span>
aaa

<span class="c1"># 创建目录</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl mkdir /testdir</span>

<span class="c1"># 删除空目录</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl mkdir /test1</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl rmdir /test1</span>

<span class="c1"># 删除非空目录</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl get /testdir</span>
/testdir: is a directory
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1">#</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl rm --recursive /testdir</span>

<span class="c1"># 列出目录内容</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl ls /</span>
/tmp
/msg1
/queue
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl ls /tmp</span>
/tmp/a
/tmp/b

<span class="c1"># 递归列出目录的内容</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl ls --recursive /</span>
/msg1
/queue
/queue/00000000000000000021
/queue/00000000000000000022
/tmp
/tmp/b
/tmp/a

<span class="c1"># 监听key，当key发生改变的时候打印出变化</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl watch /msg1</span>
xxx

<span class="o">[</span>root@VM_0_17_centos ~<span class="o">]</span><span class="c1"># etcdctl update /msg1 &quot;xxx&quot;</span>
xxx

<span class="c1"># 监听某个目录，当目录中任何 node 改变的时候，都会打印出来</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl watch --recursive /</span>
<span class="o">[</span>update<span class="o">]</span> /msg1
xxx

<span class="o">[</span>root@VM_0_17_centos ~<span class="o">]</span><span class="c1"># etcdctl update /msg1 &quot;xxx&quot;</span>
xxx

<span class="c1"># 一直监听，除非 `CTL + C` 导致退出监听</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl watch --forever /</span>


<span class="c1"># 监听目录，当发生变化时执行一条命令</span>
<span class="o">[</span>root@etcd-0-8 ~<span class="o">]</span><span class="c1"># etcdctl exec-watch --recursive / -- sh -c &quot;echo change&quot;</span>
change

<span class="c1"># backup</span>
<span class="o">[</span>root@etcd-0-14 ~<span class="o">]</span><span class="c1"># etcdctl backup --data-dir /data/app/etcd --backup-dir /root/etcd_backup</span>
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113237 I <span class="p">|</span> ignoring EntryConfChange raft entry
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113268 I <span class="p">|</span> ignoring EntryConfChange raft entry
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113272 I <span class="p">|</span> ignoring EntryConfChange raft entry
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113293 I <span class="p">|</span> ignoring member attribute update on /0/members/2d2e457c6a1a76cb/attributes
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113299 I <span class="p">|</span> ignoring member attribute update on /0/members/d2d2e9fc758e6790/attributes
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113305 I <span class="p">|</span> ignoring member attribute update on /0/members/56e0b6dad4c53d42/attributes
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113310 I <span class="p">|</span> ignoring member attribute update on /0/members/56e0b6dad4c53d42/attributes
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113314 I <span class="p">|</span> ignoring member attribute update on /0/members/2d2e457c6a1a76cb/attributes
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113319 I <span class="p">|</span> ignoring member attribute update on /0/members/d2d2e9fc758e6790/attributes
<span class="m">2019</span>-12-04 <span class="m">10</span>:25:16.113384 I <span class="p">|</span> ignoring member attribute update on /0/members/56e0b6dad4c53d42/attributes

<span class="c1"># 使用v3版本</span>
<span class="o">[</span>root@etcd-0-14 ~<span class="o">]</span><span class="c1"># export ETCDCTL_API=3</span>
<span class="o">[</span>root@etcd-0-14 ~<span class="o">]</span><span class="c1"># etcdctl --endpoints=&quot;http://172.16.0.8:2379,http://172.16.0.14:2379,http://172.16.0.17:2379&quot; snapshot save mysnapshot.db</span>
Snapshot saved at mysnapshot.db
<span class="o">[</span>root@etcd-0-14 ~<span class="o">]</span><span class="c1"># etcdctl snapshot status mysnapshot.db -w json</span>
<span class="o">{</span><span class="s2">&quot;hash&quot;</span>:928285884,<span class="s2">&quot;revision&quot;</span>    :0,<span class="s2">&quot;totalKey&quot;</span>:5,<span class="s2">&quot;totalSize&quot;</span>:20480<span class="o">}</span>
</pre></div>
</div>
<ul>
<li><p>参考链接</p></li>
<li><p><a class="reference external" href="https://github.com/etcd-io/etcd">https://github.com/etcd-io/etcd</a></p></li>
<li><p><a class="reference external" href="https://www.yuque.com/lurunhao/nl81zh/hb8sie">https://www.yuque.com/lurunhao/nl81zh/hb8sie</a></p></li>
<li><p><a class="reference external" href="https://www.hi-linux.com/posts/40915.html">https://www.hi-linux.com/posts/40915.html</a></p></li>
<li><div class="line-block">
<div class="line"><a class="reference external" href="https://cizixs.com/2016/08/02/intro-to-etcd/">https://cizixs.com/2016/08/02/intro-to-etcd/</a></div>
</div>
</li>
<li><p><a class="reference external" href="https://github.com/aCoder2013/blog/issues/30">Etcd
Raft使用入门及原理解析</a></p></li>
<li><p><a class="reference external" href="https://juejin.im/post/5dabc50ef265da5b591b761a">https://juejin.im/post/5dabc50ef265da5b591b761a</a></p></li>
<li><p><a class="reference external" href="https://www.infoq.cn/article/coreos-analyse-etcd/">https://www.infoq.cn/article/coreos-analyse-etcd/</a></p></li>
</ul>
</div>
</div>
<div class="section" id="kubesphere">
<h1><a class="toc-backref" href="#id400">二十四 国产容器管理平台KubeSphere实战排错</a><a class="headerlink" href="#kubesphere" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>概述：近期在使用QingCloud的Kubesphere，极好的用户体验，私有化部署，无基础设施依赖，无
Kubernetes
依赖，支持跨物理机、虚拟机、云平台部署，可以纳管不同版本、不同厂商的
Kubernetes
集群。在k8s上层进行了封装实现了基于角色的权限控制，DevOPS流水线快速实现CI/CD，内置harbor/gitlab/jenkins/sonarqube等常用工具，基于基于
OpenPitrix
提供应用的全生命周期管理，包含开发、测试、发布、升级，下架等应用相关操作自己体验还是非常的棒。
同样作为开源项目，难免存在一些bug，在自己的使用中遇到下排错思路，非常感谢qingcloud社区提供的技术协助，对k8s有兴趣的可以去体验下国产的平台，如丝般顺滑的体验，rancher的用户也可以来对不体验下。</p>
</div></blockquote>
<div class="section" id="id147">
<h2><a class="toc-backref" href="#id401">24.1 清理退出状态的容器</a><a class="headerlink" href="#id147" title="Permalink to this headline">¶</a></h2>
<p>在集群运行一段时间后，有些container由于异常状态退出Exited，需要去及时清理释放磁盘，可以将其设置成定时任务执行</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker rm <span class="sb">`</span>docker ps -a <span class="p">|</span> grep Exited <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="sb">`</span>
</pre></div>
</div>
</div>
<div class="section" id="id148">
<h2><a class="toc-backref" href="#id402">24.2 清理异常或被驱逐的 pod</a><a class="headerlink" href="#id148" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>清理kubesphere-devops-system的ns下清理</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl delete pods -n kubesphere-devops-system <span class="k">$(</span>kubectl get pods -n kubesphere-devops-system <span class="p">|</span> grep Evicted <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span>
kubectl delete pods -n kubesphere-devops-system <span class="k">$(</span>kubectl get pods -n kubesphere-devops-system <span class="p">|</span> grep CrashLoopBackOff <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>为方便清理指定ns清理evicted/crashloopbackoff的pod/清理exited的容器</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1"># auth:kaliarch</span>

clear_evicted_pod<span class="o">()</span> <span class="o">{</span>
  <span class="nv">ns</span><span class="o">=</span><span class="nv">$1</span>
  kubectl delete pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="k">$(</span>kubectl get pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="p">|</span> grep Evicted <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span>
<span class="o">}</span>
clear_crash_pod<span class="o">()</span> <span class="o">{</span>
  <span class="nv">ns</span><span class="o">=</span><span class="nv">$1</span>
  kubectl delete pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="k">$(</span>kubectl get pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="p">|</span> grep CrashLoopBackOff <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span>
<span class="o">}</span>
clear_exited_container<span class="o">()</span> <span class="o">{</span>
  docker rm <span class="sb">`</span>docker ps -a <span class="p">|</span> grep Exited <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="sb">`</span>
<span class="o">}</span>


<span class="nb">echo</span> <span class="s2">&quot;1.clear exicted pod&quot;</span>
<span class="nb">echo</span> <span class="s2">&quot;2.clear crash pod&quot;</span>
<span class="nb">echo</span> <span class="s2">&quot;3.clear exited container&quot;</span>
<span class="nb">read</span> -p <span class="s2">&quot;Please input num:&quot;</span> num


<span class="k">case</span> <span class="si">${</span><span class="nv">num</span><span class="si">}</span> in
<span class="s2">&quot;1&quot;</span><span class="o">)</span>
  <span class="nb">read</span> -p <span class="s2">&quot;Please input oper namespace:&quot;</span> ns
  clear_evicted_pod <span class="si">${</span><span class="nv">ns</span><span class="si">}</span>
  <span class="p">;;</span>


<span class="s2">&quot;2&quot;</span><span class="o">)</span>
  <span class="nb">read</span> -p <span class="s2">&quot;Please input oper namespace:&quot;</span> ns
  clear_crash_pod <span class="si">${</span><span class="nv">ns</span><span class="si">}</span>
  <span class="p">;;</span>
<span class="s2">&quot;3&quot;</span><span class="o">)</span>
  clear_exited_container
  <span class="p">;;</span>
<span class="s2">&quot;*&quot;</span><span class="o">)</span>
  <span class="nb">echo</span> <span class="s2">&quot;input error&quot;</span>
  <span class="p">;;</span>
<span class="k">esac</span>
</pre></div>
</div>
<ul class="simple">
<li><p>清理全部ns中evicted/crashloopbackoff的pod</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 获取所有ns</span>
kubectl get ns <span class="p">|</span> grep -v <span class="s2">&quot;NAME&quot;</span> <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span>

<span class="c1"># 清理驱逐状态的pod</span>
<span class="k">for</span> ns in <span class="sb">`</span>kubectl get ns <span class="p">|</span> grep -v <span class="s2">&quot;NAME&quot;</span> <span class="p">|</span> awk <span class="s1">&#39;{print $1}&#39;</span><span class="sb">`</span><span class="p">;</span><span class="k">do</span> kubectl delete pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="k">$(</span>kubectl get pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="p">|</span> grep <span class="s2">&quot;Evicted&quot;</span> <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span><span class="p">;</span><span class="k">done</span>
<span class="c1"># 清理异常pod</span>
<span class="k">for</span> ns in <span class="sb">`</span>kubectl get ns <span class="p">|</span> grep -v <span class="s2">&quot;NAME&quot;</span> <span class="p">|</span> awk <span class="s1">&#39;{print $1}&#39;</span><span class="sb">`</span><span class="p">;</span><span class="k">do</span> kubectl delete pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="k">$(</span>kubectl get pods -n <span class="si">${</span><span class="nv">ns</span><span class="si">}</span> <span class="p">|</span> grep <span class="s2">&quot;CrashLoopBackOff&quot;</span> <span class="p">|</span>awk <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span><span class="p">;</span><span class="k">done</span>
</pre></div>
</div>
</div>
<div class="section" id="docker">
<h2><a class="toc-backref" href="#id403">24.3 Docker 数据迁移</a><a class="headerlink" href="#docker" title="Permalink to this headline">¶</a></h2>
<p>在安装过程中未指定docker数据目录，系统盘50G，随着时间推移磁盘不够用，需要迁移docker数据，使用软连接方式：
首选挂载新磁盘到/data目录</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>systemctl stop docker

mkdir -p /data/docker/

rsync -avz /var/lib/docker/ /data/docker/

mv /var/lib/docker /data/docker_bak

ln -s /data/docker /var/lib/

systemctl daemon-reload

systemctl start docker
</pre></div>
</div>
</div>
<div class="section" id="id149">
<h2><a class="toc-backref" href="#id404">24.4 kubesphere 网络排错</a><a class="headerlink" href="#id149" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>问题描述：</p></li>
</ul>
<p>在kubesphere的node节点或master节点，手动去启动容器，在容器里面无法连通公网，是我的配置哪里不对么，之前默认使用calico，现在改成fluannel也不行，在kubesphere中部署deployment中的pod的容器上可以出公网，在node或master单独手动启动的访问不了公网</p>
<p>查看手动启动的容器网络上走的docker0</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="nd">@fd1b8101475d</span><span class="p">:</span><span class="o">/</span><span class="c1"># ip a</span>

<span class="mi">1</span><span class="p">:</span> <span class="n">lo</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">LOOPBACK</span><span class="p">,</span><span class="n">UP</span><span class="p">,</span><span class="n">LOWER_UP</span><span class="o">&gt;</span> <span class="n">mtu</span> <span class="mi">65536</span> <span class="n">qdisc</span> <span class="n">noqueue</span> <span class="n">state</span> <span class="n">UNKNOWN</span> <span class="n">group</span> <span class="n">default</span> <span class="n">qlen</span> <span class="mi">1</span>

    <span class="n">link</span><span class="o">/</span><span class="n">loopback</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span> <span class="n">brd</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>

    <span class="n">inet</span> <span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span><span class="o">/</span><span class="mi">8</span> <span class="n">scope</span> <span class="n">host</span> <span class="n">lo</span>

       <span class="n">valid_lft</span> <span class="n">forever</span> <span class="n">preferred_lft</span> <span class="n">forever</span>

<span class="mi">2</span><span class="p">:</span> <span class="n">tunl0</span><span class="nd">@NONE</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">NOARP</span><span class="o">&gt;</span> <span class="n">mtu</span> <span class="mi">1480</span> <span class="n">qdisc</span> <span class="n">noop</span> <span class="n">state</span> <span class="n">DOWN</span> <span class="n">group</span> <span class="n">default</span> <span class="n">qlen</span> <span class="mi">1</span>

    <span class="n">link</span><span class="o">/</span><span class="n">ipip</span> <span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span> <span class="n">brd</span> <span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span>

<span class="mi">105</span><span class="p">:</span> <span class="n">eth0</span><span class="nd">@if106</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">BROADCAST</span><span class="p">,</span><span class="n">MULTICAST</span><span class="p">,</span><span class="n">UP</span><span class="p">,</span><span class="n">LOWER_UP</span><span class="o">&gt;</span> <span class="n">mtu</span> <span class="mi">1500</span> <span class="n">qdisc</span> <span class="n">noqueue</span> <span class="n">state</span> <span class="n">UP</span> <span class="n">group</span> <span class="n">default</span>

    <span class="n">link</span><span class="o">/</span><span class="n">ether</span> <span class="mi">02</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="n">ac</span><span class="p">:</span><span class="mi">11</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">02</span> <span class="n">brd</span> <span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span> <span class="n">link</span><span class="o">-</span><span class="n">netnsid</span> <span class="mi">0</span>

    <span class="n">inet</span> <span class="mf">172.17</span><span class="o">.</span><span class="mf">0.2</span><span class="o">/</span><span class="mi">16</span> <span class="n">brd</span> <span class="mf">172.17</span><span class="o">.</span><span class="mf">255.255</span> <span class="n">scope</span> <span class="k">global</span> <span class="n">eth0</span>

       <span class="n">valid_lft</span> <span class="n">forever</span> <span class="n">preferred_lft</span> <span class="n">forever</span>
</pre></div>
</div>
<p>在pods中的容器网络用的是kube-ipvs0</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span><span class="p">:</span> <span class="n">lo</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">LOOPBACK</span><span class="p">,</span><span class="n">UP</span><span class="p">,</span><span class="n">LOWER_UP</span><span class="o">&gt;</span> <span class="n">mtu</span> <span class="mi">65536</span> <span class="n">qdisc</span> <span class="n">noqueue</span> <span class="n">qlen</span> <span class="mi">1</span>

    <span class="n">link</span><span class="o">/</span><span class="n">loopback</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span> <span class="n">brd</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>

    <span class="n">inet</span> <span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span><span class="o">/</span><span class="mi">8</span> <span class="n">scope</span> <span class="n">host</span> <span class="n">lo</span>

       <span class="n">valid_lft</span> <span class="n">forever</span> <span class="n">preferred_lft</span> <span class="n">forever</span>

<span class="mi">2</span><span class="p">:</span> <span class="n">tunl0</span><span class="nd">@NONE</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">NOARP</span><span class="o">&gt;</span> <span class="n">mtu</span> <span class="mi">1480</span> <span class="n">qdisc</span> <span class="n">noop</span> <span class="n">qlen</span> <span class="mi">1</span>

    <span class="n">link</span><span class="o">/</span><span class="n">ipip</span> <span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span> <span class="n">brd</span> <span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span>

<span class="mi">4</span><span class="p">:</span> <span class="n">eth0</span><span class="nd">@if18</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">BROADCAST</span><span class="p">,</span><span class="n">MULTICAST</span><span class="p">,</span><span class="n">UP</span><span class="p">,</span><span class="n">LOWER_UP</span><span class="p">,</span><span class="n">M</span><span class="o">-</span><span class="n">DOWN</span><span class="o">&gt;</span> <span class="n">mtu</span> <span class="mi">1500</span> <span class="n">qdisc</span> <span class="n">noqueue</span>

    <span class="n">link</span><span class="o">/</span><span class="n">ether</span> <span class="n">c2</span><span class="p">:</span><span class="mi">27</span><span class="p">:</span><span class="mi">44</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span><span class="n">df</span><span class="p">:</span><span class="mi">5</span><span class="n">d</span> <span class="n">brd</span> <span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span><span class="p">:</span><span class="n">ff</span>

    <span class="n">inet</span> <span class="mf">10.233</span><span class="o">.</span><span class="mf">97.175</span><span class="o">/</span><span class="mi">32</span> <span class="n">scope</span> <span class="k">global</span> <span class="n">eth0</span>

       <span class="n">valid_lft</span> <span class="n">forever</span> <span class="n">preferred_lft</span> <span class="n">forever</span>
</pre></div>
</div>
<ul class="simple">
<li><p>解决方案：</p></li>
</ul>
<p>查看docker启动配置</p>
<p><img alt="image10" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175714.png" /></p>
<p>修改文件/etc/systemd/system/docker.service.d/docker-options.conf中去掉参数：–iptables=false
这个参数等于false时会不写iptables</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>Service<span class="o">]</span>
<span class="nv">Environment</span><span class="o">=</span><span class="s2">&quot;DOCKER_OPTS=  --registry-mirror=https://registry.docker-cn.com --data-root=/var/lib/docker --log-opt max-size=10m --log-opt max-file=3 --insecure-registry=harbor.devops.kubesphere.local:30280&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id150">
<h2><a class="toc-backref" href="#id405">24.5 kubesphere 应用路由异常</a><a class="headerlink" href="#id150" title="Permalink to this headline">¶</a></h2>
<p>在kubesphere中应用路由ingress使用的是nginx，在web界面配置会导致两个host使用同一个ca证书，可以通过注释文件配置</p>
<p>⚠️注意：ingress控制deployment在：</p>
<p><img alt="image11" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175735.png" /></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">extensions/v1beta1</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">prod-app-ingress</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">prod-net-route</span>
  <span class="nt">resourceVersion</span><span class="p">:</span> <span class="s">&#39;8631859&#39;</span>
  <span class="nt">labels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">prod-app-ingress</span>
  <span class="nt">annotations</span><span class="p">:</span>
    <span class="nt">desc</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">生产环境应用路由</span>
    <span class="nt">nginx.ingress.kubernetes.io/client-body-buffer-size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1024m</span>
    <span class="nt">nginx.ingress.kubernetes.io/proxy-body-size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2048m</span>
    <span class="nt">nginx.ingress.kubernetes.io/proxy-read-timeout</span><span class="p">:</span> <span class="s">&#39;3600&#39;</span>
    <span class="nt">nginx.ingress.kubernetes.io/proxy-send-timeout</span><span class="p">:</span> <span class="s">&#39;1800&#39;</span>
    <span class="nt">nginx.ingress.kubernetes.io/service-upstream</span><span class="p">:</span> <span class="s">&#39;true&#39;</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">tls</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">hosts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">smartms.tools.anchnet.com</span>
      <span class="nt">secretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smartms-ca</span>
    <span class="p p-Indicator">-</span> <span class="nt">hosts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">smartsds.tools.anchnet.com</span>
      <span class="nt">secretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smartsds-ca</span>
  <span class="nt">rules</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">host</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smartms.tools.anchnet.com</span>
      <span class="nt">http</span><span class="p">:</span>
        <span class="nt">paths</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
            <span class="nt">backend</span><span class="p">:</span>
              <span class="nt">serviceName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smartms-frontend-svc</span>
              <span class="nt">servicePort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="p p-Indicator">-</span> <span class="nt">host</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smartsds.tools.anchnet.com</span>
      <span class="nt">http</span><span class="p">:</span>
        <span class="nt">paths</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
            <span class="nt">backend</span><span class="p">:</span>
              <span class="nt">serviceName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smartsds-frontend-svc</span>

              <span class="nt">servicePort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
</pre></div>
</div>
</div>
<div class="section" id="jenkins-agent">
<h2><a class="toc-backref" href="#id406">24.6 Jenkins 的 Agent</a><a class="headerlink" href="#jenkins-agent" title="Permalink to this headline">¶</a></h2>
<p>用户在自己的使用场景当中，可能会使用不同的语言版本活不同的工具版本。这篇文档主要介绍如何替换内置的
agent。</p>
<p>默认base-build镜像中没有sonar-scanner工具，Kubesphere Jenkins 的每一个
agent 都是一个Pod，如果要替换内置的agent，就需要替换 agent 的相应镜像。</p>
<p>构建最新 kubesphere/builder-base:advanced-1.0.0 版本的 agent 镜像</p>
<p>更新为指定的自定义镜像：ccr.ccs.tencentyun.com/testns/base:v1</p>
<p>参考链接：<a class="reference external" href="https://kubesphere.io/docs/advanced-v2.0/zh-CN/devops/devops-admin-faq/#%E5%8D%87%E7%BA%A7-jenkins-agent-%E7%9A%84%E5%8C%85%E7%89%88%E6%9C%AC">https://kubesphere.io/docs/advanced-v2.0/zh-CN/devops/devops-admin-faq/#%E5%8D%87%E7%BA%A7-jenkins-agent-%E7%9A%84%E5%8C%85%E7%89%88%E6%9C%AC</a></p>
<p><img alt="image12" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175826.png" /><img alt="image13" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175841.png" /></p>
<p>在 KubeSphere 修改 jenkins-casc-config 以后，您需要在 Jenkins Dashboard
系统管理下的 configuration-as-code 页面重新加载您更新过的系统配置。</p>
<p>参考：</p>
<p><a class="reference external" href="https://kubesphere.io/docs/advanced-v2.0/zh-CN/devops/jenkins-setting/#%E7%99%BB%E9%99%86-jenkins-%E9%87%8D%E6%96%B0%E5%8A%A0%E8%BD%BD">https://kubesphere.io/docs/advanced-v2.0/zh-CN/devops/jenkins-setting/#%E7%99%BB%E9%99%86-jenkins-%E9%87%8D%E6%96%B0%E5%8A%A0%E8%BD%BD</a></p>
<p><img alt="image14" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175918.png" /></p>
<p>jenkins中更新base镜像</p>
<p><img alt="image15" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315175938.png" /></p>
<p>⚠️先修改kubesphere中jenkins的配置，<a class="reference external" href="http://xxxxxxxxx:30800/system-workspace/projects/kubesphere-devops-system/configmaps/jenkins-casc-config">jenkins-casc-config</a></p>
</div>
<div class="section" id="devops-mail">
<h2><a class="toc-backref" href="#id407">24.7 Devops 中 Mail的发送</a><a class="headerlink" href="#devops-mail" title="Permalink to this headline">¶</a></h2>
<p>参考：<a class="reference external" href="https://www.cloudbees.com/blog/mail-step-jenkins-workflow">https://www.cloudbees.com/blog/mail-step-jenkins-workflow</a></p>
<p>内置变量：</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>变量名</strong></p></th>
<th class="head"><p><strong>解释</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>BUILD_NUMBER</p></td>
<td><p>The current build number, such as
“153”</p></td>
</tr>
<tr class="row-odd"><td><p>BUILD_ID</p></td>
<td><p>The current build ID, identical
to BUILD_NUMBER for builds
created in 1.597+, but a
YYYY-MM-DD_hh-mm-ss timestamp for
older builds</p></td>
</tr>
<tr class="row-even"><td><p>BUILD_DISPLAY_NAME</p></td>
<td><p>The display name of the current
build, which is something like
“#153” by default.</p></td>
</tr>
<tr class="row-odd"><td><p>JOB_NAME</p></td>
<td><p>Name of the project of this
build, such as “foo” or
“foo/bar”. (To strip off folder
paths from a Bourne shell script,
try:
<span class="math notranslate nohighlight">\({JOB_NAME}) | | BUILD_TAG
| String of &quot;jenkins-\)</span>{JOB_NAME
}-${BUILD_NUMBER}”.
Convenient to put into a resource
file, a jar file, etc for easier
identification.</p></td>
</tr>
<tr class="row-even"><td><p>EXECUTOR_NUMBER</p></td>
<td><p>The unique number that identifies
the current executor (among
executors of the same machine)
that’s carrying out this build.
This is the number you see in the
“build executor status”, except
that the number starts from 0,
not 1.</p></td>
</tr>
<tr class="row-odd"><td><p>NODE_NAME</p></td>
<td><p>Name of the slave if the build is
on a slave, or “master” if run on
master</p></td>
</tr>
<tr class="row-even"><td><p>NODE_LABELS</p></td>
<td><p>Whitespace-separated list of
labels that the node is assigned.</p></td>
</tr>
<tr class="row-odd"><td><p>WORKSPACE</p></td>
<td><p>The absolute path of the
directory assigned to the build
as a workspace.</p></td>
</tr>
<tr class="row-even"><td><p>JENKINS_HOME</p></td>
<td><p>The absolute path of the
directory assigned on the master
node for Jenkins to store data.</p></td>
</tr>
<tr class="row-odd"><td><p>JENKINS_URL</p></td>
<td><p>Full URL of Jenkins, like
<a class="reference external" href="http://server:port/jenkins/">http://server:port/jenkins/</a>
(note: only available if Jenkins
URL set in system configuration)</p></td>
</tr>
<tr class="row-even"><td><p>BUILD_URL</p></td>
<td><p>Full URL of this build, like
<a class="reference external" href="http://server:port/jenkins/job/foo/15/">http://server:port/jenkins/job/f
oo/15/</a>
(Jenkins URL must be set)</p></td>
</tr>
<tr class="row-odd"><td><p>SVN_REVISION</p></td>
<td><p>Subversion revision number that’s
currently checked out to the
workspace, such as “12345”</p></td>
</tr>
<tr class="row-even"><td><p>SVN_URL</p></td>
<td><p>Subversion URL that’s currently
checked out to the workspace.</p></td>
</tr>
<tr class="row-odd"><td><p>JOB_URL</p></td>
<td><p>Full URL of this job, like
<a class="reference external" href="http://server:port/jenkins/job/foo/">http://server:port/jenkins/job/f
oo/</a>
(Jenkins URL must be set)</p></td>
</tr>
</tbody>
</table>
<p>最终自己写了适应自己业务的模版，可以直接使用</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mail to: <span class="s1">&#39;xuel@net.com&#39;</span>,
          charset:<span class="s1">&#39;UTF-8&#39;</span>, // or GBK/GB18030
          mimeType:<span class="s1">&#39;text/plain&#39;</span>, // or text/html
          subject: <span class="s2">&quot;Kubesphere </span><span class="si">${</span><span class="nv">env</span><span class="p">.JOB_NAME</span><span class="si">}</span><span class="s2"> [</span><span class="si">${</span><span class="nv">env</span><span class="p">.BUILD_NUMBER</span><span class="si">}</span><span class="s2">] 发布正常Running Pipeline: </span><span class="si">${</span><span class="nv">currentBuild</span><span class="p">.fullDisplayName</span><span class="si">}</span><span class="s2">&quot;</span>,
          body: <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">          ---------Anchnet Devops Kubesphere Pipeline job--------------------</span>


<span class="s2">          项目名称 : </span><span class="si">${</span><span class="nv">env</span><span class="p">.JOB_NAME</span><span class="si">}</span><span class="s2"></span>
<span class="s2">          构建次数 : </span><span class="si">${</span><span class="nv">env</span><span class="p">.BUILD_NUMBER</span><span class="si">}</span><span class="s2"></span>
<span class="s2">          扫描信息 : 地址:</span><span class="si">${</span><span class="nv">SONAR_HOST</span><span class="si">}</span><span class="s2"></span>
<span class="s2">          镜像地址 : </span><span class="si">${</span><span class="nv">REGISTRY</span><span class="si">}</span><span class="s2">/</span><span class="si">${</span><span class="nv">QHUB_NAMESPACE</span><span class="si">}</span><span class="s2">/</span><span class="si">${</span><span class="nv">APP_NAME</span><span class="si">}</span><span class="s2">:</span><span class="si">${</span><span class="nv">IMAGE_TAG</span><span class="si">}</span><span class="s2"></span>
<span class="s2">          构建详情：SUCCESSFUL: Job </span><span class="si">${</span><span class="nv">env</span><span class="p">.JOB_NAME</span><span class="si">}</span><span class="s2"> [</span><span class="si">${</span><span class="nv">env</span><span class="p">.BUILD_NUMBER</span><span class="si">}</span><span class="s2">]</span>
<span class="s2">          构建状态 : </span><span class="si">${</span><span class="nv">env</span><span class="p">.JOB_NAME</span><span class="si">}</span><span class="s2"> jenkins 发布运行正常</span>
<span class="s2">          构建URL : </span><span class="si">${</span><span class="nv">env</span><span class="p">.BUILD_URL</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span>
</pre></div>
</div>
<div class="figure align-default" id="id165">
<img alt="image-20200315180012132" src="Users/xuel/Library/Application%20Support/typora-user-images/image-20200315180012132.png" />
<p class="caption"><span class="caption-text">image-20200315180012132</span><a class="headerlink" href="#id165" title="Permalink to this image">¶</a></p>
</div>
<p><img alt="image16" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180020.png" /></p>
</div>
<div class="section" id="id151">
<h2><a class="toc-backref" href="#id408">24.8 kubesphere应用上传问题</a><a class="headerlink" href="#id151" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id152">
<h3><a class="toc-backref" href="#id409">24.8.1 文件上传413</a><a class="headerlink" href="#id152" title="Permalink to this headline">¶</a></h3>
<p>将应用部署进入kubesphere中，应用中有设置上传文件功能，测试上次异常无法正常上传，文件上传，ingress413报错，kubesphere使用的是ingress-nginx控制器，可以在其中注解添加k-v来支持，</p>
<p>解决方案：应用路由自定义max body size</p>
<p><a class="reference external" href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#custom-max-body-size">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#custom-max-body-size</a></p>
</div>
<div class="section" id="id153">
<h3><a class="toc-backref" href="#id410">24.8.2 大文件上传后端504</a><a class="headerlink" href="#id153" title="Permalink to this headline">¶</a></h3>
<p>大文件上传后端响应504解决方案：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>proxy <span class="nb">read</span> timeoutnginx.ingress.kubernetes.io/proxy-read-timeout
</pre></div>
</div>
</div>
</div>
<div class="section" id="id154">
<h2><a class="toc-backref" href="#id411">24.9 跨域问题</a><a class="headerlink" href="#id154" title="Permalink to this headline">¶</a></h2>
<p>kubesphere使用ingress-nginx支持跨域，可以参考以下链接在注解中添加</p>
<p><a class="reference external" href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#enable-cors">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#enable-cors</a></p>
<p>测试环境可以使用可以使用hosts，将域名解析到本地，前端利用nginx来做静态文件服务，反向代理后端api，可以参考示例：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>server <span class="o">{</span>
  listen <span class="m">80</span><span class="p">;</span>
  server_name localhost<span class="p">;</span>
  <span class="c1"># 强制https跳转</span>
  <span class="c1"># rewrite ^(.*)$ https://$host$1 permanent;</span>
  location / <span class="o">{</span>
    index      index.html<span class="p">;</span>
    root       /smart-frontend<span class="p">;</span>
    try_files <span class="nv">$uri</span> <span class="nv">$uri</span>/ /index.html<span class="p">;</span>
    client_body_buffer_size 200m<span class="p">;</span>
    charset utf-8<span class="p">;</span>
  <span class="o">}</span>
  location /api <span class="o">{</span>
      proxy_pass http://smart-backend:8080/api<span class="p">;</span>
      proxy_read_timeout <span class="m">1200</span><span class="p">;</span>
      client_max_body_size 1024m<span class="p">;</span>
  <span class="o">}</span>
      gzip  on<span class="p">;</span> <span class="c1">#开启gzip</span>
      gzip_vary on<span class="p">;</span>
      gzip_min_length 1k<span class="p">;</span> <span class="c1">#不压缩临界值,大于1k的才压缩,一般不用改</span>
      gzip_buffers <span class="m">4</span> 16k<span class="p">;</span>
      gzip_comp_level <span class="m">6</span><span class="p">;</span> <span class="c1">#压缩级别,数字越大压缩的越好</span>
      gzip_types  text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png image/x-icon<span class="p">;</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id155">
<h2><a class="toc-backref" href="#id412">24.10 添加节点</a><a class="headerlink" href="#id155" title="Permalink to this headline">¶</a></h2>
<p>后期逐渐业务上来，集群节点资源不足，新增node节点，将node节点的数据盘添加到ceph节点</p>
<div class="section" id="id156">
<h3><a class="toc-backref" href="#id413">24.10.1 ceph集群添加节点</a><a class="headerlink" href="#id156" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>系统配置</p></li>
<li><p>免费密钥配置</p></li>
<li><p>hosts配置</p></li>
<li><p>docker安装并迁移至数据盘</p></li>
<li><p>cgroup启用</p></li>
<li><p>ceph数据节点添加</p></li>
</ul>
<p>ceph集群配置添加node03集群的数据盘节点（如果数据存储类足够，可以不用添加数据节点）</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@node03 docker<span class="o">]</span><span class="c1"># mkfs.xfs /dev/vdd</span>
<span class="o">[</span>root@node03 docker<span class="o">]</span><span class="c1"># mkdir -p /var/local/osd3</span>
<span class="o">[</span>root@node03 docker<span class="o">]</span><span class="c1"># mount /dev/vdd /var/local/osd3/</span>

添加vdd到/etc/fstab中
<span class="o">[</span>root@node03 docker<span class="o">]</span><span class="c1"># yum -y install yum-plugin-priorities epel-release</span>

<span class="o">[</span>root@node03 yum.repos.d<span class="o">]</span><span class="c1"># chmod 777 -R /var/local/osd3/</span>
<span class="o">[</span>root@node03 yum.repos.d<span class="o">]</span><span class="c1"># chmod 777 -R /var/local/osd3/*  master节点利用ceph-deploy部署node03节点[root@master ceph]# ceph-deploy install node03</span>
<span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph-deploy  gatherkeys master</span>
<span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph-deploy osd prepare node03:/var/local/osd3</span>
</pre></div>
</div>
<ul class="simple">
<li><p>激活osd</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph-deploy osd activate node03:/var/local/osd3</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看状态</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph-deploy osd list master node01 node02 node03</span>
</pre></div>
</div>
<ul class="simple">
<li><p>拷贝密钥</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph-deploy admin master node01 node02 node03</span>
</pre></div>
</div>
<ul class="simple">
<li><p>在node03节点设置权限</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@node03 yum.repos.d<span class="o">]</span><span class="c1"># chmod +r /etc/ceph/ceph.client.admin.keyring</span>
</pre></div>
</div>
<ul class="simple">
<li><p>在master设置MDS</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph-deploy mds create node01 node02 node03</span>
</pre></div>
</div>
<ul class="simple">
<li><p>查看状态</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph health</span>
<span class="o">[</span>root@master ceph<span class="o">]</span><span class="c1"># ceph - 由于是新增node节点，数据需要平衡回填，此刻查看集群状态[root@master conf]# ceph -s</span>
    cluster 5b9eb8d2-1c12-4f6d-ae9c-85078795794b
     health HEALTH_ERR
            <span class="m">44</span> pgs backfill_wait
            <span class="m">1</span> pgs backfilling
            <span class="m">1</span> pgs inconsistent
            <span class="m">45</span> pgs stuck unclean
            recovery <span class="m">1</span>/55692 objects degraded <span class="o">(</span><span class="m">0</span>.002%<span class="o">)</span>
            recovery <span class="m">9756</span>/55692 objects misplaced <span class="o">(</span><span class="m">17</span>.518%<span class="o">)</span>
            <span class="m">2</span> scrub errors
     monmap e1: <span class="m">1</span> mons at <span class="o">{</span><span class="nv">master</span><span class="o">=</span><span class="m">172</span>.16.60.2:6789/0<span class="o">}</span>
            election epoch <span class="m">35</span>, quorum <span class="m">0</span> master
     osdmap e2234: <span class="m">4</span> osds: <span class="m">4</span> up, <span class="m">4</span> in<span class="p">;</span> <span class="m">45</span> remapped pgs
            flags sortbitwise,require_jewel_osds
      pgmap v5721471: <span class="m">192</span> pgs, <span class="m">2</span> pools, <span class="m">104</span> GB data, <span class="m">27846</span> objects
            <span class="m">230</span> GB used, <span class="m">1768</span> GB / <span class="m">1999</span> GB avail
            <span class="m">1</span>/55692 objects degraded <span class="o">(</span><span class="m">0</span>.002%<span class="o">)</span>
            <span class="m">9756</span>/55692 objects misplaced <span class="o">(</span><span class="m">17</span>.518%<span class="o">)</span>
                 <span class="m">146</span> active+clean
                  <span class="m">44</span> active+remapped+wait_backfill
                   <span class="m">1</span> active+remapped+backfilling
                   <span class="m">1</span> active+clean+inconsistent
recovery io <span class="m">50492</span> kB/s, <span class="m">13</span> objects/s
  client io <span class="m">20315</span> B/s wr, <span class="m">0</span> op/s rd, <span class="m">5</span> op/s wr
</pre></div>
</div>
<ul class="simple">
<li><p>最终的问题，目前由于新增了node节点，新增ceph数据节点需要数据同步</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master conf<span class="o">]</span><span class="c1"># ceph -s</span>
    cluster 5b9eb8d2-1c12-4f6d-ae9c-85078795794b
     health HEALTH_ERR
            <span class="m">1</span> pgs inconsistent
            <span class="m">2</span> scrub errors
     monmap e1: <span class="m">1</span> mons at <span class="o">{</span><span class="nv">master</span><span class="o">=</span><span class="m">172</span>.16.60.2:6789/0<span class="o">}</span>
            election epoch <span class="m">35</span>, quorum <span class="m">0</span> master
     osdmap e2324: <span class="m">4</span> osds: <span class="m">4</span> up, <span class="m">4</span> in
            flags sortbitwise,require_jewel_osds
      pgmap v5723479: <span class="m">192</span> pgs, <span class="m">2</span> pools, <span class="m">104</span> GB data, <span class="m">27848</span> objects
            <span class="m">229</span> GB used, <span class="m">1769</span> GB / <span class="m">1999</span> GB avail
                 <span class="m">191</span> active+clean
                   <span class="m">1</span> active+clean+inconsistent
  client io <span class="m">78305</span> B/s wr, <span class="m">0</span> op/s rd, <span class="m">18</span> op/s wr修复<span class="o">[</span>root@master conf<span class="o">]</span><span class="c1"># ceph -s</span>
    cluster 5b9eb8d2-1c12-4f6d-ae9c-85078795794b
     health HEALTH_OK
     monmap e1: <span class="m">1</span> mons at <span class="o">{</span><span class="nv">master</span><span class="o">=</span><span class="m">172</span>.16.60.2:6789/0<span class="o">}</span>
            election epoch <span class="m">35</span>, quorum <span class="m">0</span> master
     osdmap e2324: <span class="m">4</span> osds: <span class="m">4</span> up, <span class="m">4</span> in
            flags sortbitwise,require_jewel_osds
      pgmap v5724320: <span class="m">192</span> pgs, <span class="m">2</span> pools, <span class="m">104</span> GB data, <span class="m">27848</span> objects
            <span class="m">229</span> GB used, <span class="m">1769</span> GB / <span class="m">1999</span> GB avail
                 <span class="m">192</span> active+clean
  client io <span class="m">227</span> kB/s wr, <span class="m">0</span> op/s rd, <span class="m">7</span> op/s wr
<span class="c1"># 同步完成</span>
<span class="o">[</span>root@master conf<span class="o">]</span><span class="c1"># ceph health</span>
HEALTH_OK
</pre></div>
</div>
</div>
<div class="section" id="id157">
<h3><a class="toc-backref" href="#id414">24.10.2 node节点添加</a><a class="headerlink" href="#id157" title="Permalink to this headline">¶</a></h3>
<p>kubesphere为方便新增节点，提供了方便的脚步一键新增，可参考：<a class="reference external" href="https://kubesphere.com.cn/docs/v2.1/zh-CN/installation/add-nodes/">https://kubesphere.com.cn/docs/v2.1/zh-CN/installation/add-nodes/</a></p>
<p>修改host.ini</p>
<div class="highlight-[all] notranslate"><div class="highlight"><pre><span></span>master ansible_connection=local  ip=172.16.60.2
node01  ansible_host=172.16.60.3  ip=172.16.60.3
node02  ansible_host=172.16.60.4  ip=172.16.60.4
node03  ansible_host=172.16.60.5  ip=172.16.60.5
[kube-master]
master
[kube-node]
master
node01
node02
node03
</pre></div>
</div>
<p>在 “/script” 目录执行
add-nodes.sh脚本。待扩容脚本执行成功后，即可看到包含新节点的集群节点信息，可通过
KubeSphere 控制台的菜单选择 基础设施 然后进入 主机管理
页面查看，或者通过 Kubectl 工具执行 kubectl get
node命令，查看扩容后的集群节点详细信息。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master scripts<span class="o">]</span><span class="c1"># ./add-nodes.sh</span>
</pre></div>
</div>
<p>查看验证</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master conf<span class="o">]</span><span class="c1"># kubectl get nodes -owide</span>
NAME     STATUS   ROLES         AGE    VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION          CONTAINER-RUNTIME
master   Ready    master        136d   v1.15.5   <span class="m">172</span>.16.60.2   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://18.6.2
node01   Ready    node,worker   136d   v1.15.5   <span class="m">172</span>.16.60.3   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://18.6.2
node02   Ready    node,worker   136d   v1.15.5   <span class="m">172</span>.16.60.4   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://18.6.2
node03   Ready    worker        10m    v1.15.5   <span class="m">172</span>.16.60.5   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://19.3.5
<span class="o">[</span>root@master conf<span class="o">]</span><span class="c1"># kubectl label node  node-role.kubernetes.io/node=</span>
common.yaml            hosts.ini              plugin-qingcloud.yaml
<span class="o">[</span>root@master conf<span class="o">]</span><span class="c1"># kubectl label node node03  node-role.kubernetes.io/node=</span>
node/node03 labeled
<span class="o">[</span>root@master conf<span class="o">]</span><span class="c1"># kubectl get nodes -owide</span>
NAME     STATUS   ROLES         AGE    VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION          CONTAINER-RUNTIME
master   Ready    master        136d   v1.15.5   <span class="m">172</span>.16.60.2   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://18.6.2
node01   Ready    node,worker   136d   v1.15.5   <span class="m">172</span>.16.60.3   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://18.6.2
node02   Ready    node,worker   136d   v1.15.5   <span class="m">172</span>.16.60.4   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://18.6.2
node03   Ready    node,worker   11m    v1.15.5   <span class="m">172</span>.16.60.5   &lt;none&gt;        CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>   <span class="m">3</span>.10.0-693.el7.x86_64   docker://19.3.5
<span class="o">[</span>root@master conf<span class="o">]</span><span class="c1">#</span>
</pre></div>
</div>
<p><img alt="image17" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180530.png" /></p>
</div>
</div>
<div class="section" id="id158">
<h2><a class="toc-backref" href="#id415">24.11 K8s集群资源不均</a><a class="headerlink" href="#id158" title="Permalink to this headline">¶</a></h2>
<p>可以发现k8s资源使用不均衡，之前的部署应用为制定nodeSelect，导致一些系统服务运行在node节点，查看node2内存占用很大,导致集群异常告警或重启</p>
<p><img alt="image18" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180550.png" /></p>
<p>可以通过查看</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>kubectl get pods -o wide --all-namespaces <span class="p">|</span>grep node02 <span class="p">|</span>awk <span class="s1">&#39;{print $1,  $2}&#39;</span>
</pre></div>
</div>
<p>将一些系统应用通过nodeselect来调度到master节点，以减轻node2节点的内存压力。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="sb">`</span>kubectl  get nodes --show-labels<span class="sb">`</span>
</pre></div>
</div>
<p>在node2上查看系统组建添加nodeselector来重新调度</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>nodeSelector:
  node-role.kubernetes.io/master: master
</pre></div>
</div>
<p><img alt="image19" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180603.png" /></p>
<p>查看现存在node2上面的kubesphere系统deployment</p>
<p><img alt="image20" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180621.png" /></p>
<p>通过调度完成，查看node2的内存负载已经下来了</p>
<p><img alt="image21" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180634.png" /></p>
</div>
<div class="section" id="kubesphere-devops">
<h2><a class="toc-backref" href="#id416">24.12 kubesphere devops工程</a><a class="headerlink" href="#kubesphere-devops" title="Permalink to this headline">¶</a></h2>
<p>新增了node03节点，devops工程一周为队列中为此时运行该job的实例未完成初始化，登录集群查看，node03上的base
pod在pull agent镜像，为了快速，直接在node节点，save
base镜像然后在node03上load</p>
<p><img alt="image22" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180658.png" /></p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl describe pods -n kubesphere-devops-system $(kubectl get pods -n kubesphere-devops-system |grep -E &quot;^base&quot; |awk &#39;{print $1}&#39;)</span>
</pre></div>
</div>
<p><img alt="image23" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315180736.png" /></p>
</div>
<div class="section" id="id159">
<h2><a class="toc-backref" href="#id417">24.13 kubesphere 应用安装</a><a class="headerlink" href="#id159" title="Permalink to this headline">¶</a></h2>
<p>目前自己的kubesphere集群为2.1，在具体的在项目中添加了repo后，后台回自己去同步镜像数据还是需要为手动在那个地方触发下，我添加了几个helm
的repo，好像里面的chart没有在web界面显示，在添加了repo的项目下，我新建应用，然后选择来自kubesphere的应用商店，其中只有几个charts，发现不了添加的helm
源的chartscharts，在服务器内部是可以使用命令search到。咨询社区暂时为收到回复，记得v2.0版本后台有个任务会去同步charts，目前2.1版本，先使用helm命令在集群内进行手动helm安装</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@master common-service<span class="o">]</span><span class="c1"># helm install -n consul --namespace common-service -f consul/values-production.yaml consul/</span>
NAME:   consul
LAST DEPLOYED: Tue Jan <span class="m">14</span> <span class="m">17</span>:56:27 <span class="m">2020</span>
NAMESPACE: common-service
STATUS: DEPLOYED


RESOURCES:
<span class="o">==</span>&gt; v1/Pod<span class="o">(</span>related<span class="o">)</span>
NAME      READY  STATUS   RESTARTS  AGE
consul-0  <span class="m">0</span>/2    Pending  <span class="m">0</span>         <span class="nv">0s</span>


<span class="o">==</span>&gt; v1/Service
NAME       TYPE       CLUSTER-IP   EXTERNAL-IP  PORT<span class="o">(</span>S<span class="o">)</span>                                                AGE
consul     ClusterIP  None         &lt;none&gt;       <span class="m">8400</span>/TCP,8301/TCP,8301/UDP,8300/TCP,8600/TCP,8600/UDP  1s
consul-ui  ClusterIP  <span class="m">10</span>.233.59.7  &lt;none&gt;       <span class="m">80</span>/TCP                                                 <span class="nv">1s</span>
<span class="o">==</span>&gt; v1/StatefulSet
NAME    READY  AGE
consul  <span class="m">0</span>/3    <span class="nv">0s</span>


<span class="o">==</span>&gt; v1beta1/PodDisruptionBudget
NAME        MIN AVAILABLE  MAX UNAVAILABLE  ALLOWED DISRUPTIONS  AGE
consul-pdb  <span class="m">1</span>              N/A              <span class="m">0</span>                    1s


NOTES:
  ** Please be patient <span class="k">while</span> the chart is being deployed **


  Consul can be accessed within the cluster on port <span class="m">8300</span> at consul.common-service.svc.cluster.local


In order to access to the Consul Web UI:


    kubectl port-forward --namespace common-service svc/consul-ui <span class="m">80</span>:80
    <span class="nb">echo</span> <span class="s2">&quot;Consul URL: http://127.0.0.1:80&quot;</span>


Please take into account that you need to <span class="nb">wait</span> <span class="k">until</span> a cluster leader is elected before using the Consul Web UI.


In order to check the status of the cluster you can run the following command:


    kubectl <span class="nb">exec</span> -it consul-0 -- consul members


Furthermore, to know which Consul node is the cluster leader run this other command:


    kubectl <span class="nb">exec</span> -it consul-0 -- consul operator raf
</pre></div>
</div>
<div class="figure align-default" id="id166">
<img alt="image-20200125133812075" src="Users/xuel/Library/Application%20Support/typora-user-images/image-20200125133812075.png" />
<p class="caption"><span class="caption-text">image-20200125133812075</span><a class="headerlink" href="#id166" title="Permalink to this image">¶</a></p>
</div>
<p>具体问题可以参考帖子：<a class="reference external" href="https://kubesphere.com.cn/forum/d/669-kubesphere">https://kubesphere.com.cn/forum/d/669-kubesphere</a></p>
</div>
<div class="section" id="id160">
<h2><a class="toc-backref" href="#id418">参考链接</a><a class="headerlink" href="#id160" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">Kubernetes官网教程</a></p></li>
<li><p><a class="reference external" href="https://www.kubernetes.org.cn/k8s">Kubernetes中文社区</a></p></li>
<li><p><a class="reference external" href="https://jimmysong.io/kubernetes-handbook/cloud-native/from-kubernetes-to-cloud-native.html">从Kubernetes到Cloud
Native</a></p></li>
<li><p><a class="reference external" href="https://www.bookstack.cn/read/feiskyer-kubernetes-handbook/appendix-ecosystem.md">Kubernetes
Handbook</a></p></li>
<li><p><a class="reference external" href="https://www.kancloud.cn/huyipow/kubernetes/722822">Kubernetes从入门到实战</a></p></li>
<li><p><a class="reference external" href="https://kubernetes.feisky.xyz/">Kubernetes指南</a></p></li>
<li><p><a class="reference external" href="https://ramitsurana.github.io/awesome-kubernetes/">awesome-kubernetes</a></p></li>
<li><p><a class="reference external" href="https://www.qikqiak.com/k8s-book/">从Docker到Kubernetes进阶</a></p></li>
<li><p><a class="reference external" href="https://www.qikqiak.com/tdd-book/">python微服务实战</a></p></li>
<li><p><a class="reference external" href="https://jimmysong.io/kubernetes-handbook/cloud-native/from-kubernetes-to-cloud-native.html">云原生之路</a></p></li>
<li><p><a class="reference external" href="https://landscape.cncf.io/">CNCF Cloud Native Interactive
Landscape</a></p></li>
</ul>
<div class="section" id="id161">
<h3><a class="toc-backref" href="#id419">视频</a><a class="headerlink" href="#id161" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.bilibili.com/video/av35847195/?p=16&amp;t=3931">马哥(docker容器技术+k8s集群技术)</a></p></li>
<li><p><a class="reference external" href="https://www.acfun.cn/v/ac10232871">微服务容器化实战</a></p></li>
</ul>
<hr class="docutils" />
<p>如果此笔记对您有任何帮助，更多文章，欢迎关注博客一块学习交流👏</p>
<p>​</p>
</div>
<div class="section" id="id162">
<h3><a class="toc-backref" href="#id420">请我喝咖啡☕️</a><a class="headerlink" href="#id162" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>微信 <img alt="微信" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315181628.png" />)</p></li>
<li><p>支付宝 <img alt="支付宝" src="https://kaliarch-bucket-1251990360.cos.ap-beijing.myqcloud.com/blog_img/20200315181115.png" /></p></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to kaliarch kubernetes-note’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, kaliarch

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>